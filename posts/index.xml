<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on PaperMod</title>
    <link>http://localhost:8888/posts/</link>
    <description>Recent content in Posts on PaperMod</description>
    <generator>Hugo -- 0.131.0</generator>
    <language>en</language>
    <lastBuildDate>Fri, 09 Aug 2024 23:10:20 +0000</lastBuildDate>
    <atom:link href="http://localhost:8888/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hugo主题配置</title>
      <link>http://localhost:8888/posts/hugo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Fri, 09 Aug 2024 23:10:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/hugo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE/</guid>
      <description>配置页面的菜单 在config.yaml中配置menu字段，如下：
menu: main: - identifier: &amp;#34;archives&amp;#34; name: 归档 url: &amp;#34;/archives/&amp;#34; weight: 2 - identifier: &amp;#34;tags&amp;#34; name: &amp;#34;标签&amp;#34; url: &amp;#34;/tags/&amp;#34; weight: 3 - identifier: &amp;#34;categories&amp;#34; name: &amp;#34;分类&amp;#34; url: &amp;#34;/categories/&amp;#34; weight: 4 其中weight字段表示菜单的排序，数字越小越靠前。此时页面应该会显示这三个菜单，但是归档页面是404，还需要在创建一个content/archives.md文件，内容如下：
--- title: &amp;#34;Archive&amp;#34; layout: &amp;#34;archives&amp;#34; url: &amp;#34;/archives&amp;#34; summary: &amp;#34;archives&amp;#34; --- 其中最关键的就是layout字段，指定了这个页面使用的模板，这里使用的是themes\PaperMod\layouts\_default\archives.html模板，所以我们在content/archives.md中只需要制定这个模板就行，不需要再添加其他内容，这样就能够让归档页面正常显示了。
修改layout模板 我们可以直接修改主题中的文件，但是这样会导致主题更新时丢失我们的修改，所以我们可以将主题中的文件复制到layouts目录下，然后再进行修改，这样就不会丢失我们的修改了。hugo会优先使用layouts目录下的文件。
文章添加标签和分类 在文章的头部添加tags和categories字段，如下：
tags: [ELF, C] categories: [C语言入门] 文章添加封面图 在static目录下创建一个img目录，然后将图片a.jpg放到这个目录下，然后在文章的头部添加cover字段，如下：
cover: image: img/a.jpg # 设置图片的小标题 alt: &amp;#34;图片&amp;#34; caption: &amp;#34;图片&amp;#34; 点击图片显示原图 在config.yaml中添加如下配置：
params: cover: linkFullImages: true 设置面包屑导航 在config.</description>
    </item>
    <item>
      <title>VSCode 插件发布简易流程</title>
      <link>http://localhost:8888/posts/vscode-%E6%8F%92%E4%BB%B6%E5%8F%91%E5%B8%83%E7%AE%80%E6%98%93%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sat, 27 Jul 2024 22:24:55 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode-%E6%8F%92%E4%BB%B6%E5%8F%91%E5%B8%83%E7%AE%80%E6%98%93%E6%B5%81%E7%A8%8B/</guid>
      <description>VSCode 插件发布简易流程 注册微软开发者账号 如果已经有微软账号，直接登录即可，如果没有，需要注册一个微软账号。登录：https://login.live.com/。
登录https://aka.ms/SignupAzureDevOps，注册微软开发者账号。设置保存默认即可，自己设置也行，不太重要。
右上角创建Personal Access Token，用于登录vsce。
创建的Token名随意，但是Organization和Scopes需要选择正确的，否则会报错。
Organization：All accessible organizations Scopes：Full access 创建成功后，会生成一个Token，需要保存好，后续会用到。Token只会显示一次，如果忘记了，需要重新创建。
注册VSCode Publisher 登录：https://aka.ms/vscode-create-publisher，填写姓名即可如“Dominic Zhang”，会自动生成一个唯一的ID，ID只能是数字字母下划线，所以会生成“DominicZhang”。需要记住这个ID，后续会用到。
vsce登录并发布插件 输入在注册微软开发者账号时生成的Token，登录vsce。
vsce login DominicZhang WARNING Failed to open credential store. Falling back to storing secrets clear-text in: /home/nic/.vsce https://marketplace.visualstudio.com/manage/publishers/ Personal Access Token for publisher &amp;#39;DominicZhang&amp;#39;: **************************************************** The Personal Access Token verification succeeded for the publisher &amp;#39;DominicZhang&amp;#39;. 打包插件：
vsce package 发布插件：
vsce publish </description>
    </item>
    <item>
      <title>Windows挂载NFS网络文件系统实现与开发文件传输</title>
      <link>http://localhost:8888/posts/windows%E6%8C%82%E8%BD%BDnfs%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%BC%80%E5%8F%91%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/</link>
      <pubDate>Thu, 25 Jul 2024 21:11:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/windows%E6%8C%82%E8%BD%BDnfs%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%BC%80%E5%8F%91%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/</guid>
      <description>配置Windows与开发板网络通信 配置Windows侧网卡 将Windows与开发板通过USB网卡连接，开发板的网卡插口选择eth0，也就是靠近拨码开关的网口。开发板开机，Windows的设备管理器中出现以下网卡表示网卡功能正常。
打开网络和共享中心，选择更改适配器设置，找到USB网卡，右键属性，选择Internet协议版本4（TCP/IPv4），点击属性，选择使用以下IP地址，设置IP地址为以下内容：
IP地址：192.168.1.111 子网掩码：255.255.225.0 默认网关：192.168.1.1 网卡的IP要和你Window主机自己的IP在一个网段，不能盲目设置为手册里的192.168.5.10，这样会导致Windows主机无法访问开发板。可以通过在Windows命令行输入ipconfig查看Windows主机的IP地址。一般来说，如果没有设置过路由器，默认都是在192.168.1.x网段。那么网关通常就是这个网段的第一个地址，也就是192.168.1.1，这也是路由器的地址。
如果你配置完网卡以及开发板的IP后能正常相互ping通，那么说明网络配置成功。如果你很不巧和我一样，USB网卡一直无法通过DHCP自动获取IP地址，并且配置完静态IP后只能单侧ping通，那么也可以和我一样将USB网卡和主机的WIFI网卡桥接，这样就可以实现双向通信。这里有个前提条件就是你的主机原先就有两张网卡，一张用于连接路由器，一张是WIFI网卡。不能直接将USB网卡和连接路由器的网卡桥接。
万万没想到一张整年闲置的WIFI网卡竟然派上了用场。
选择WIFI网卡和USB网卡，右键桥接，这样就创建一个网桥，网桥会自动获取IP地址。
开发板侧配置网卡 配置网卡IP，这个IP也是需要和Windows主机在一个网段的。因为路由器分配IP时会从小到大分配，为了避免和已有的设备IP冲突，我们就可以设置一个比较大的IP，比如112。
# 配置网卡ip为192.169.1.112，子网掩码为255.255.255.0 ifconfig eth0 192.168.1.112 设置默认网关：
ip route add default via 192.168.1.1 注意：更换网口需要重启开发板
[Match] Name=eth0 [Network] Address=192.168.1.112/24 Gateway=192.168.1.1 挂载NSF共享目录 Windows侧配置 安装haneWIN NFS 服务器（https://pan.baidu.com/s/1y2R2aJyEExnCJ7FRqdaNdA 提取码：esdw）
安装路径一般为：C:\Program Files (x86)\nfsd。使用VScode打开该目录下的exports文件，修改内容如下，保存时需要用管理员身份保存： d:\nfs -public 192.168.1.112 d:\nfs：共享目录为D盘的nfs，可以根据自己的实际情况修改。 -public：表示共享目录为公共目录，即所有用户都可以访问。 IP：为开发板的IP地址，表示要与这个IP进行共享。 关闭防火墙或者开启必要的通信端口
如果为了省事，可以直接关闭Windows防火墙 如果不想关防火墙需要开启以下端口的通信： TCP 111 UDP 111 TCP 2049 UDP 2049 TCP 1058 UDP 1058 开启端口的方法为：控制面板 -&amp;gt; 系统和安全 -&amp;gt; Windows Defender 防火墙 -&amp;gt; 高级设置 -&amp;gt; 入站规则 -&amp;gt; 新建规则 -&amp;gt; 端口 -&amp;gt; 下一步 -&amp;gt; TCP -&amp;gt; 特定本地端口 -&amp;gt; 2049 -&amp;gt; 下一步 -&amp;gt; 允许连接 -&amp;gt; 下一步 -&amp;gt; 下一步 -&amp;gt; 规则名称 -&amp;gt; 完成。 需要注意在出站规则和入站规则都需要添加。 重启Windows NFS Server服务</description>
    </item>
    <item>
      <title>QEMU 常用命令</title>
      <link>http://localhost:8888/posts/qemu%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sun, 07 Jul 2024 10:22:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>QEMU 是一个开源的虚拟化软件，它能够模拟不同的硬件平台，让用户在不同的操作系统之间进行切换和测试。以下是 QEMU 常用命令的总结文档，包含每个命令的功能说明。
QEMU 安装 源码下载 压缩包方式 版本可以修改
cd qemu-build &amp;amp;&amp;amp; wget &amp;#34;https://download.qemu.org/qemu-8.0.2.tar.xz&amp;#34; tar -xf qemu-8.0.2.tar.xz --strip-components=1 Clone 方式 git clone https://gitlab.com/qemu-project/qemu.git cd qemu git submodule init git submodule update --recursive 配置编译选项 ./configure --target-list=riscv32-softmmu,riscv32-linux-user,riscv64-linux-user,riscv64-softmmu \ --enable-kvm \ --enable-debug \ --enable-sdl \ --prefix=/home/user/program/riscv64-qemu \ --python=/usr/bin/python3 # --python=python路径，如果提示默认python版本低，可以加这个参数 # --prefix 选项设置qemu的安装位置绝对路径，之后若要卸载删除qemu只要删除该文件夹即可，--enable-kvm开启kvm # config完，可以在指定的qemu安装文件夹下面找到config-host.mak文件， # 该文件记录着qemu配置的选项，可以和自己设置的进行对比，确保配置和自己已知 一些常用的编译选项 &amp;ndash;enable-debug：编译调试版本，调试版本的运行速度非常慢 &amp;ndash;disable-werror：忽略警告，否则任何编译警告都被视为编译错误 &amp;ndash;enable-plugins：开启TCG Plugin支持 &amp;ndash;disable-stack-protector：关闭QEMU自身的栈保护 &amp;ndash;extra-cflags=&amp;quot;-O3&amp;quot;：能让你的QEMU提速5~10%，如果编译时报错，请加上--disable-werror &amp;ndash;prefix=&amp;lt;路径&amp;gt;：指定安装目录的路径 &amp;ndash;target-list=&amp;lt;架构&amp;gt;：指定要编译的目标架构列表，例如 x86_64-softmmu,arm-softmmu。 &amp;ndash;enable-&amp;lt;功能&amp;gt;：启用指定的功能。例如，--enable-kvm 启用 KVM 支持，--enable-gtk 启用 GTK 图形界面等。 &amp;ndash;disable-&amp;lt;功能&amp;gt;：禁用指定的功能。 &amp;ndash;enable-debug：启用调试模式，包括调试符号和调试输出。 &amp;ndash;enable-virtfs：启用 virtio 文件系统支持。 &amp;ndash;enable-modules：启用模块支持。 &amp;ndash;disable-guest-agent：禁用客户机代理支持。 &amp;ndash;enable-trace-backend=&amp;lt;后端&amp;gt;：指定跟踪后端，例如 simple、log 或 dtrace。 &amp;ndash;disable-vhost-net：禁用 vhost-net 支持。 编译时输出.</description>
    </item>
    <item>
      <title>小白环法观赛指南</title>
      <link>http://localhost:8888/posts/%E5%B0%8F%E7%99%BD%E7%8E%AF%E6%B3%95%E8%A7%82%E8%B5%9B%E6%8C%87%E5%8D%97/</link>
      <pubDate>Tue, 02 Jul 2024 13:51:31 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%B0%8F%E7%99%BD%E7%8E%AF%E6%B3%95%E8%A7%82%E8%B5%9B%E6%8C%87%E5%8D%97/</guid>
      <description>常见术语 黄衫（Yellow jersey/Maillot Jaune） 黄衫是总成绩领先者的象征，穿上黄衫的车手就是比赛的领头羊。 绿衫（Green jersey/Maillot Vert） 绿衫代表冲刺积分的领先者，通常由擅长平地冲刺的车手穿着。 圆点衫（Polka dot jersey/Maillot à Pois Rouges） 圆点衫授予爬坡积分最高的车手，爬坡能力强的车手更有机会获得。 白衫（White jersey/Maillot Blanc） 白衫是最佳年轻车手（25岁以下）的象征，表现优异的年轻车手会穿上白衫。 突围/兔子（Breakaway） 指比赛中一小部分车手从主集团（Peloton）中突围出来，尝试抢占领先位置。 主集团（Peloton） 主集团是比赛中最大的车手队伍，大部分车手都会待在主集团里，节省体力。 冲刺（Sprint） 冲刺是比赛最后几百米的激烈竞争，冲刺手（Sprinter）们会在这时全力以赴，争夺赛段冠军。 掉队（Dropped） 被其他选手甩在后面，也被称为off the back或者out the back。 计时赛（Time Trial） 计时赛是车手单独出发，按时间计成绩的比赛形式，包括个人计时赛（ITT）和团队计时赛（TTT）。 总成绩（General Classification, GC） 总成绩是根据车手每个赛段的时间累加计算的，最终总时间最少的车手将获得黄衫。 皇后赛段（Queen Stage） 指的是能够决定多日赛最终排名的关键性山地赛段，通常有数座难度很大的山峰。 火车（Paceline） 指的是队友在前面做苦力，保护主将，为主将节省体力的战术。（对应的有冲刺火车或是山地火车） 跟风/蹭风/吸尾流（Draft） 在高速骑行过程中，车手的大部分体力是消耗在对抗空气阻力（风阻）上。因此会有车手骑在其他人或车子后方，来降低风阻，节省体力。 粘瓶（Sticky Bpttle） 选手在拿补给车的水壶时，会短暂获得补给车所带来的助力，以节省体力，通常三五秒之内都是被允许的，如果时间太长被裁判发现将会被罚款甚至取消成绩。 关门时间（Time limit） 在每天的比赛中，车手们必须在不超过当日赛段冠军用时的一定比例时间内完赛，否则将被取消比赛资格，不被获准在第二天的比赛时发车；确切的比例取决于赛段的类型、地形和速度；速度快时，在平地赛段中，比例会低至5%，而速度慢时，在山地赛段中，比例会达到16、17%。在某些情况下，赛事组织者有权酌情赦免一些车手，比如当有过大一部分车手无法在关门时间内完赛时。历史上也有过特例，一些大牌冲刺手被关门，然后组委会以扣冲刺积分的形式来放他们一马。 爬坡点等级（Mountain Climb Classification） 比赛中设置的爬坡抢分点，难度与级数由低至高为4、3、2、1、HC（顶级）；越高的级数代表爬坡长度越长、坡度越陡。 补给区 Feed Zone 比赛中设置一个区域，让车队提供车手饮食补给袋的地方。通常，车手不会在这个区域发动攻击。 垃圾丢弃区（Collection Zone） UCI规定只能在固定的垃圾丢弃区扔垃圾，否则会被罚款。 自行车战术 油管上有个台湾博主叫做《喂我阿维》做了一个自行车战术的系列视频，这个系列的视频选择了一些实战的战况并结合了三维动画来解释各种战术，非常直观易懂，推荐大家观看。
环法观赛中小白常问的问题 为何约纳斯温格高（Jonas Vingegaard Rasmussen）外号鲨鱼佬？ 温格高在进入职业比赛之前曾在鱼类加工厂干过一年左右的兼职，所以粉丝给他起了外号sha鱼佬。因为鲨鱼和sha鱼发音相同，所以就有了这个外号。其实也是为了规避社交平台的敏感词。 为何提到波加查就会提到芬达？叫他芬达超人？ 因为其他车手结束比赛大多会喝纯净水或者一些电解质饮料，或者一些我们不认识的功能饮料。而波加查喜欢比赛后喝芬达。不过今年很少看到他喝芬达了，不知道是不是没要到赞助费（狗头保命）。 每次比赛都有四五个小时，车手怎么上厕所？ 当然是站着解决了，哈哈。比赛开始时车速较慢，还可以停车在路边解决。比赛中段车速会很快，一旦停车将很难追上，通常这时车手会边骑边放水，如果你在直播中看到有在边上骑车并且骑行姿势奇怪的车手，那么他可能在放水。 环法中有中国的车队吗？ 很可惜，没有。目前也只有一位中国车手完成过环法，是在2014年来自捷安特·禧玛诺车队中国车手计成，以第164名，也是最后一名完成比赛。 有的赛段在终点前许多车手为什么向路边扔水壶？ 为了减轻负重，提高冲刺速度。 卡文迪什（Mark CAVENDISH）外号由来？ 盘爷：取自名字（CAVENDISH）的最后四个字母（Dish）。 曼岛飞弹：因为卡文迪什是土生土长的曼岛人，并且速度飞快（曼岛以摩托赛曼岛TT著称）。 卡胖：卡文迪什不擅爬坡，以及每逢佳节胖三斤的体质，为他招来了这个“雅号”。 为何不想争赛段的车队也会在前面带风？为何要把主将带到最后三公里？ 首先在集团前方相对来说较为安全，因为集团后方只能看到前面车手的屁股，对突发情况难以预判。其次因为在最后三公里发生摔车或者机械故障，成绩按照大集团的过线成绩计算，不会丢时间。 更新：UCI 已决定允许组织者和其他利益相关者试行要求修改所谓的“三公里”（或“冲刺区”）规则（《UCI 规则》第 2.</description>
    </item>
    <item>
      <title>Milk-V Duo S 启动</title>
      <link>http://localhost:8888/posts/milk-v-duo-s-%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Sun, 30 Jun 2024 21:04:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/milk-v-duo-s-%E5%90%AF%E5%8A%A8/</guid>
      <description>准备工作 一直在QEMU上做RISC-V开发，最近入手了Milk-V Duo S开发板，准备尝试在硬件上玩玩RISC-V。99块钱的开发板，性价比还是很高的。以下内容就是参考官方文档从 microSD 卡启动 Duo | Milk-V，复现一遍。先熟悉一下硬件。
Milk-V Duo S开发板一块 大于 1GB 的 microSD 卡，我买的是 SD 卡版本，如果买的自带eMMC的就不需要了。 Type-C 数据线 准备镜像并烧录 下载官方镜像，我使用的是milkv-duos-sd-v1.1.1-2024-0528.img.zip。解压后就可以得到镜像文件。我习惯使用Rufus烧录镜像。
Milk-V Duo S 启动！ 将SD卡插入开发板，然后使用Type-C线连接Duo S开发板和电脑。稍等片刻开发板上的蓝色LED灯将闪烁，红色LED保持常量亮。说明开发板已经启动成功。接下来就可以通过SSH连接开发板了。
在使用SSH之前需要开启Windows RNDIS。开启过程参考官方文档设置工作环境 | Milk-V，我就不再重复了，图片有点多，看官方文档更直观。</description>
    </item>
    <item>
      <title>BusyBox 构建并启动 RISC-V Linux 内核</title>
      <link>http://localhost:8888/posts/busybox-%E6%9E%84%E5%BB%BA%E5%B9%B6%E5%90%AF%E5%8A%A8-risc-v-linux-%E5%86%85%E6%A0%B8/</link>
      <pubDate>Thu, 20 Jun 2024 21:10:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/busybox-%E6%9E%84%E5%BB%BA%E5%B9%B6%E5%90%AF%E5%8A%A8-risc-v-linux-%E5%86%85%E6%A0%B8/</guid>
      <description>根文件系统 文件系统与根文件系统 文件系统（File System）是操作系统用于管理和存储数据的一种方式。它定义了如何在存储设备（如硬盘、SSD、USB 驱动器等）上组织文件和目录，以及如何进行数据的读写操作。
常见的文件系统类型有：
ext4：Linux 最常用的文件系统，支持大文件和大分区。 NTFS：Windows 操作系统常用的文件系统，支持文件加密和权限控制。 FAT32：一种兼容性广泛的文件系统，常用于 USB 驱动器和内存卡。 XFS：适用于高性能和高容量存储需求的文件系统。 btrfs：一种现代 Linux 文件系统，支持快照、压缩和多设备管理。 根文件系统（Root File System，通常简称为 rootfs）是文件系统层次结构中的顶级文件系统。它包含了操作系统启动和运行所需的所有基本文件和目录。根文件系统是整个文件系统层次的起点，在 Linux 中由单个斜杠（/）表示。根文件系统首先是内核启动时所 mount 的第一个文件系统，内核代码映像文件保存在根文件系统中，而系统引导启动程序会在根文件系统挂载之后从中把一些基本的初始化脚本和服务等加载到内存中去运行。
根文件系统是建立在文件系统之上的。根文件系统使用某种具体的文件系统类型（如 ext4）来管理和存储其内容。
基于内存的文件系统 ramdisk 是一种基于内存的文件系统，它将内存的一部分用作硬盘驱动器，这样就可以在内存中创建一个文件系统。ramdisk 是一个虚拟磁盘，它的大小和硬盘驱动器的大小一样。ramdisk 的优点是速度快，缺点是断电后数据丢失。
根文件系统中各种配置文件的作用以及配置文件的格式介绍 /etc/inittab /etc/inittab 是 Linux 系统中的一个配置文件，它是 init 程序的配置文件，用于配置系统的运行级别和 init 程序的行为。在 Linux 系统中，init 程序是系统的第一个进程，它负责启动系统中的所有其他进程。/etc/inittab 文件中的每一行都是一个配置项，每个配置项由四个字段组成，字段之间用空格或制表符分隔。/etc/inittab 文件的格式如下：
id:runlevels:action:process 每个字段用冒号分隔，可以缺省。各字段的含义如下：
id：配置项的标识符，用于标识配置项。 runlevels：配置项所对应的运行级别，可以是一个或多个运行级别的组合。 action：配置项的动作，可以是以下几种动作之一： sysinit：系统初始化时运行。 respawn：如果进程终止，立即重新启动。 askfirst：在运行 process 之前询问用户。并在控制台上显示 Please press Enter to active this console。 wait：等待进程终止，然后继续执行下一个配置项。 once：只运行一次，进程终止后不会重新启动。 boot：在系统引导时运行。 bootwait：在系统引导时运行，等待进程终止后继续引导。 initdefault：设置默认运行级别。 shutdown：在系统关机时运行。 process：要执行的进程或脚本的路径。 示例：</description>
    </item>
    <item>
      <title>Google Play 改区</title>
      <link>http://localhost:8888/posts/google-play-%E6%94%B9%E5%8C%BA/</link>
      <pubDate>Fri, 14 Jun 2024 15:03:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/google-play-%E6%94%B9%E5%8C%BA/</guid>
      <description>Google Play 改区 第一步登录 Google Pay，点击右上角的设置按钮。
第二步点击付款方式，删除已有的付款方式。然后点击添加付款方式。
第三步添加信用卡或者借记卡，填写卡号、有效期、CVV、姓名、地址等信息。所有信息可以使用美国地址生成。美国地址只是网站的名称，根据实际情况可以选择其他国家的地址。
需要注意的是：
你要改哪个国家就选择哪个国家，并且生成对应国家的地址。 地址第一行和地址第二行可以随便填。 市/区、州/省、邮编、必须使用生成的地址。 填写示例如下：
第四步添加完成后点击保存，此时底部会有弹窗提示，如图所示。这是正常现象，点击继续。关闭窗口到Google Pay查看地区已经完成更改。
如果不巧，你也跟我一样没能修改成功，可以尝试在手机端登录Google Play，在手机端添加付款方式。添加方式和电脑端一样，只是在手机端添加更容易成功。</description>
    </item>
    <item>
      <title>VSCode关闭滚动条预览</title>
      <link>http://localhost:8888/posts/vscode%E5%85%B3%E9%97%AD%E6%BB%9A%E5%8A%A8%E6%9D%A1%E9%A2%84%E8%A7%88/</link>
      <pubDate>Thu, 13 Jun 2024 17:02:36 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E5%85%B3%E9%97%AD%E6%BB%9A%E5%8A%A8%E6%9D%A1%E9%A2%84%E8%A7%88/</guid>
      <description>VSCode滚动条左侧有较宽的滚动条，这玩意叫小地图Minimap，作用和游戏里的小地图类似，就是为了看一下整个代码结构，便于快速定位，但是我习惯用搜索，觉得这玩意太占地方了，可以在设置里搜索Minimap进行关闭，或者设置为自动隐藏。</description>
    </item>
    <item>
      <title>FRP 内网穿透</title>
      <link>http://localhost:8888/posts/frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</link>
      <pubDate>Mon, 01 Apr 2024 21:08:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</guid>
      <description>懒得自己搭建了，还要准备一台公网服务器，直接找第三方服务商。签到免费送流量，不过流量不多，不过用来穿透个小服务还是够的。
https://chickfrp.com?affcode=2649EJBPNQ https://console.openfrp.net/ 创建隧道，下载配置文件如下：
[common] protocol=tcp server_addr=ali-shanghai-a.chickfrp.com server_port=7000 user=xxxxxxxxx token=xxxxxxxx tcp_mux=true [ openai ] type= tcp remote_port= 10006 local_ip= 192.168.1.9 local_port= 3322 use_compression=false use_encryption=false 配置客户端，下面以 Linux 为例，因为需要配置 Docker 服务，所以做个简单记录。
# 下载 frp 应用，解压后 frpc 是客户端，frps 是服务端，今天我们只用到 frpc wget https://github.com/fatedier/frp/releases/download/v0.56.0/frp_0.56.0_linux_amd64.tar.gz tar zxvf frp_0.56.0_linux_amd64.tar.gz 将服务商提供的配置文件复制到frpc.toml中。服务商提供的可能是旧版本的 frp 配置，是ini格式，需要转换成toml格式。有能力可以自己稍微改一下格式就行，不会的话，可以用在线转换工具，比如：https://toml.info/zh/ini-to-toml。
简单启动：
./frpc -c ./frpc.toml 2024-04-01 21:04:29.326 [I] [client/control.go:170] [19341bf77b5454753237] [SDSDasdaderf.openai] start proxy success 配置 Docker-compose 一键启动，将配置文件frpc.toml映射到容器中。
version: &amp;#34;3.7&amp;#34; services: frp: image: stilleshan/frpc:latest container_name: frp volumes: - /path/to/frpc.</description>
    </item>
    <item>
      <title>BootROM 中 SPI 如何适配不同厂家的 Flash 芯片</title>
      <link>http://localhost:8888/posts/bootrom%E4%B8%ADspi%E5%A6%82%E4%BD%95%E9%80%82%E9%85%8D%E4%B8%8D%E5%90%8C%E5%8E%82%E5%AE%B6%E7%9A%84flash%E8%8A%AF%E7%89%87/</link>
      <pubDate>Sat, 30 Mar 2024 21:38:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/bootrom%E4%B8%ADspi%E5%A6%82%E4%BD%95%E9%80%82%E9%85%8D%E4%B8%8D%E5%90%8C%E5%8E%82%E5%AE%B6%E7%9A%84flash%E8%8A%AF%E7%89%87/</guid>
      <description>问题背景 一款 SoC 芯片，会支持多种方式启动，比如从 NAND Flash、SPI Flash、eMMC、USB、UART 启动。对于 SPI Flash 启动，BootROM 需要知道 SPI Flash 的型号、容量、页大小、擦除大小等信息，以便正确读取、写入、擦除 SPI Flash。但是，不同厂家的 SPI Flash，这些参数可能不同，而 ROM 中的代码是无法修改的，并且容量有限，如何以最小的代码量，适配不同厂家的 SPI Flash 呢？
SPI 开发流程 SPI 控制器初始
SPI 控制器有自己的寄存器，可以配置 SPI 的页，块的擦除时间，是否需要 DMA，是否开启中断，单次读写的大小等等。 使用 SPI 对 Flash 进行配置
BootROM 的 SPI 支持三种模式：Single、Dual、Quad，这不仅要配置 SPI 本身的寄存器，也需要配置 Flash 的寄存器。配置 Flash 的寄存器就需要使用 SPI 来完成。 BootROM 中配置 SPI 控制器的 SPIC_CSR_01 寄存器的spi_bus_mode 位可以配置 SPI 的模式； 查阅 Flash 手册，找到配置总线模式的寄存器以及操作它的命令，如 WINBOND-W25Q128JW 这款 Flash 的配置寄存器为 Status Register-2，Flash 的寄存器是无法直接读写的，所以需要在 Flash 手册中找到操作这个寄存器的命令，在手册的 Instructions 章节可以找到这款 Flash 的配置命令为 Write Status Register-2，命令码为 0x31，只要我们向 Flash 发送 0x31，就可以配置 Flash 的总线模式了。 如何向 Flash 发送指令？需要将真正要发送的指令写入 SPI 的寄存器SPIC_CSR_06，该寄存器的各个 Bit 可以配置命令码，命令类型，命令是否有效等信息。我们将之前的命令码0x31写入到SPIC_CSR_06的command_code位，然后将SPIC_CSR_06的command_type位设置为write status register，SPI 就会自动将这些信息发送给 Flash。Flash 接收到命令后，会根据命令码执行配置寄存器的操作。 SPI 读写 Flash</description>
    </item>
    <item>
      <title>GitHub Copilot CLI命令行AI工具</title>
      <link>http://localhost:8888/posts/github-copilot-cli%E5%91%BD%E4%BB%A4%E8%A1%8Cai%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Sun, 24 Mar 2024 09:44:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/github-copilot-cli%E5%91%BD%E4%BB%A4%E8%A1%8Cai%E5%B7%A5%E5%85%B7/</guid>
      <description>GitHub Copilot CLI 是一个命令行工具，它允许你在终端中使用 GitHub Copilot。你可以使用它来获取代码建议，这些建议是由 OpenAI 的 GPT-4 模型生成的。这个工具可以在任何支持命令行的环境中使用，包括 Visual Studio Code 的集成终端。
参考官方文档：Using GitHub Copilot in the CLI - GitHub Docs
安装 前提：
需要订阅Github Copilot，每月$10。
需要安装GH CLI
订阅自行解决，接下来安装GH CLI：
sudo mkdir -p -m 755 /etc/apt/keyrings &amp;amp;&amp;amp; wget -qO- https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo tee /etc/apt/keyrings/githubcli-archive-keyring.gpg &amp;gt; /dev/null \ &amp;amp;&amp;amp; sudo chmod go+r /etc/apt/keyrings/githubcli-archive-keyring.gpg \ &amp;amp;&amp;amp; echo &amp;#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main&amp;#34; | sudo tee /etc/apt/sources.list.d/github-cli.list &amp;gt; /dev/null \ &amp;amp;&amp;amp; sudo apt update \ &amp;amp;&amp;amp; sudo apt install gh -y 如果没法安装，可以下载deb文件手动安装。Release GitHub CLI 2.</description>
    </item>
    <item>
      <title>RemoteX11 远程调试带GUI应用</title>
      <link>http://localhost:8888/posts/remotex11-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B8%A6gui%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sun, 03 Mar 2024 20:45:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/remotex11-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B8%A6gui%E5%BA%94%E7%94%A8/</guid>
      <description>Windows上通过WSL2进行Linux开发，但是有时候需要开发带GUI的引用，这样就需要将图像转发。
配置Windows 下载安装XMing，启动Xlaunch。
选择MultiWindow 设置Display number为10（可以自行设置，主要是需要和后面在WSL2中设置的变量保持一致） 选择Start no client（Windows的XMing是被动等待接收图像数据，所以选择该项） 一直下一页，其余保持默认，点击完成即可。 配置VSCode 安装RemoteX11插件，直接在插件中心搜索安装即可。
打开设置页面，搜索Remote x11，找到如下配置项，将Display Number配置为10
配置WSL2 安装xclock用于测试
sudo apt-get install xclock 设置环境变量
export DISPLAY=localhost:10.0 # 或者 export DISPLAY=:0 运行xclock查看结果</description>
    </item>
    <item>
      <title>解决系统依赖错误GLIBCXX_3.4.29 not found</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E7%B3%BB%E7%BB%9F%E4%BE%9D%E8%B5%96%E9%94%99%E8%AF%AFglibcxx-3-4-29-not-found/</link>
      <pubDate>Sat, 02 Mar 2024 22:21:23 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E7%B3%BB%E7%BB%9F%E4%BE%9D%E8%B5%96%E9%94%99%E8%AF%AFglibcxx-3-4-29-not-found/</guid>
      <description>以前对软件包的构建不太了解，喜欢随意修改软件源列表，软件源和当前系统的版本不一致就会出现安装了一个依赖较多的软件包后会出现连锁反应，修改了所有依赖的软件包版本，导致系统故障。最常出现的就是修改了GCC版本，导致GLIBCXX版本不一致，导致系统软件无法运行。
如果你的系统还能正常安装软件，那么修改软件源和当前系统版本保存一致，然后更新软件，并重新安装GCC即可解决问题。具体步骤如下：
# 修改软件源 sudo vim /etc/apt/sources.list # 检查当前系统版本 lsb_release -a # 将软件源修改为当前系统版本的软件源，Ubuntu系统版本号对应的软件源列表可以在https://wiki.ubuntu.com/Releases查看 # 更新软件 sudo apt update # 安装GCC，build-essential包含了GCC sudo apt install build-essential 如果你和我一样倒霉，连 apt 都无法使用，那么可以使用 dpkg 命令手动安装 GCC。
因为误操作在 Ubuntu 20.04 上安装了 Ubuntu 18.04 的 GCC，导致系统软件无法运行，apt 也无法使用，所以只能手动安装 GCC。
apt: libx86_64-linux-gnu-libstdc++.so.6: version `GLIBCXX_3.4.29&amp;#39; not found (required by libx86_64-linux-gnulibapt-private.so.0.0) 既然libstdc++版本不一致，我们就去下载对应版本的GCC，访问https://packages.ubuntu.com/，在下方的搜索框中输入libstdc++6，选择对应的系统版本，然后下载对应的GCC。
点击搜索结果，点击系统的架构，一般为amd64，
具体下载地址比较隐蔽，直接点击红框的链接没有反应，你可以右键另存为到本地，我习惯复制链接后用wget下载。
下载完成后，使用dpkg命令安装GCC。
sudo dpkg -i libstdc++6_12.3.0-1ubuntu1\~22.04_amd64.deb 之后可以检查一下缺失的GLIBCXX版本已经安装。
$ strings /lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX GLIBCXX_3.4 GLIBCXX_3.4.1 GLIBCXX_3.4.2 GLIBCXX_3.4.3 GLIBCXX_3.4.4 GLIBCXX_3.4.5 GLIBCXX_3.</description>
    </item>
    <item>
      <title>repo源配置解析</title>
      <link>http://localhost:8888/posts/repo%E6%BA%90%E9%85%8D%E7%BD%AE%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Wed, 17 Jan 2024 21:32:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/repo%E6%BA%90%E9%85%8D%E7%BD%AE%E8%A7%A3%E6%9E%90/</guid>
      <description>repo 源配置解析 openEuler 的软件源配置文件位于/etc/yum.repos.d/目录下，以.repo 为后缀名，文件名可以任意取，但是必须以.repo 结尾。
#generic-repos is licensed under the Mulan PSL v2. #You can use this software according to the terms and conditions of the Mulan PSL v2. #You may obtain a copy of Mulan PSL v2 at: # http://license.coscl.org.cn/MulanPSL2 #THIS SOFTWARE IS PROVIDED ON AN &amp;#34;AS IS&amp;#34; BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR #IMPLIED, INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY OR FIT FOR A PARTICULAR #PURPOSE.</description>
    </item>
    <item>
      <title>Linux内核模块校验机制</title>
      <link>http://localhost:8888/posts/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Sat, 13 Jan 2024 22:00:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6/</guid>
      <description>初学 Linux 内核或者第一次编译使用内核模块时经常会遇到类似这样的错误：
insmod: ERROR: could not insert module kvm.ko: Invalid module format 这个报错通常由于当前插入kvm.ko的version magic版本信息与正在运行的 kernel 的version magic版本不一致导致的。
内核校验模块的流程 我们从问题出发，看看内核是如何校验模块的。搜索了内核源码，找到了在函数check_version中抛出了disagrees about version of symbol错误信息，我们根据源码来回溯一下整个过程。
// kernel/module.c static int check_version(const struct load_info *info, const char *symname, struct module *mod, const s32 *crc) { Elf_Shdr *sechdrs = info-&amp;gt;sechdrs; unsigned int versindex = info-&amp;gt;index.vers; unsigned int i, num_versions; struct modversion_info *versions; /* Exporting module didn&amp;#39;t supply crcs? OK, we&amp;#39;re already tainted. */ if (!</description>
    </item>
    <item>
      <title>x86 平台使用 Gitea Actions 构建多架构应用 (binfmt_misc)</title>
      <link>http://localhost:8888/posts/x86%E5%B9%B3%E5%8F%B0%E4%BD%BF%E7%94%A8gitea-actions%E6%9E%84%E5%BB%BA%E5%A4%9A%E6%9E%B6%E6%9E%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Wed, 10 Jan 2024 11:10:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/x86%E5%B9%B3%E5%8F%B0%E4%BD%BF%E7%94%A8gitea-actions%E6%9E%84%E5%BB%BA%E5%A4%9A%E6%9E%B6%E6%9E%84%E5%BA%94%E7%94%A8/</guid>
      <description>binfmt_misc 简介 binfmt_misc 是 Linux 内核提供的一个机制，它允许用户空间定义新的二进制格式，并将它们与相应的解释器关联起来。这个机制使得在 Linux 上能够动态地注册并运行不同架构的二进制可执行文件，从而支持交叉编译和多架构环境。
具体来说，binfmt_misc 的功能可以通过 /proc/sys/fs/binfmt_misc/ 目录下的文件系统接口实现。这个目录下的文件用于注册和管理二进制格式和相应解释器之间的关联关系。
下面是一些与 binfmt_misc 相关的重要概念和文件：
注册表文件： 在 /proc/sys/fs/binfmt_misc/ 目录下，每个注册的二进制格式都有一个对应的注册表文件。这些文件的命名通常遵循格式 &amp;lt;格式名称&amp;gt;，例如 qemu-riscv64。 注册和注销： 用户空间可以通过在注册表目录下创建文件来注册新的二进制格式。这可以通过写入注册表文件的方式完成。相反，通过删除这些文件，可以注销二进制格式的支持。 解释器： 对于每种注册的二进制格式，需要指定相应的解释器，即用于执行这种格式的程序。在注册表文件中，通过 interpreter 字段指定解释器的路径。 参数： 除了解释器，还可以为每个注册的格式指定一些参数。这些参数可以影响如何运行二进制文件。 内核如何通过 binfmt_misc 机制添加新架构的支持？ 可以通过向 /proc/sys/fs/binfmt_misc/register 文件写入注册信息来注册新的二进制格式。告诉内核某一格式的文件用什么解释器来执行。写入的格式如下：
:name:type:offset:magic:mask:interpreter:flags 各个字段以冒号分隔，部分字段可以缺省，但是冒号需要保留。
字段含义如下：
name：二进制格式的名称，比如qemu-riscv64。
type：类型为 E 或 M。
如果是 E，可执行文件格式由其文件扩展名标识：magic 是要与二进制格式相关联的文件扩展名；offset 和 mask 将被忽略。 如果是 M，格式由文件中绝对偏移（默认为 0）处的魔数标识，并且 mask 是一个位掩码（默认为全 0xFF），表示数字中哪些位是有效的。 interpreter：是要作为匹配文件的参数运行的解释器，使用解释器的绝对路径，比如/usr/bin/qemu-riscv64-static。
flags：可选字段，控制 interpreter 打开文件的行为。共支持 POCF 四种 flag。
P 表示 preserve-argv[0]，保留原始的 argv[0] 参数。 O 表示 open-binary，binfmt-misc 默认会传递文件的路径，而启用这个参数时，binfmt-misc 会打开文件，传递文件描述符。 C 表示 credentials，即会传递文件的 setuid 等权限，这个选项也隐含了 O。 F 表示 fix binary，binfmt-misc 默认的行为在 spwan 进程时会延迟，这种方式可能会受到 mount 命名空间和 chroot 的影响，设置 F 时会立刻打开二进制文件。 举个例子，如果要在 x86_64 架构的系统上运行 RISC-V 架构的二进制文件，可以通过以下方式注册 RISC-V 二进制格式：</description>
    </item>
    <item>
      <title>解决Armoury Crate(华硕奥创中心）安装驱动卡在55%</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3armoury-crate-%E5%8D%8E%E7%A1%95%E5%A5%A5%E5%88%9B%E4%B8%AD%E5%BF%83%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8%E5%8D%A1%E5%9C%A855/</link>
      <pubDate>Sun, 07 Jan 2024 10:37:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3armoury-crate-%E5%8D%8E%E7%A1%95%E5%A5%A5%E5%88%9B%E4%B8%AD%E5%BF%83%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8%E5%8D%A1%E5%9C%A855/</guid>
      <description>卡在55%的基本上驱动已经下载完成，但是还没有安装。这时我们找到下载的文件手动安装即可。一般保存的路径为C:\Users\Administrator\AppData\Local\Packages\B9ECED6F.ArmouryCrate_qmba6cd70vzyy\LocalState\SupportTemp，找到需要安装的驱动文件夹，双击setup.exe即可。</description>
    </item>
    <item>
      <title>迁移WSL2到非系统盘</title>
      <link>http://localhost:8888/posts/%E8%BF%81%E7%A7%BBwsl2%E5%88%B0%E9%9D%9E%E7%B3%BB%E7%BB%9F%E7%9B%98/</link>
      <pubDate>Sat, 06 Jan 2024 16:47:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%81%E7%A7%BBwsl2%E5%88%B0%E9%9D%9E%E7%B3%BB%E7%BB%9F%E7%9B%98/</guid>
      <description>迁移过程 # 关闭WSL2 wsl --shutdown # 查看WSL2的状态 wsl -l -v NAME STATE VERSION Stopped 2 Ubuntu Stopped 2 # 导出WSL2 wsl --export Ubuntu D:\wsl2\ubuntu.tar 正在导出，这可能需要几分钟时间。 操作成功完成。 # 删除WSL2 wsl --unregister Ubuntu 正在注销。 操作成功完成。 # 导入WSL2 wsl --import Ubuntu D:\wsl2 D:\wsl2\ubuntu.tar --version 2 正在导入，这可能需要几分钟时间。 操作成功完成。 # 设置默认用户，如果不设置将会使用root用户，因为之前我一直使用自己创建的用户，所以需要设置，否则zsh配置文件会找不到 ubuntu.exe config --default-user nic # 启动WSL2 wsl 可能有人和我一样安装了Docker，启用WSL后，docker运行数据都在WSL发行版中，文件位置都只能由WSL管理！
安装docker后，docker会自动创建2个发行版：
wsl -l -v NAME STATE VERSION Stopped 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 和上面一样需要到导出，删除，导入。</description>
    </item>
    <item>
      <title>耳机换电池复活耳机小记</title>
      <link>http://localhost:8888/posts/%E8%80%B3%E6%9C%BA%E6%8D%A2%E7%94%B5%E6%B1%A0%E5%A4%8D%E6%B4%BB%E8%80%B3%E6%9C%BA%E5%B0%8F%E8%AE%B0/</link>
      <pubDate>Sat, 06 Jan 2024 10:34:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%80%B3%E6%9C%BA%E6%8D%A2%E7%94%B5%E6%B1%A0%E5%A4%8D%E6%B4%BB%E8%80%B3%E6%9C%BA%E5%B0%8F%E8%AE%B0/</guid>
      <description>半月前给用了三年的小米 10 换了一块二手电池，手机又可以再战三年了。想着自己还有两个耳机，也没有严重故障，只是电池亏点用不了半小时，于是也想着换个电池，看看能不能复活。本来以为耳机太小，太精密，怕自己修不了，但是想想如果不换电池，这个耳机也还是死路一条，不如自己尝试尝试，也能积攒一点经验。实操下来，发现并没有想象中那么难，只要有耐心，还是能修好的。甚至比换手机电池还要容易些，没有那么多螺丝需要拆，也没有那么多胶需要撬。
小米 FlipBuds Pro 配件和工具准备 配件
CR1254 3V 锂电池（可以直接淘宝搜索 FlipBuds Pro 电池，也可以直接搜这个型号，最好买带线的，不带线焊接会比较麻烦） 工具
热风枪（吹风机即可） 电烙铁（小米的这个耳机是需要焊接电池线的） 镊子（清理耳机里面的胶水） 拆机 用吹风机对准耳机吹一两分钟，沿着合模线徒手就能掰开。打开腔体时需要慢一点，有地方有胶水粘粘，不是一打开就是图中的样子，需要把胶水清理干净。
分离后可以从边缘将电池撬出来。
电池正极上用的双面胶将导线粘到了正极，用吹风机对准图中位置稍微加热一分钟作用，然后将电池正极上的贴片取下来。
除了上面一个连接点，还有两个焊接的连接点，用电烙铁加热取下即可将电池脱离。
没有微距镜头，用了我爱音频网的图片
装机 将电池红线连接到正极，黑线连接到负极，然后将电池放回原位，合模即可。如果不知道正负极，可以在耳机线路板上有标识。
还有个需要注意的地方就是吸附磁铁的安装，可能在拆电池时候磁铁会掉落，可以根据图片中磁铁的位置进行安装。先放磁铁再安电池。
在装机过程中就可以连接手机，并播放音乐测试耳机是否能正常工作。因为合模时需要大力压合，播放音乐还能保证压合过程中线路没有断开。
测试 用了一天，耳机电池能用四小时左右，基本上和全新的一样。
索尼 WF-1000XM3、 配件和工具准备 配件
CR1254 3.7V 锂电池，原装的是 VARTA 品牌的，我买的是 ZeniPower，只要型号一样，品牌自己选。甚至可以选 3.85V，75mAh 的续航更好。 工具
热风枪（吹风机即可） 镊子（清理耳机里面的胶水） 螺丝刀 拆机 用吹风机对着耳机的触摸原盘吹一两分钟胶水只在这块区域，边缘是卡扣不需要加热，指甲长的话直接用指甲掰开即可。打开后的样子如下图所示。
有两个小螺丝，拧下后就可以将盖板翻过来，电池就在下方。电池下方有双面胶，直接抠不容易抠出来，用吹风机对着盖板吹一两分钟就可以将胶水软化，然后用镊子将胶水取下。
安装 将电池放回原位，盖板合上，拧上螺丝即可。在安装回耳机盖时需要注意耳机盖是分左右的，如果左右颠倒了是合不上的。参考图中的位置。</description>
    </item>
    <item>
      <title>解决Adobe Photoshop正版升级弹窗</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3adobe-photoshop%E6%AD%A3%E7%89%88%E5%8D%87%E7%BA%A7%E5%BC%B9%E7%AA%97/</link>
      <pubDate>Sat, 23 Dec 2023 12:08:36 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3adobe-photoshop%E6%AD%A3%E7%89%88%E5%8D%87%E7%BA%A7%E5%BC%B9%E7%AA%97/</guid>
      <description>问题背景 不知什么原因，一直正常使用的Adobe Photoshop 2021突然开始弹窗提示升级，还是日文的（应该是代理到到日本了），可能根据地区不同，弹窗的内容也不同，但是都是提示升级，倒计时10天，不知道十天之后啥情况。
解决方法 Adobe的其他软件同理，比如我在用的Lightroom也是这样，解决方法也是一样的。以下方式基于Windows 11，其他版本的Windows也是类似的。
如果没有用代理，可以直接将Photoshop程序禁止联网。可以通过配置Windows的防火墙来实现，具体方法如下：
打开设置搜索“防火墙”，打开Windows防火墙，选择“高级设置”。
选择“出站规则”，点击“新建规则”，选择规则类型为“程序”，程序选择为Photoshop的安装目录下的Photoshop.exe，然后选择“阻止连接”，一路下一步，最后命名规则为“禁止Photoshop联网”。 如果使用了代理，防火墙可能会被绕过，Photoshop可能仍然会通过代理访问更新服务器。需要通过配置代理将Photoshop禁止代理。如果不配置，可以在每次打开Adobe相关软件前关闭代理，如果配置，这里以Clash for Windows为例，可以通过配置Clash的规则来实现，不用关闭代理。具体方法如下：
点击“Profiles”，选择自己的订阅，右击选择“Edit”，将以下这些规则添加到配置文件中保存即可，把配置放到最前面，这样优先级最高。
# Final - MATCH,Proxy - PROCESS-NAME,Lightroom.exe,REJECT - PROCESS-NAME,lightroom.exe,REJECT - PROCESS-NAME,Photoshop.exe,REJECT - PROCESS-NAME,photoshop.exe,REJECT - PROCESS-NAME,Adobe Lightroom CEF Helper.exe,REJECT - PROCESS-NAME,AdobeIPCBroker.exe,REJECT - PROCESS-NAME,dynamiclinkmanager.exe,REJECT - PROCESS-NAME,dynamiclinkmediaserver.exe,REJECT - DOMAIN-SUFFIX,adobe.com,REJECT - DOMAIN-SUFFIX,adobelogin.com,REJECT - DOMAIN-SUFFIX,adobesc.com,REJECT - DOMAIN-SUFFIX,adobe.io,REJECT - DOMAIN-SUFFIX,adobecc.com,REJECT - DOMAIN-SUFFIX,adobemarketingcloud.com,REJECT - DOMAIN-SUFFIX,adobe.net,REJECT - DOMAIN-SUFFIX,adobeexchange.com,REJECT - DOMAIN-SUFFIX,photoshop.com,REJECT - DOMAIN-SUFFIX,photoshop.adobe.com,REJECT - DOMAIN-KEYWORD,photoshop,REJECT 其他程序你可以自己添加，格式为PROCESS-NAME,程序名,REJECT。表示拒绝这些程序访问网络。</description>
    </item>
    <item>
      <title>ZWIFT 使用 Tips</title>
      <link>http://localhost:8888/posts/zwift%E4%BD%BF%E7%94%A8tips/</link>
      <pubDate>Sun, 17 Dec 2023 13:24:55 +0000</pubDate>
      <guid>http://localhost:8888/posts/zwift%E4%BD%BF%E7%94%A8tips/</guid>
      <description>安装与配置 登录 Zwift 官网下载安装包，安装完成后打开，输入邮箱和密码登录。但是我的电脑离骑行台较远，蓝牙很不稳定，Zwift 还有一个配套的手机 App，叫 Companion，可以在谷歌商店安装。安装后打开登录。Zwift PC 客户端登录后在配对装置页面左上角选择“透过手机进行配对”，正常情况下手机端会自动弹出配对页面。记得打开手机的蓝牙开关。
道具功能介绍 常见问题 启动后闪退 将输入法切换为英文模式再重新启动。
没有其他玩家，只有自己 挂全局代理重新启动。</description>
    </item>
    <item>
      <title>Nexus搭建内部镜像</title>
      <link>http://localhost:8888/posts/nexus-%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86/</link>
      <pubDate>Sat, 16 Dec 2023 12:16:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/nexus-%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86/</guid>
      <description>Docker-Compose version: &amp;#34;3.8&amp;#34; services: nexus: image: sonatype/nexus3 container_name: nexus restart: always ports: - 8081:8081 volumes: - /srv/nexus/data:/nexus-data 修改/srv/nexus目录的所有者为当前用户：
sudo chown -R username:username /srv/nexus 修改data目录有最高权限，否则无法启动成功：
sudo chmod -R 777 /srv/nexus/data 代理Docker Hub 登录WEB页面 登录WEB页面，地址为：http://192.168.1.9:8081。 用户名为：admin，密码通过命令获取：
docker exec nexus3 cat /nexus-data/admin.password 创建Blob 在 Nexus Repository Manager 中，Blob Store（二进制大对象存储）是一个用于存储仓库数据的核心组件。Blob Store 主要用于存储各种二进制文件，例如软件包、依赖库、构建产物等，这些文件通常被称为“blob”。
Blob Store 的作用包括：
存储二进制文件： Blob Store 被设计用来安全、可靠地存储二进制文件。这些文件可以是各种形式的构建产物、软件包、依赖库等。Blob Store 是 Nexus 仓库管理系统的核心，它为这些文件提供了一个中央存储位置。
支持不同类型的存储后端： Nexus 支持不同类型的 Blob Store，例如本地文件系统、云存储（如Amazon S3、Google Cloud Storage）等。这使得用户可以根据需求选择不同的存储后端，并根据实际情况进行扩展或迁移。
提供存储策略： Blob Store 允许你定义存储策略，以确定何时以及如何清理或删除不再需要的文件。这对于管理仓库的存储空间非常重要，可以根据策略自动清理不再需要的快照或旧版本。</description>
    </item>
    <item>
      <title>Tunasync 搭建私有镜像站</title>
      <link>http://localhost:8888/posts/tunasync%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E7%AB%99/</link>
      <pubDate>Thu, 14 Dec 2023 14:15:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/tunasync%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E7%AB%99/</guid>
      <description>Tunasync 项目简介 Tunasync 是一个开源的镜像站点镜像工具，可以帮助你快速搭建一个镜像站点，也可以帮助你快速的同步镜像站点的镜像。我们所熟知的清华大学镜像站就是使用 Tunasync 来同步镜像的。
准备 workspace 创建目录用于存放 Tunasync 的程序、配置文件和数据库文件：
mkdir /home/username/tunasync mkdir /home/username/tunasync/conf mkdir /home/username/tunasync/db 创建目录用于存放镜像文件：
sudo mkdir /srv/mirrors srv 目录需要 root 权限，将 mirrors 目录的所有者改为当前用户：
sudo chown -R username:username /srv/mirrors 下载 Tunasync 可以从 Tunasync 项目的 Github releases 编译好的程序直接使用。
cd /home/username/tunasync wget https://github.com/tuna/tunasync/releases/download/v0.8.0/tunasync-linux-amd64-bin.tar.gz tar -zxvf tunasync-linux-amd64-bin.tar.gz 配置 Tunasync Manager 配置 创建配置文件/home/username/tunasync/conf/manager.conf，并添加以下内容：
debug = false [server] addr = &amp;#34;127.0.0.1&amp;#34; port = 12345 ssl_cert = &amp;#34;&amp;#34; ssl_key = &amp;#34;&amp;#34; [files] db_type = &amp;#34;bolt&amp;#34; db_file = &amp;#34;/home/username/tunasync/db/manager.</description>
    </item>
    <item>
      <title>VSCode Linux内核源码阅读环境</title>
      <link>http://localhost:8888/posts/vscode-linux%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Thu, 14 Dec 2023 10:02:32 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode-linux%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83/</guid>
      <description>安装Clangd插件 在VSCode中，你可以通过以下步骤安装Clangd插件：
打开VSCode； 点击左侧的插件图标（Ctrl+Shift+X）； 搜索“Clangd”插件； 点击“安装”按钮。 生成compile_commands.json 对于make项目来说，常规来讲，可以使用Bear来对源码生成compile_commands.json。首先安装Bear：
sudo apt install bear 然后在项目根目录下执行：
bear make -j32 编译完成后，会在项目根目录下生成compile_commands.json文件。
对于CMAKE项目来说，可以在CMakeLists.txt中添加以下语句，然后重新编译项目即可生成compile_commands.json文件： set(CMAKE_EXPORT_COMPILE_COMMANDS True)
配置Clangd插件 进入到项目目录下，下载配置文件：
git clone --depth 1 https://github.com/Dunky-Z/dot-vscode.git .vscode 主要修改--compile-commands-dir参数，将其修改为自己的路径。
随便打开内核源码文件，clangd将会自动生成索引，并将索引文件.idx保存在项目根目录下的.cache目录中。
Linux-5.4 ├── .cache │ └── clangd ├── .config ├── .git 如果生成了索引文件，那么说明配置成功，可以打开源码文件看看是否能够正常跳转。</description>
    </item>
    <item>
      <title>嵌入式Linux驱动开发环境搭建踩坑</title>
      <link>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Flinux%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Wed, 13 Dec 2023 22:59:23 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Flinux%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%B8%A9%E5%9D%91/</guid>
      <description>通过文档资料百度网盘下载配套资料，学习手册目录中有嵌入式Linux应用开发完全手册V5.1_STM32MP157_Pro开发板.pdf，里面有详细的开发环境搭建步骤，但是在搭建过程中还是遇到了一些问题，记录如下：
ModuleNotFoundError: No module named &amp;lsquo;requests&amp;rsquo; ../repo/repo init -u https://gitee.com/weidongshan/manifests.git -b linux-sdk -m stm32mp1/100ask_stm32mp157_pro_release-v2.0.xml --no-repo-verify Traceback (most recent call last): File &amp;#34;/home/nic/develop/repo/main.py&amp;#34;, line 56, in &amp;lt;module&amp;gt; from subcmds.version import Version File &amp;#34;/home/nic/develop/repo/subcmds/__init__.py&amp;#34;, line 35, in &amp;lt;module&amp;gt; mod = __import__(__name__, File &amp;#34;/home/nic/develop/repo/subcmds/selfupdate.py&amp;#34;, line 22, in &amp;lt;module&amp;gt; from subcmds.sync import _PostRepoUpgrade File &amp;#34;/home/nic/develop/repo/subcmds/sync.py&amp;#34;, line 74, in &amp;lt;module&amp;gt; from project import Project File &amp;#34;/home/nic/develop/repo/project.py&amp;#34;, line 33, in &amp;lt;module&amp;gt; import requests ModuleNotFoundError: No module named &amp;#39;requests&amp;#39; 解决方法：</description>
    </item>
    <item>
      <title>解决Ubuntu更新源报错Clearsigned file isnt valid, got NOSPLIT</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3ubuntu%E6%9B%B4%E6%96%B0%E6%BA%90%E6%8A%A5%E9%94%99clearsigned-file-isn-t-valid-got-nosplit/</link>
      <pubDate>Sun, 19 Nov 2023 21:18:09 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3ubuntu%E6%9B%B4%E6%96%B0%E6%BA%90%E6%8A%A5%E9%94%99clearsigned-file-isn-t-valid-got-nosplit/</guid>
      <description>sudo apt update 在更新源时报错 Clearsigned file isn&amp;rsquo;t valid, got &amp;lsquo;NOSPLIT&amp;rsquo; (does the network require authentication?)。
换中科大的源解决，其余源无法解决。
如要用于其他版本，把 jammy 换成其他版本代号即可: 22.04：jammy；20.04：focal；18.04：bionic；16.04：xenial；14.04：trusty。
# 默认注释了源码仓库，如有需要可自行取消注释 deb https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.</description>
    </item>
    <item>
      <title>使用Gitea部署个人代码仓库</title>
      <link>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8gitea%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93/</link>
      <pubDate>Sat, 18 Nov 2023 18:17:42 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8gitea%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93/</guid>
      <description>docker-compose 部署 version: &amp;#34;3.7&amp;#34; services: postgres: image: postgres:latest container_name: postgres ports: - 5432:5432 networks: - br-net-gitea environment: POSTGRES_USER: user POSTGRES_PASSWORD: 123456 POSTGRES_DB: gitea volumes: - ./postgresql:/var/lib/postgresql - ./data:/var/lib/postgresql/data gitea: image: gitea/gitea:1.20.5 container_name: gitea environment: - USER_UID=1000 - USER_GID=1000 - GITEA__database__DB_TYPE=postgres - GITEA__database__HOST=192.168.1.9:5432 - GITEA__database__NAME=gitea - GITEA__database__USER=user - GITEA__database__PASSWD=123456 restart: always networks: - br-net-gitea volumes: - ./data:/data - /etc/timezone:/etc/timezone:ro - /etc/localtime:/etc/localtime:ro - /home/git/.ssh/:/data/git/.ssh ports: - 3000:3000 - &amp;#34;127.0.0.1:2222:22&amp;#34; depends_on: - postgres act_runner: image: gitea/act_runner:latest environment: - GITEA_INSTANCE_URL=http://192.</description>
    </item>
    <item>
      <title>ocrmypdf 让 PDF 可搜索</title>
      <link>http://localhost:8888/posts/ocrmypdf-%E8%AE%A9pdf%E5%8F%AF%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Tue, 19 Sep 2023 19:51:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/ocrmypdf-%E8%AE%A9pdf%E5%8F%AF%E6%90%9C%E7%B4%A2/</guid>
      <description>买的一些课程配套资料都是 PDF 格式的，为了防止盗版都事先用的图片转成的 PDF，这样 PDF 里的内容既没法复制也没法搜索，在查找资料里的关键词的时候就很不方便，所以就想着把这些 PDF 转成可搜索的 PDF。找到了一款工具叫做 ocrmypdf，可以把 PDF 转成可搜索的 PDF，而且还支持中文，这里记录一下使用方法。详细使用文档可以参考官方文档 OCRmyPDF documentation。
安装 sudo apt install ocrmypdf 使用 指定 OCR 的语言 安装语言包
sudo apt install tesseract-ocr-chi-sim 查看是否安装成功
$ tesseract --list-langs List of available languages (3): chi_sim eng osd 注意参数 -l 后面的语言包名称是下划线，而不是短横线。
ocrmypdf -l chi_sim input.pdf output.pdf $ ocrmypdf -l chi_sim --redo-ocr input.pdf output.pdf Scanning contents: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 752/752 [00:14&amp;lt;00:00, 51.36page/s] Start processing 24 pages concurrently 33 redoing OCR 26 [tesseract] lots of diacritics - possibly poor OCR 54 [tesseract] lots of diacritics - possibly poor OCR 88 [tesseract] lots of diacritics - possibly poor OCR 119 [tesseract] lots of diacritics - possibly poor OCR 203 [tesseract] lots of diacritics - possibly poor OCR 256 [tesseract] lots of diacritics - possibly poor OCR 265 [tesseract] lots of diacritics - possibly poor OCR 347 [tesseract] lots of diacritics - possibly poor OCR 376 [tesseract] lots of diacritics - possibly poor OCR 383 [tesseract] lots of diacritics - possibly poor OCR 386 [tesseract] lots of diacritics - possibly poor OCR 402 [tesseract] lots of diacritics - possibly poor OCR 404 [tesseract] lots of diacritics - possibly poor OCR 403 [tesseract] lots of diacritics - possibly poor OCR 412 [tesseract] lots of diacritics - possibly poor OCR 415 [tesseract] lots of diacritics - possibly poor OCR 410 [tesseract] lots of diacritics - possibly poor OCR 439 [tesseract] lots of diacritics - possibly poor OCR 519 [tesseract] lots of diacritics - possibly poor OCR 526 [tesseract] lots of diacritics - possibly poor OCR 587 [tesseract] lots of diacritics - possibly poor OCR 591 [tesseract] lots of diacritics - possibly poor OCR 595 [tesseract] lots of diacritics - possibly poor OCR 607 [tesseract] lots of diacritics - possibly poor OCR 644 [tesseract] lots of diacritics - possibly poor OCR 661 [tesseract] lots of diacritics - possibly poor OCR 682 [tesseract] lots of diacritics - possibly poor OCR 720 [tesseract] lots of diacritics - possibly poor OCR 742 [tesseract] lots of diacritics - possibly poor OCR OCR: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 752.</description>
    </item>
    <item>
      <title>uCore-实验第 0 章 - 实验环境搭建</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC0%E7%AB%A0-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 08 Sep 2023 10:46:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC0%E7%AB%A0-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>本次实验是清华大学操作系统课程的课程实验，实验内容是基于 RISC-V 架构的 uCore 操作系统。本次实验的目的是搭建实验环境，为后续实验做准备。指导书参考uCore-Tutorial-Guide-2023S 文档。本系列文章内容主要是指导书的补充以及我在实验过程的一些理解。
本章没有什么需要特别说明的，指导手册十分详细，按照指导手册的步骤一步步来就可以了。因为平时也在用 WSL2 开发，所以配置十分顺利，没有遇到什么问题。这篇文章就当占坑了，如果后续有什么需要补充的再来更新。</description>
    </item>
    <item>
      <title>uCore-实验第 1 章 - 应用程序与基本执行环境</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC1%E7%AB%A0-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Fri, 08 Sep 2023 10:45:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC1%E7%AB%A0-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83/</guid>
      <description>了解系统调用 操作系统的系统调用（syscall）是操作系统提供给应用程序使用的一种接口。它允许应用程序通过向操作系统发送请求，来执行一些必须由操作系统来完成的任务，例如读取文件、创建进程、分配内存等。
通俗地说，可以把操作系统看作一个巨大的服务员，而应用程序就像是顾客。应用程序不能直接访问硬件或执行特权操作，因为这样可能会导致系统不稳定或不安全。所以，应用程序需要通过系统调用来与操作系统进行交互，请求操作系统代表它完成某些任务。
当应用程序需要操作系统执行特定的功能时，它会调用适当的系统调用函数，并传递参数给它。然后操作系统会接收到这个请求，并根据请求的类型和参数来执行相应的操作。完成后，操作系统会将执行结果返回给应用程序。
在 RISC-V 架构中，系统调用是通过使用特定的指令来实现的。具体来说，RISC-V 架构提供了一个称为 ecall（environment call）的指令来触发系统调用。
要使用 syscall，在 RISC-V 汇编代码中可以通过以下步骤来完成：
将系统调用编号（syscall number）放入寄存器 a7 中，该编号对应于所需的系统调用功能。 将系统调用所需的参数放入其他相应的寄存器中。例如，参数传递给文件读取系统调用可能需要将文件描述符放入 a0 寄存器，缓冲区地址放入 a1 寄存器，以及读取的字节数放入 a2 寄存器。 执行 ecall 指令。这会触发操作系统处理当前运行的程序的系统调用请求。 操作系统接收到系统调用请求后，根据寄存器 a7 中的系统调用编号和其他寄存器中的参数来执行相应的操作。 当操作系统完成系统调用请求时，它将结果放入适当的寄存器中，通常是 a0 寄存器。 程序继续执行，可以检查结果并进行后续的处理。 需要注意的是，具体的系统调用编号以及参数的传递方式会根据操作系统的实现而有所不同。所以在编写 RISC-V 汇编代码时，需要参考操作系统的相关文档来了解具体的系统调用接口和参数传递方式。
makr run 之后发生了什么？ 当执行make run命令后，以下是运行流程的概述：
内核代码编译：执行make run会触发 Makefile 中的相应规则，从而编译生成内核（kernel）二进制文件。
加载 kernel 并启动 QEMU：根据 QEMUOPTS 变量指定的参数，QEMU 加载生成的 kernel 二进制文件，并启动模拟器。
引导代码执行：在模拟器启动后，CPU 的通用寄存器被清零，程序计数器（PC）指向 0x1000 的位置，这里有硬件固化的一小段引导代码。该引导代码会迅速跳转到 0x80000000 处的 RustSBI（Rust Supervisor Binary Interface）。
RustSBI 完成硬件初始化：RustSBI 是一个用于与操作系统进行交互的接口层。在跳转到 RustSBI 之后，它会完成必要的硬件初始化工作。</description>
    </item>
    <item>
      <title>uCore 实验第 5 章 - 进程及进程管理</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC5%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Fri, 08 Sep 2023 10:01:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC5%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>首先，.section .data 表示定义了一个数据段，在这个段中定义了一系列的全局变量。其中，_app_num 是一个标签，表示一个 64 位的整数，初始值为 23。接下来是一系列的标签，分别代表了应用程序的起始地址，每个标签都是 64 位的整数。
接着，.section .data 后面又出现了一个标签 _app_names，它是一个字符串数组，包含了一组字符串，分别命名为 &amp;ldquo;ch2b_exit&amp;rdquo;、&amp;ldquo;ch2b_hello_world&amp;rdquo;、&amp;ldquo;ch2b_power&amp;rdquo; 等等。这些字符串名字对应了前面定义的应用程序的起始地址。
再往下，出现了一个标签 INIT_PROC，它是一个字符串，表示初始化进程的名称，值为 &amp;ldquo;usershell&amp;rdquo;。
之后，每个应用程序都有自己的标签和段名，比如 app_0_start、app_1_start 等等。每个标签都包含一个指令 .incbin，它用于将一个二进制文件（以字符串形式指定文件路径）插入到当前段中。
进程初始化分析 scheduler() fetch_task() // 获取下一个要执行的进程 swtch(&amp;amp;curenv-&amp;gt;context, nextenv-&amp;gt;context) // 切换到下一个进程上下文 // Per-process state struct proc { enum procstate state; // 进程状态 int pid; // 进程 ID uint64 ustack; // 进程用户栈虚拟地址 (用户页表) uint64 kstack; // 进程内核栈虚拟地址 (内核页表) struct trapframe *trapframe; // 进程中断帧 struct context context; // 用于保存进程内核态的寄存器信息，进程切换时使用 pagetable_t pagetable; // User page table uint64 max_page; uint64 program_brk; uint64 heap_bottom; struct proc * parent; // Parent process uint64 exit_code; struct file * files[FD_BUFFER_SIZE]; uint32 syscall_times[MAX_SYSCALL_NUM]; // 系统调用次数统计 uint64 start_time; // 进程开始运行时间 struct vma vmas[NVMA]; // 虚拟内存区域 }; wait 系统调用的功能 wait 系统调用是用于处理子进程终止状态的系统调用。其主要功能是等待子进程的终止，并获取子进程的退出状态信息。在操作系统中，当一个父进程创建了一个子进程后，通常会使用 wait 来等待子进程的终止，以便进行后续的处理，如回收子进程的资源或获取其运行结果。</description>
    </item>
    <item>
      <title>uCore 实验第 4 章 - 地址空间</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC4%E7%AB%A0-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Mon, 04 Sep 2023 11:11:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC4%E7%AB%A0-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</guid>
      <description>为何指定 TRAMPOLINE 和 TRAPFRAME 在 va 的最高位？ TRAMPOLINE 和 TRAPFRAME 被定义在最高的虚拟内存地址上，是因为它们在操作系统的内存布局中起着重要作用。 TRAMPOLINE 被用作从用户模式切换到内核模式的跳转目标。当发生异常或中断时，处理器将从用户模式切换到内核模式，并将控制权转移到内核中预定义的位置，也就是陷阱处理程序。TRAMPOLINE 页面被映射到最高虚拟地址，以便处理器能够在这个转换过程中方便地引用它。通过将其放置在最高地址，确保了无论系统的具体内存布局如何，它始终是可访问的。 另一方面，TRAPFRAME 用于在发生异常或中断时存储机器状态。它包含寄存器、标志和其他操作系统处理异常所需的信息。TRAPFRAME 也被放置在最高的虚拟地址上，以确保它易于访问，并且陷阱处理程序可以高效地访问它。 通过将 TRAMPOLINE 和 TRAPFRAME 定义在最高的虚拟内存地址上，内核可以方便而可靠地处理异常和中断，而无需关心它们在内存中的特定位置。
如何确定分页方案 - satp 在 MMU 没有使能的情况下，虚拟地址和物理地址是相同的。在 MMU 使能的情况下，虚拟地址会被转换成物理地址。这个转换过程是由操作系统来管理的，操作系统需要维护一个数据结构来记录虚拟地址和物理地址的映射关系。这个数据结构就是页表。
转换的过程需要分页机制，分页机制有多种。RISC-V 的分页方案以 SvX 的模式命名，其中 X 是以位为单位的虚拟地址的长度。在 RV64 架构下，RISC-V 支持多种分页方案，包括 Sv39，Sv48，Sv57 以及 Sv64。Sv39 最大支持 39 位的虚拟地址，这意味着它可以支持 512 GB 的虚拟地址空间。Sv48 最大支持 48 位的虚拟地址，这意味着它可以支持 256 TB 的虚拟地址空间。我们将在本章中实现 Sv39 分页方案。
如何开启分页机制呢？RISC-V 的分页机制是通过 satp（Supervisor address translation and protection）寄存器来开启的。satp 寄存器字段分布如下：
Mode 字段可以决定是否开启分页以及分页级数。Mode=0 时，不开启分页；Mode=8 时，开启 Sv39 分页机制。 ASID（Address Space Identifier，地址空间标识符）域是可选的，它可以用来降低上下文切换的开销。目前我们暂不考虑这个字段的作用。 PPN（Physical Page Number，物理页号），保存了根页表的物理地址。 SV39 多级页表机制 页表项描述 Sv39 页表项（page-table entry，PTE）的布局，从左到右分别包含如下所述的域：</description>
    </item>
    <item>
      <title>uCore 实验第 3 章 - 多道程序与分时多任务</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC3%E7%AB%A0-%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%88%86%E6%97%B6%E5%A4%9A%E4%BB%BB%E5%8A%A1/</link>
      <pubDate>Sat, 02 Sep 2023 16:03:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC3%E7%AB%A0-%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%88%86%E6%97%B6%E5%A4%9A%E4%BB%BB%E5%8A%A1/</guid>
      <description>// 启动时初始化进程表 void proc_init(void) { struct proc *p; for (p = pool; p &amp;lt; &amp;amp;pool[NPROC]; p++) { p-&amp;gt;state = UNUSED; // p - pool 是 p 指向的 proc 在 pool 中的下标，因此 p - pool 变化情况是 0, 1, 2, ..., NPROC - 1 p-&amp;gt;kstack = (uint64)kstack[p - pool]; p-&amp;gt;ustack = (uint64)ustack[p - pool]; p-&amp;gt;trapframe = (struct trapframe *)trapframe[p - pool]; /* * LAB1: you may need to initialize your new fields of proc here */ } idle.</description>
    </item>
    <item>
      <title>yq 为 yaml 文件内容排序</title>
      <link>http://localhost:8888/posts/yq%E4%B8%BAyaml%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Fri, 01 Sep 2023 21:37:25 +0000</pubDate>
      <guid>http://localhost:8888/posts/yq%E4%B8%BAyaml%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%8E%92%E5%BA%8F/</guid>
      <description>背景 配置 yaml 文件时会遇到需要将配置的内容按照键值排序的情况，比如下面这样riscv_fork_list.yaml：
packages: - name: accumulo - name: abseil-cpp - name: acpica-tools - name: acpid - name: activemq - name: afflib - name: adcli - name: adwaita-icon-theme - name: aide - name: alsa-lib - name: amtk - name: anaconda - name: apache-sshd - name: annobin - name: antlr3 - name: apache-commons-csv - name: aom - name: apache-commons-beanutils - name: apache-commons-daemon - name: apache-commons-el - name: apache-commons-exec - name: apache-commons-jexl - name: apache-poi - name: apache-rat 我想按照 name 的字母顺序排序，可以使用 yq 工具来实现。</description>
    </item>
    <item>
      <title>解决复制 Markdown 文本到思源笔记无法转义为 Markdown 格式</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E5%A4%8D%E5%88%B6markdown%E6%96%87%E6%9C%AC%E5%88%B0%E6%80%9D%E6%BA%90%E7%AC%94%E8%AE%B0%E6%97%A0%E6%B3%95%E8%BD%AC%E4%B9%89%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Fri, 01 Sep 2023 20:25:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E5%A4%8D%E5%88%B6markdown%E6%96%87%E6%9C%AC%E5%88%B0%E6%80%9D%E6%BA%90%E7%AC%94%E8%AE%B0%E6%97%A0%E6%B3%95%E8%BD%AC%E4%B9%89%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</guid>
      <description>问题描述 在 VSCode 中编辑 Markdown 文本，复制到思源笔记后，思源笔记无法转义为 Markdown 格式。会变成一个代码块，但是代码块内的内容并不是复制的内容。
比如上面这段话复制到思源笔记成了下图这样：
但是我需要的是能够转义为 Markdown 的阅读模式。
解决方法 问题的原因在于 VSCode 复制的文本是带格式的，而思源笔记默认的粘贴模式是纯文本模式，所以会出现上面的问题。
解决方法就是从 VSCode 复制的内容为纯文本，一种可以把文本复制到 txt 文件中，再复制，但是比较麻烦。
第二种方法是使用 VSCode 的插件 Copy Plain Text，搜索下载后，默认快捷键为 Ctrl+Alt+C，可以复制为纯文本。
再次粘贴到思源笔记中，就可以转义为 Markdown 格式了。</description>
    </item>
    <item>
      <title>uCore 实验第 2 章 - 批处理系统</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC2%E7%AB%A0-%E6%89%B9%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Thu, 31 Aug 2023 23:16:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC2%E7%AB%A0-%E6%89%B9%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/</guid>
      <description>flowchart TBsubgraph entry.S_entry[_entry]endsubgraph link_app.S_app_num[_app_num]endsubgraph main.cmain[main]endsubgraph loader.cloader_init[loader_init]run_next_app[run_next_app]load_app[load_app]end_entry --&amp;gt; mainmain --&amp;gt; loader_initmain --&amp;gt; run_next_apprun_next_app --&amp;gt; load_apploader_init --&amp;gt; _app_num </description>
    </item>
    <item>
      <title>如何离线安装 VSCode 插件</title>
      <link>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85vscode%E6%8F%92%E4%BB%B6/</link>
      <pubDate>Tue, 29 Aug 2023 20:59:19 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85vscode%E6%8F%92%E4%BB%B6/</guid>
      <description>背景简介 在使用 VSCode 的过程中，我们经常会安装一些插件来提高开发效率。但是，由于某些原因，我们可能无法直接访问 VSCode 的插件市场，这时候我们就需要离线安装插件了。
这里存在两种情况，一种是为本地的 VSCode 安装插件，另一种是为远程的 VSCode 安装插件。本文将分别介绍这两种情况下的离线安装方法。
远程 VSCode 也就是 VSCode 的Remote Development功能，可以通过 SSH、Docker、WSL 等方式远程连接到远程主机上的 VSCode。
方法一：使用已安装的插件目录 从已经安装插件的电脑上拷贝所有插件，路径一般为 C:\用户\用户名\.vscode\extensions 拷贝到离线安装的电脑上的 .vscode/extensions 文件夹下即可，重启 VScode 即可安装成功。 对于远程 VSCode 我们需要知道，插件不区分操作系统，所以我们可以在本地的 Windows 上的 VSCode 上安装插件，然后将插件目录压缩后整个拷贝到远程主机上即可。
远程主机上的插件目录一般在 ~/.vscode-server/extensions 下。将压缩的文件解药到这个目录下，重启 VSCode 即可。
方法二：下载离线安装包 vslx 安装 到 VScode 插件中心 搜索需要使用的插件名称
下载对应的拓展程序文件，下载的文件的后缀是.vslx VSCode 中安装 </description>
    </item>
    <item>
      <title>Windows 端口映射</title>
      <link>http://localhost:8888/posts/windows%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/</link>
      <pubDate>Mon, 28 Aug 2023 23:24:53 +0000</pubDate>
      <guid>http://localhost:8888/posts/windows%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/</guid>
      <description>命令行 在 Windows 中，可以使用 netsh 命令来添加、查看和删除端口转发规则。
要添加一个端口转发规则，可以使用以下命令：
netsh interface portproxy add v4tov4 listenaddress=&amp;lt;local_address&amp;gt; listenport=&amp;lt;local_port&amp;gt; connectaddress=&amp;lt;remote_address&amp;gt; connectport=&amp;lt;remote_port&amp;gt; 其中：
&amp;lt;local_address&amp;gt;是本地监听的地址（可以是 IP 地址或 0.0.0.0 表示所有地址）。 &amp;lt;local_port&amp;gt;是本地监听的端口。 &amp;lt;remote_address&amp;gt;是转发连接到的远程地址。 &amp;lt;remote_port&amp;gt;是转发连接到的远程端口。 例如，要将本地的 8080 端口转发到远程服务器上的 80 端口，可以使用以下命令：
netsh interface portproxy add v4tov4 listenaddress=127.0.0.1 listenport=8080 connectaddress=192.168.0.100 connectport=80 要查看当前的端口转发规则，可以使用以下命令：
netsh interface portproxy show v4tov4 要删除特定的端口转发规则，可以使用以下命令：
netsh interface portproxy delete v4tov4 listenaddress=&amp;lt;local_address&amp;gt; listenport=&amp;lt;local_port&amp;gt; 其中的&amp;lt;local_address&amp;gt;和&amp;lt;local_port&amp;gt;应该与你想删除的规则匹配。
请注意，执行这些操作通常需要管理员权限。
GUI 使用开源工具PortProxyGUI可以在 UI 界面快速增删改查端口映射。</description>
    </item>
    <item>
      <title>内网穿透远程访问家里的 WSL2</title>
      <link>http://localhost:8888/posts/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%E5%AE%B6%E9%87%8C%E7%9A%84wsl2/</link>
      <pubDate>Mon, 28 Aug 2023 22:45:01 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%E5%AE%B6%E9%87%8C%E7%9A%84wsl2/</guid>
      <description>背景简介 WSL2 是 Windows 的子系统，可以在 Windows 上运行 Linux，但是 WSL2 是运行在虚拟机中的，所以无法直接访问 WSL2 中的服务，比如 SSH 服务。本文介绍如何使用内网穿透工具花生壳来实现远程访问 WSL2 中的服务。
实现这一需求需要完成两个功能。
WSL2 中的服务是运行在虚拟机中的，如何将公网的访问转发到 WSL2 中。 Windows 没有公网 IP，如何通过公网来访问。 WSL2 端口转发 获取 WSL2 的 IP 地址：
hostname -I | awk &amp;#39;{print $1}&amp;#39; 172.26.13.98 Windows 自带的netsh interface portproxy可以实现端口转发。管理员身份打开 cmd，执行以下命令：
netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=2222 connectaddress=172.26.13.98 connectport=22 listenport：公网访问的端口（改一个不冲突的就行） connectaddress：WSL2 的 IP 地址 connectport：WSL2 中 SSH 服务的端口 (默认为 22，不需要更改) 开启 Windows 防火墙入站规则，管理员身份打开 cmd，执行以下命令：
netsh advfirewall firewall add rule name=WSL2 dir=in action=allow protocol=TCP localport=2222 这个命令是用于在 Windows 高级防火墙中添加一条规则。下面是对每个参数的解释：</description>
    </item>
    <item>
      <title>PhotoPrism 部署私人相册</title>
      <link>http://localhost:8888/posts/photoprism%E9%83%A8%E7%BD%B2%E7%A7%81%E4%BA%BA%E7%9B%B8%E5%86%8C/</link>
      <pubDate>Sun, 20 Aug 2023 09:48:13 +0000</pubDate>
      <guid>http://localhost:8888/posts/photoprism%E9%83%A8%E7%BD%B2%E7%A7%81%E4%BA%BA%E7%9B%B8%E5%86%8C/</guid>
      <description>Docker-compose 启动 下载官方的 docker-compose.yml 文件，然后修改一下端口和挂载路径，然后启动即可。
wget https://dl.photoprism.app/docker/docker-compose.yml 如果无法下载下载地址可以前往 Docker Compose - PhotoPrism 查看最新。
根据自己需要修改以下参数：
version: &amp;#39;3.5&amp;#39; services: photoprism: ## Use photoprism/photoprism:preview for testing preview builds: image: dockerproxy.com/photoprism/photoprism:latest # 配置了镜像加速 ports: - &amp;#34;2342:2342&amp;#34; # HTTP port (host:container) environment: PHOTOPRISM_ADMIN_USER: &amp;#34;admin&amp;#34; # 管理员用户名 PHOTOPRISM_ADMIN_PASSWORD: &amp;#34;12345678&amp;#34; # 管理员密码 PHOTOPRISM_DETECT_NSFW: &amp;#34;true&amp;#34; # 自动检测 NSFW 图片并标记隐私图片 PHOTOPRISM_UPLOAD_NSFW: &amp;#34;true&amp;#34; # 运行上传 NSFW 图片 ## Share hardware devices with FFmpeg and TensorFlow (optional): devices: - &amp;#34;/dev/dri:/dev/dri&amp;#34; # 如果有核显或者独显可以配置硬件加速 volumes: - &amp;#34;/root/sharedfolder/syncthing/Photo_Album:/photoprism/originals/Photo_Album&amp;#34; # 照片存放路径 - &amp;#34;/root/sharedfolder/syncthing/daily:/photoprism/originals/daily&amp;#34; # 照片存放路径 - &amp;#34;/root/sharedfolder/syncthing/baby:/photoprism/originals/baby&amp;#34; # 照片存放路径 - &amp;#34;.</description>
    </item>
    <item>
      <title>Docker 部署 Radarr 刮削电影</title>
      <link>http://localhost:8888/posts/docker%E9%83%A8%E7%BD%B2radarr%E5%88%AE%E5%89%8A%E7%94%B5%E5%BD%B1/</link>
      <pubDate>Thu, 17 Aug 2023 22:46:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/docker%E9%83%A8%E7%BD%B2radarr%E5%88%AE%E5%89%8A%E7%94%B5%E5%BD%B1/</guid>
      <description>docker-compose.yml version: &amp;#34;3.7&amp;#34; services: radarr: container_name: radarr image: dockerproxy.com/linuxserver/radarr:latest ports: - &amp;#34;7878:7878&amp;#34; environment: - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Shanghai volumes: - /root/sharedfolder/appdata/radarr:/config - /root/sharedfolder/media:/movies - /root/sharedfolder/downloads/qbittorrent:/downloads 配置中文界面：
导入视频：</description>
    </item>
    <item>
      <title>SSH 免密登录</title>
      <link>http://localhost:8888/posts/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</link>
      <pubDate>Sat, 12 Aug 2023 09:22:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</guid>
      <description>生成密钥对 宿主机任意下目录执行：
$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/user/.ssh/id_rsa): host2servera_id_rsa Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in host2servera_id_rsa. Your public key has been saved in host2servera_id_rsa.pub. The key fingerprint is: SHA256:OkWcw+R3x6Z2mzeYQuG033H3N9qIeym3TZKzz6YD8tQ user@ubuntu18 The key&amp;#39;s randomart image is: +---[RSA 2048]----+ | . | | = . . | | B .o. + | | .</description>
    </item>
    <item>
      <title>Linux 网络配置常用命令</title>
      <link>http://localhost:8888/posts/linux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sat, 05 Aug 2023 15:29:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>配置网桥 brctl # 创建一个名为 br0 的网桥 sudo brctl addbr br0 # 删除网桥 br0 sudo brctl delbr br0 # 列出所有的网桥及其接口信息 sudo brctl show # 将网络接口 `eth0` 添加到网桥 `br0` 中 sudo brctl addif br0 eth0 # 从网桥 `br0` 中删除网络接口 `eth0` sudo brctl delif br0 eth0 ### 显示网桥 `br0` 的 Spanning Tree Protocol (STP)配置 sudo brctl showstp br0 # 禁用 Linux 内核中桥接器对数据包进行处理时调用 iptables 的功能。这种配置通常用于提高桥接速度，减少桥接过程中的 CPU 开销。 sudo sysctl net.bridge.bridge-nf-call-iptables=0 sudo sysctl net.bridge.bridge-nf-call-iptables=0 # 为虚拟网卡设置IP并启动 sudo ifconfig tap0 192.</description>
    </item>
    <item>
      <title>QEMU 虚拟机网络配置</title>
      <link>http://localhost:8888/posts/qemu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 05 Aug 2023 14:47:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</guid>
      <description>Quick Setup 安装工具 安装两个网络管理工具用于建立网桥以及虚拟网卡：
# 安装虚拟网桥工具 sudo apt install bridge-utils -y # UML（User-mode linux）工具 sudo apt install uml-utilities -y 配置脚本 qemu-ifup 将下面的脚本保存为文件 qemu-ifup，并赋予可执行权限：
为了方便复制脚本，在 confluence 页面提供了脚本内容，可以直接复制。
mkdir -p /etc/qemu mv qemu-ifup /etc/qemu &amp;amp;&amp;amp; mv qemu-ifdown /etc/qemu sudo chmod +x qemu-ifup sudo chmod +x qemu-ifdown 因为网卡信息不容易定位，可能一台机器有多个网卡，所以不方便用脚本获取，需要手动设置一下。将下面的NIC值修改为宿主机可以上网的网卡名称。可以通过ifconfig命令查看。
#!/bin/bash # 设置默认网卡信息 NIC=enp2s0 # 设置用户名 USER_NAME=user # 设置网桥名称 BRIDGE=br0 # 设置网络信息 NIC_IP=$(ifconfig $NIC | grep &amp;#34;inet\b&amp;#34; | awk &amp;#39;{print $2}&amp;#39;) NIC_NETMAST=$(ifconfig $NIC | grep &amp;#34;inet\b&amp;#34; | awk &amp;#39;{print $4}&amp;#39;) NIC_BROADCAST=$(ifconfig $NIC | grep &amp;#34;inet\b&amp;#34; | awk &amp;#39;{print $6}&amp;#39;) NETMASK=255.</description>
    </item>
    <item>
      <title>使用 Yadm 管理并同步配置文件 Dotfile</title>
      <link>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8yadm%E7%AE%A1%E7%90%86%E5%B9%B6%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6dotfile/</link>
      <pubDate>Sun, 30 Jul 2023 13:39:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8yadm%E7%AE%A1%E7%90%86%E5%B9%B6%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6dotfile/</guid>
      <description>Dotfiles 就是我们在使用软件的时候，软件为了存储我们个人偏好设置而建立的一个以 . 开头的文件。例如，vim 的配置文件就是 .vimrc，zsh 的配置文件就是 .zshrc。这些文件通常存储在用户的 home 目录中。但是，在不同的电脑上工作时，如果需要使用相同的配置，我们可以考虑使用版本控制工具来管理这些文件。或者在一台新电脑上想快速配置好环境，也可以使用版本控制工具来管理这些文件。Yadm 就可以帮助我们完成这些需求。
安装 yadm 安装 安装 yadm 非常简单，只需在终端输入以下命令：
sudo apt-get install yadm 初始化 yadm 仓库 创建一个新的 yadm 仓库很容易，只需在 home 目录中运行以下命令：
yadm init 现在，yadm 已经创建了一个空白的 git 仓库。
添加 dotfile 文件 要将现有的 dotfile 添加到 yadm 仓库中，请使用以下命令：
yadm add ~/.zshrc 一旦您完成了对要添加的文件的更改并将它们添加到 yadm 仓库中，您需要提交它们。可以使用以下命令：
yadm commit -m &amp;#34;Add .zshrc file to yadm repository&amp;#34; 建立远程仓库 使用 yadm 还可以将 dotfile 文件同步到 GitHub 等 Git 托管服务中。
登录 Github，创建一个新的仓库。例如，您可以创建一个名为 dotfile 的仓库。现在，您需要将本地仓库与远程仓库连接起来。要将本地仓库连接到远程仓库，请使用以下命令：</description>
    </item>
    <item>
      <title>QEMU启动RISC-V架构OpenEuler并配置OSC环境</title>
      <link>http://localhost:8888/posts/qemu%E5%90%AF%E5%8A%A8risc-v%E6%9E%B6%E6%9E%84openeuler%E5%B9%B6%E9%85%8D%E7%BD%AEosc%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Sun, 23 Jul 2023 19:28:29 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%90%AF%E5%8A%A8risc-v%E6%9E%B6%E6%9E%84openeuler%E5%B9%B6%E9%85%8D%E7%BD%AEosc%E7%8E%AF%E5%A2%83/</guid>
      <description>基于Ubuntu 18.04，QEMU 8.0.2，OpenEuler 22.09
安装QEMU 安装基础编译工具 sudo apt install build-essential autoconf automake autotools-dev pkg-config bc curl \ gawk git bison flex texinfo gperf libtool patchutils mingw-w64 libmpc-dev \ libmpfr-dev libgmp-dev libexpat-dev libfdt-dev zlib1g-dev libglib2.0-dev \ libpixman-1-dev libncurses5-dev libncursesw5-dev meson libvirglrenderer-dev libsdl2-dev -y sudo add-apt-repository ppa:deadsnakes/ppa sudo apt install python3.8 python3-pip -y sudo apt install -f pip3 install meson 下载QEMU 建立文件夹用于编译：
cd &amp;amp;&amp;amp; mkdir -p qemu-build 建立文件夹用于安装：
cd &amp;amp;&amp;amp; mkdir -p /home/user/program/riscv64-qemu 可登录官网将版本号换成最新版本即可：</description>
    </item>
    <item>
      <title>SSH 登录 OpenStack 实例</title>
      <link>http://localhost:8888/posts/ssh-%E7%99%BB%E5%BD%95-openstack-%E5%AE%9E%E4%BE%8B/</link>
      <pubDate>Wed, 28 Jun 2023 22:20:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/ssh-%E7%99%BB%E5%BD%95-openstack-%E5%AE%9E%E4%BE%8B/</guid>
      <description>基础配置 添加安全组规则，允许 Ping 和 SSH 访问虚拟机：
openstack security group rule create --proto icmp default root@allone:~# openstack security group rule create --proto icmp default +-------------------+---------------------------+ | Field | Value | +-------------------+-------------------------+ | created_at | 2023-06-28T06:26:10Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | fe9adfc3-dc42-4680-8ecd-ed5a667e1215 | | location | cloud=&amp;#39;&amp;#39;, project.domain_id=, project.domain_name=&amp;#39;Default&amp;#39;, project.id=&amp;#39;6396365541a74b6b8ea8812d1af05e70&amp;#39;, project.name=&amp;#39;admin&amp;#39;, region_name=&amp;#39;&amp;#39;, zone= | | name | None | | port_range_max | None | | port_range_min | None | | project_id | 6396365541a74b6b8ea8812d1af05e70 | | protocol | icmp | | remote_group_id | None | | remote_ip_prefix | 0.</description>
    </item>
    <item>
      <title>VirtualBox Ubuntu 无法联网</title>
      <link>http://localhost:8888/posts/virtualbox-ubuntu%E6%97%A0%E6%B3%95%E8%81%94%E7%BD%91/</link>
      <pubDate>Mon, 26 Jun 2023 22:38:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/virtualbox-ubuntu%E6%97%A0%E6%B3%95%E8%81%94%E7%BD%91/</guid>
      <description>解决方案 VirtualBox Ubuntu 无法联网，重启后可以联网但是几分钟后断开网络。笔者的情况是因为 NetworkManager 自动修改了网络配置导致无法联网，具体现象是开机后网卡信息如下：
user@allone:~$ ifconfig brq64ff9b38-fa: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 ether ce:29:de:12:35:06 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 enp0s3: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet 10.0.2.15 netmask 255.255.255.0 broadcast 10.0.2.255 inet6 fe80::2e8f:2be6:3752:dec4 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 08:00:27:18:31:21 txqueuelen 1000 (Ethernet) RX packets 947 bytes 584483 (584.</description>
    </item>
    <item>
      <title>Virtual Box 的不同虚拟机网络模式</title>
      <link>http://localhost:8888/posts/virtual-box%E7%9A%84%E4%B8%8D%E5%90%8C%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sat, 17 Jun 2023 16:48:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/virtual-box%E7%9A%84%E4%B8%8D%E5%90%8C%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/</guid>
      <description> 💻 NAT 网络模式 NAT 网络以路由器的 NAT 功能为原理，允许虚拟机通过共享主机的 IP 地址访问互联网，但虚拟机之间不能直接通信。通过端口转发可以实现虚拟机之间的连接。 🔗 桥接网络模式 桥接网络模式通过虚拟交换机连接虚拟机和主机，使得虚拟机可以通过局域网访问互联网，并允许虚拟机之间直接通信。 🔒 内部网络模式 内部网络模式使得虚拟机可以创建一个完全隔离的网络，虚拟机之间可以直接通信，但无法访问互联网或外部网络。 🏠 仅主机网络模式 仅主机网络模式允许虚拟机之间可以通信，并且与主机之间也可以通信，但无法访问互联网或外部网络。 虚拟机 ↔ 虚拟机 虚拟机 → 宿主机 宿主机 → 虚拟机 虚拟机 → 互联网 互联网 → 虚拟机 网络地址转换 NAT × √ × √ × NAT 网络 √ √ × √ × Bridged Adapter 桥接网卡 √ √ √ √ √ </description>
    </item>
    <item>
      <title>计算机网络 - 数据链路层</title>
      <link>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/</link>
      <pubDate>Sun, 11 Jun 2023 10:26:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/</guid>
      <description>数据链路层 基本概念 结点：主机，路由器 链路：网络中两个结点之间的物理通道，链路的传输介质主要有双绞线、光纤和微波。分为有线链路、无线链路。 数据链路：网络中两个结点之间的逻辑通道，把实现控制数据传输协议的硬件和软件加到链路上就构成数据链路。 帧：链路层的协议数据单元，封装网络层数据报。
数据链路层负责通过一条链路从一个结点向另一个物理链路直接相连的相邻结点传送数据报。
数据链路层的功能 功能概述 数据链路层在物理层提供服务的基础上向网络层提供服务，其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。其主要作用是加强物理层传输原始比特流的功能，将物理层提供的可能出错的物理连 接改造成为逻辑上无差错的数据链路，使之对网络层表现为一条无差错的链路。
为网络层提供服务 无确认无连接服务 有确认无连接服务 有确认面向连接服务 链路管理 连接的建立，维持，释放 组帧 差错控制 封装成帧 封装成帧就是在一段数据的前后部分添加首部和尾部，这样就构成了一个帧。接收端在收到物理层上交的比特流后，就能根据首部和尾部的标记(帧定界符)，从收到的比特流中识别帧的开始和结束。
首部和尾部包含许多的控制信息，他们的一个重要作用：帧定界（确定帧的界限）。
帧同步：接收方应当能从接收到的二进制比特流中区分出帧的起始和终止。
透明传输
差错控制 传输中的差错都是由噪声引起的。
全局性，由于线路本身电气特性所产生的随机噪声 局部性，由于外界短暂的原因造成的冲击噪声 差错又分为位错和帧错
位错，比特位出错，1 变 0,0 变 1 帧错，包括丢失，重复，失序 发现差错的帧后就将错误值丢弃，如果没有差错控制，将会浪费大量资源，因为传输过程中一直传输了错误的信息。
差错控制
检错编码 奇偶校验码 循环冗余 CRC 纠错编码 海明码 这里提到的编码和物理层的编码与调制不同，物理层的编码针对单个比特，解决传输同步问题。这里的编码针对的是一组比特，通过冗余码的技术检测传输中是否出错。
奇偶校验码 奇校验码：在信息元前加上 1 位后使得 1 的个数为奇数个 偶检验码：在信息元前加上 1 位后使得 1 的个数为偶数个
该检测方式只能检测出奇数个的位错，检错能力为 50%
如果一个字符S的ASCI编码从低到高依次为1100101，采用奇校验，在下述收到的传输后字符中，哪种错误不能检测？ A.11000011B.11001010 C.11001100 D.11010011 答：因为采用奇校验，所以在首位加上一个1使得所有1个数为奇数变成11100101，ABC选项中1的个数都是偶数个，明显发生了变化，所以能检测出错误，但是D选项的1也是奇数个，将无法判断是否出现差错。 CRC 循环冗余码 链路层的两种信道 局域网、广域网 数据链路层的设备 流量控制与可靠传输 单帧滑动窗口与停止等待协议 SR 选择重传协议 滑动窗口最大值 </description>
    </item>
    <item>
      <title>Ubuntu 22.04 系统安装水星 wifi 驱动 Mercury MW310UH</title>
      <link>http://localhost:8888/posts/ubuntu-22-04-%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%B0%B4%E6%98%9F-wifi-%E9%A9%B1%E5%8A%A8mercury-mw310uh/</link>
      <pubDate>Sun, 11 Jun 2023 10:00:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/ubuntu-22-04-%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%B0%B4%E6%98%9F-wifi-%E9%A9%B1%E5%8A%A8mercury-mw310uh/</guid>
      <description>确认网卡信息 lsusb 得到 USB 设备信息
Bus 001 Device 013: ID 0bda:a192 Realtek Semiconductor Corp. Disk 安装网卡驱动 根据设备 ID，用关键词网上搜素一下相关驱动，得到有这个驱动可用：
sudo apt update sudo apt install build-essential git dkms git clone https://gitee.com/BrightXu/rtl8192fu.git cd rtl8192fu make -j$(nproc) sudo make install sudo modprobe 8192fu 查看是否安装成功
usb-devices 如果有 Driver=rtl8192fu 字段说明安装成功。如果桌面右上角无线连接图标可用，说明可以使用无线网络了。如果不可用继续往下看。
修改设备模式 如果使用lsusb命令查看设备，发现设备末尾依然是 Disk 模式，说明这个设备是磁盘设备，还不能当做网络适配器使用，需要修改其模式。
sudo apt-get install -y usb-modeswitch sudo vim /lib/udev/rules.d/40-usb_modeswitch.rules 在最后 LABEL 之前加上
# Realtek 8192F Wifi AC USB ATTR{idVendor}==&amp;#34;0bda&amp;#34;, ATTR{idProduct}==&amp;#34;a192&amp;#34;, RUN+=&amp;#34;/usr/sbin/usb_modeswitch -K -v 0bda -p a192&amp;#34; LABEL=&amp;#34;modeswitch_rules_end&amp;#34; sudo usb_modeswitch -KW -v 0bda -p a192 关闭安全启动 安全启动模式下无法使用第三方的驱动，所以需要在开机时进入 BIOS 将安全启动关闭，每个主板不一样，自行搜索。</description>
    </item>
    <item>
      <title>云计算基础技术汇总</title>
      <link>http://localhost:8888/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/</link>
      <pubDate>Fri, 09 Jun 2023 21:42:59 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/</guid>
      <description>云计算服务类型 传统架构=&amp;gt;Iaas=&amp;gt;Paas=&amp;gt;Saas
自己烧饭=&amp;gt; 叮咚买菜=&amp;gt; 美团外卖=&amp;gt; 餐厅吃饭
云计算部署形式以及应用 类型 描述 优点 缺点 私有云 利用已有设备自我构建，云端资源只给内部人员使用。 安全性高 维护成本高 社区云、行业云 为特定行业构建共享基础设施的云。 有一套用户体系 维护成本高 公有云 构建大型基础设施云出租给公众。 用户来说成本低，服务多 安全性低 混合云 两种或者两种以上的云组成的云服务 敏捷，灵活，降低成本 兼容性问题 应用 存储云、医疗云、教育云、企业云、金融云、游戏云、桌面云
关键技术 虚拟化 分布式存储 将数据存储在不同的物理设备中。这种模式不仅摆脱了硬件设备的限制，同时扩展性更好，能够快速响应用户需求的变化（整合存储资源提供动态可伸缩资源池的分布式存储技术)
数据中心联网 虚拟机之间需要实时同步大量的数据，产生大量东西流量。
并行编程 在并行编程模式下，并发处理、容错、数据分布、负载均衡等细节都被抽象到一个函数库中，通过统一接口，用户大尺度的计算任务被自动并发和分布执行，即将一个任务自动分成多个子任务，并行地处理海量数据。
体系结构 云计算平台体系结构由用户界面、服务目录、管理系统、部署工具、监控和服务器集群组成。
自动化部署 对云资源进行自动化部署指的是基于脚本调节的基础上实现不同厂商对于设备工具的自动配置，用以减少人机交互比例、提高应变效率，避免超负荷人工操作等现象的发生，最终推进智能部署进程。
云服务提供商 亚马逊云、腾讯云、阿里云、百度云、华为云
技术架构：开源（Xen,KVM），Vmware，微软 hyper-v，阿里飞天 Apsara
开源云管理平台：OpenStack
虚拟化简介 虚拟化：一种计算机资源管理技术，将各种 T 实体资源抽象、转换成另一种形式的技术都是虚拟化。 作用：通过该技术将一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。
从行业数据互相关联的角度来说，云计算是极度依赖虚拟化的。但虚拟化并非云计算，云计算也并非虚拟化。虚拟化只是云计算的核心技术，但并非云计算的核心关注点。
云计算是一种服务。虚拟化是云计算的技术基础。
虚拟化相关的几个概念 Guest OS:运行在虚拟机之上的 OS Guest Machine:虚拟出来的虚拟机 VMM:虚拟机监控器，即虚拟化层 (Virtual Machine Monitor,VMM) Host OS:运行在物理机之上的 OS Host Machine:物理机
虚拟化类型 虚拟化类型 描述 特点 案例 寄居虚拟化（Type2） 在主机（宿主）操作系统上安装和运行虚拟化程序 - 简单、易于实现。- 安装和运行应用程序依赖于主机操作系统对设备的支持。- 有两层 OS，管理开销较大，性能损耗大。- 虚拟机对各种物理设备 (cpu、内存、硬盘等) 的调用，都通过虚拟化层和宿主机的 OS 一起协调才能完成。 - Vmware- VirturalBox 裸金属虚拟化 (Type1) 直接将 VMM 安装在硬件设备上，VMM 在这种模式下又叫做 Hypervisor，虚拟机有指令要执行时，Hypervisors 会接管该指令，模拟相应的操作。 - 不依赖于操作系统。- 支持多种操作系统，多种应用。- 依赖虚拟层内核和服务器控制台进行管理。- 需要对虚拟层的内核进行开发（难度大）。 - VMware ESX- Xen- 华为 FusionSphere 混合虚拟化 在一个现有的正常操作系统下安装一个内核模块，内核拥有虚拟化能力。(相当于寄居与裸金属的混合) - 相对于寄居虚拟化架构，性能高。- 相对于裸金属虚拟化架构，不需要开发内核。- 可支持多种操作系统。- 需底层硬件支持虚拟化扩展功能。 - KVM 寄居虚拟化（Type2）</description>
    </item>
    <item>
      <title>Devstack 部署 OpenStack</title>
      <link>http://localhost:8888/posts/devstack%E9%83%A8%E7%BD%B2openstack/</link>
      <pubDate>Fri, 09 Jun 2023 21:38:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/devstack%E9%83%A8%E7%BD%B2openstack/</guid>
      <description>Devstack 部署 OpenStack 试验发现在 Host 为 Ubuntu20.04 和 22.04 上无法顺利安装 VirtualBox，请在 Ubuntu18.04 上安装 VirtualBox。虚拟机镜像版本为 Ubuntu20.04，以下步骤可以稳定复现，OpenStack master（c424a7a299e37004d318107648bb18e157344985）版本。
总而言之，在 18.04 版本上安装 VirtualBox，在 20.04 版本上安装 OpenStack。
因为安装 OpenStack 容易破话系统包依赖，如果为了学习建议在虚拟机中安装。
安装过程中需要下载镜像，请确认机器可以访问外网。
安装 VirtualBox sudo apt update sudo apt install virtualbox virtualbox-ext-pack 确认 VirtualBox 配置 请确认 VirtualBox 配置如下，VirtualBox 默认配置硬盘为 10G，远远不够用，为了避免后续的麻烦，请确认如下配置：
磁盘大于 100G
内存大于 16G
CPU 大于 4 个
下载镜像并安装 镜像可以去清华大学开源软件镜像站 | Tsinghua Open Source Mirror下载。
更新源 sudo mv /etc/apt/sources.list /etc/apt/sources.list.bk &amp;amp;&amp;amp; sudo bash -c &amp;#34;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/apt/sources.</description>
    </item>
    <item>
      <title>计算机网络 - 物理层</title>
      <link>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%89%A9%E7%90%86%E5%B1%82/</link>
      <pubDate>Mon, 10 Apr 2023 21:14:41 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%89%A9%E7%90%86%E5%B1%82/</guid>
      <description>物理层 基本概念 物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。 物理层主要任务：确定与传输媒体接口有关的一些特性
机械特性：定义物理连接的特性，规定物理连接时所采用的规格、接口形状、引线数目、引脚数量和排列情况。 电气特性：规定传输二进制位时，线路上信号的电压范围、阻抗匹配、传输速率和距离限制等。 功能特性：指明某条线上出现的某一电平表示何种意义，接口部件的信号线的用途。 规程特性（过程特性）：定义各条物理线路的工作规程和时序关系 数据通信基础概念 典型的数据通信模型 通信的目的是传送消息。 数据：传送信息的实体，通常是有意义的符号序列。 信号：数据的电气/电磁的表现，是数据在传输过程中的存在形式。
数字信号：代表消息的参数取值是离散的。 - 模拟信号：代表消息的参数取值是连续的。 信源：产生和发送数据的源头。 信道：信号的传输媒介。一般用来表示向某一个方向传送信息的介质，因此一条通信线路往往包含一条发送信道和一条接收信道。
通信方式 从通信双方信息的交互方式看，可以有三种基本方式：
单工通信只有一个方向的通信而没有反方向的交互，仅需要一一条信道。 半双工通信通信的双方都可以发送或接收信息，但任何一方都不能同时发送和接收，需要两条信道。 全双工通信通信双方可以同时发送和接受信息，也需要两条信道。 传输方式 串行传输 速度慢，费用低，适合远距离 并行传输 速度快，费用高，适合近距离 码元 码元是指用一个固定时长的信号波形（数字脉冲），代表不同离散数值的基本波形，是数字通信中数字信号的计量单位，这个时长内的信号称为k进制码元，而该时长称为码元宽度。当码元的离散状态有 M 个时（M 大于 2），此时码元为 M 进制码元。 1码元可以携带多个比特的信息量。例如，在使用二进制编码时，只有两种不同的码元，一种代表 0 状态，另 - 一种代表 1 状态。在四进制码元中，一个码元就由 2 比特组成。
速率，波特，带宽 速率也叫数据率，是指数据的传输速率，表示单位时间内传输的数据量。可以用码元传输速率和信息传输速率表示。 传输速率是主机上发出的速率，而传播速率是在信道上的传播速率。两者是不同的概念
码元传输速率1s传输多少个码元：别名码元速率、波形速率、调制速率、符号速率等，它表示单位时间内数字通信系统所传输的码元个数（也可称为脉冲个数或信号变化的次数），单位是波特（Baud）。1 波特表示数字通信系统每秒传输一个码元。这里的码元可以是多进制的，也可以是二进制的，但码元速率与进制数无关。 信息传输速率1s传输多少个比特：别名信息速率、比特率等，表示单位时间内数字通信系统传输的二进制码元个数（即比特数），单位是比特/秒（b/s）。 关系：若一个码元携带n bit的信息量，则M Baud的码元传输速率所对应的信息传输速率为M * n bit/s。
带宽 (是个理想值)：表示在单位时间内从网络中的某一点到另一 点所能通过的“最高数据率”，常用来表示网络的通信线路所能传输数据的能力。单位是 b/s。
4 进制表示码元有 4 种波形，只需要 2 位就可以表示 4 种波形，同理 16 进制需要 4 位表示。</description>
    </item>
    <item>
      <title>VSCode 插件 REST Client 使用文档</title>
      <link>http://localhost:8888/posts/vscode-%E6%8F%92%E4%BB%B6-rest-client%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/</link>
      <pubDate>Fri, 24 Mar 2023 19:59:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode-%E6%8F%92%E4%BB%B6-rest-client%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/</guid>
      <description>REST Client 是 VSCode 中一款非常好用的插件，能够帮助开发人员快速、方便地发送 HTTP 请求并查看响应。在本文中，我们将会详细介绍 REST Client 的使用方法。
安装 REST Client 插件 在 VSCode 中，你可以通过以下步骤安装 REST Client 插件：
打开 VSCode； 点击左侧的插件图标（Ctrl+Shift+X）； 搜索“REST Client”插件； 点击“安装”按钮。 发送 HTTP 请求 使用 REST Client 插件发送 HTTP 请求非常简单。你只需要创建一个新的.rest文本文件，将请求信息放入其中，然后使用快捷键Ctrl + Alt + R 或者右键菜单的 Send Request 选项发送请求。
下面是一个简单的 GET 请求的例子：
GET https://jsonplaceholder.typicode.com/posts/1 HTTP/1.1 这个请求会获取 JSONPlaceholder API 中的一篇博客文章。
如果你想添加请求头或请求体，可以使用以下语法：
GET https://jsonplaceholder.typicode.com/posts/1 HTTP/1.1 Content-Type: application/json { &amp;#34;title&amp;#34;: &amp;#34;foo&amp;#34;, &amp;#34;body&amp;#34;: &amp;#34;bar&amp;#34;, &amp;#34;userId&amp;#34;: 1 } 这个请求会在请求头中添加 Content-Type 头，请求体中包含 JSON 数据。</description>
    </item>
    <item>
      <title>WSL2 安装 Docker</title>
      <link>http://localhost:8888/posts/wsl2%E5%AE%89%E8%A3%85docker/</link>
      <pubDate>Thu, 16 Mar 2023 22:19:00 +0000</pubDate>
      <guid>http://localhost:8888/posts/wsl2%E5%AE%89%E8%A3%85docker/</guid>
      <description>在 WSL2 中，你可能会遇到与 Docker 服务相关的问题，因为 WSL2 与传统 Linux 系统在某些方面有所不同。在这种情况下，你可以尝试以下步骤来解决问题：
首先，确保你已经安装了 WSL2 的最新版本。你可以通过运行以下命令来更新 WSL2： wsl --update 确保 Docker Desktop for Windows 已安装并启用 WSL2 集成。你可以在 Docker Desktop 设置中找到这个选项。确保你的 WSL2 发行版已被添加到 Docker Desktop 的 WSL 集成列表中。点击链接下载安装在 Windows 上安装 Docker 桌面。 在 WSL2 中，尝试手动停止 Docker 服务： sudo /etc/init.d/docker stop 如果这个命令无法停止 Docker 服务，请尝试以下命令： sudo killall dockerd 卸载 Docker： sudo apt-get purge docker-ce 删除 Docker 相关的文件和目录： sudo rm -rf /var/lib/docker 重新启动 WSL2： wsl --shutdown 然后重新打开 WSL2。 在 WSL2 中，不要直接安装 Docker CE。而是使用 Docker Desktop for Windows 提供的 Docker 服务。这意味着你不需要在 WSL2 中安装 Docker CE，因为 Docker Desktop 已经提供了 Docker 服务。 确保你的 WSL2 发行版可以访问 Docker Desktop 提供的 Docker 服务。你可以通过运行以下命令来检查： docker --version docker info </description>
    </item>
    <item>
      <title>一生一芯笔记</title>
      <link>http://localhost:8888/posts/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 12 Mar 2023 12:58:15 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%B8%80%E7%94%9F%E4%B8%80%E8%8A%AF%E7%AC%94%E8%AE%B0/</guid>
      <description>一生一芯概述 “一生一芯”概述 _哔哩哔哩_bilibili
程序的执行和模拟器 freestanding 运行时环境 程序如何结束运行 在正常的环境中，写了一段代码return之后，实际上调用了一个系统调用exit。但是在 freestanding 环境中，没有操作系统支持，根据 C99 手册规定，在 freestanding 环境中结束运行是由用户实现决定的。
5.1.2.1 Freestanding environment 2 The effect of program termination in a freestanding environment is implementation-defined. 在 qemu-system-riscv64 中的 virt 机器模型中，往一个特殊的地址写入一个特殊的“暗号”即可结束 QEMU
#include &amp;lt;stdint.h&amp;gt; void _start() { volatile uint8_t *p = (uint8_t *)(uintptr_t)0x10000000; *p = &amp;#39;A&amp;#39;; volatile uint32_t *exit = (uint32_t *)(uintptr_t)0x100000; *exit = 0x5555; // magic number _start(); // 递归调用，如果正常退出将不会再次打印A } 在自制 freestanding 运行时环境上运行 Hello 程序 QEMU 虽然是个开源项目，但还挺复杂，不利于我们理解细节。让我们来设计一个面向 RISC-V 程序的简单 freestanding 运行时环境，我做以下约定。</description>
    </item>
    <item>
      <title>JAVA 小白笔记</title>
      <link>http://localhost:8888/posts/java%E5%B0%8F%E7%99%BD%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 12 Mar 2023 09:55:55 +0000</pubDate>
      <guid>http://localhost:8888/posts/java%E5%B0%8F%E7%99%BD%E7%AC%94%E8%AE%B0/</guid>
      <description>基础设施 本章记录一些配置笔记，不是 step by step 教程
安装 JAVA # 免登陆下载java https://xiandan.io/posts/jdk-download.html # 高速镜像 https://github.com/LilithBristol/javajdkforwinx64 Linux 环境变量 PATH
%JAVA_HOME%\bin %JAVA_HOME%\jre\bin Windows 环境变量
# JAVA_HOME C:\Program Files\Java\jdk1.8.0_212 # CLASSPATH .;%JAVA_HOME%\bin;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar VSCode 开发环境 基础插件 安装 Extension Pack for Java 即可，会把用到的开发插件都安装。不需要安装 Java Language Support 会和 Extension Pack for Java 中的 Language Support for Java by Red Hat 冲突。目前使用过程中也没有遇到必须使用 Java Language Support 的情况。
基本使用 使用 CTRL+SHIFT+P 输入 Java: create Project，输入项目名，在 src 文件夹中，选择 Run 运行 Java 代码。</description>
    </item>
    <item>
      <title>如何使用 Gitlab CI Pipeline</title>
      <link>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8gitlab-ci-pipeline/</link>
      <pubDate>Sat, 07 Jan 2023 11:08:19 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8gitlab-ci-pipeline/</guid>
      <description>GitLab CI/CD 是一个强大的工具，可以帮助开发团队实现自动化构建、测试和部署。本文将介绍如何使用 GitLab CI/CD 的 Pipeline 功能，以实现将 Markdown 文件自动编译为 PDF 并上传至 GitLab Release 界面的功能。
准备工作 在开始使用 GitLab CI/CD 的 Pipeline 功能之前，需要进行一些准备工作。具体步骤如下：
创建 GitLab 项目：在 GitLab 上创建一个新项目，并将 Markdown 文件上传至项目的某个目录下。例如，我们将 Markdown 文件上传至项目的根目录下，并命名为 example.md。 安装 Pandoc：Pandoc 是一个用于文档转换的工具，我们将使用它将 Markdown 文件转换为 PDF。在安装 Pandoc 之前，需要先安装 LaTeX，因为 Pandoc 使用 LaTeX 进行 PDF 渲染。具体安装步骤请参考 Pandoc 和 LaTeX 的官方文档。
创建 Release：在 GitLab 上创建一个 Release，用于存储编译好的 PDF 文件。具体操作方法请参考 GitLab 的官方文档。
创建 CI/CD 配置文件：在项目根目录下创建一个.gitlab-ci.yml 文件，并在其中定义 Pipeline 的流程。
编写 CI/CD 配置文件 下面是一个样例的.gitlab-ci.yml 文件，用于实现将 Markdown 文件编译为 PDF 并上传至 GitLab Release 界面的功能。</description>
    </item>
    <item>
      <title>Markdown 嵌入 Draw.io</title>
      <link>http://localhost:8888/posts/markdown%E5%B5%8C%E5%85%A5draw-io/</link>
      <pubDate>Sat, 07 Jan 2023 10:42:06 +0000</pubDate>
      <guid>http://localhost:8888/posts/markdown%E5%B5%8C%E5%85%A5draw-io/</guid>
      <description>Markdown 是支持嵌入 HTML 的，大部分阅读器也都支持解析。Draw.io 可以导出为 HTML 格式。
文件—导出为 HTML—导出—新窗口打开—复制 HTML 代码—只保留&amp;lt;body&amp;gt;标签之间的内容，不包含&amp;lt;body&amp;gt;和&amp;lt;/body&amp;gt;。</description>
    </item>
    <item>
      <title>Ubuntu 18.04 安装Clang/LLVM 11</title>
      <link>http://localhost:8888/posts/ubuntu-18-04-%E5%AE%89%E8%A3%85clang-llvm-11/</link>
      <pubDate>Sat, 24 Dec 2022 15:53:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/ubuntu-18-04-%E5%AE%89%E8%A3%85clang-llvm-11/</guid>
      <description>从 APT 安装 Install the GPG Key for https://apt.llvm.org/
wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - Add the repo for Clang 11 stable-old for Ubuntu 18.04 Bionic
echo &amp;#34;deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-11 main&amp;#34; | sudo tee -a /etc/apt/sources.list sudo apt-get update Install practically everything (except python-clang-11 which for some reason doesn&amp;rsquo;t work)
sudo apt-get install libllvm-11-ocaml-dev libllvm11 llvm-11 llvm-11-dev llvm-11-doc llvm-11-examples llvm-11-runtime \ clang-11 clang-tools-11 clang-11-doc libclang-common-11-dev libclang-11-dev libclang1-11 clang-format-11 clangd-11 \ libfuzzer-11-dev lldb-11 lld-11 libc++-11-dev libc++abi-11-dev libomp-11-dev -y Make Clang 11 and everything related to it defaults</description>
    </item>
    <item>
      <title>每天学命令-chown 修改文件拥有者</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chown%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E6%8B%A5%E6%9C%89%E8%80%85/</link>
      <pubDate>Sun, 04 Dec 2022 16:32:59 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chown%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E6%8B%A5%E6%9C%89%E8%80%85/</guid>
      <description>chown 命令用来变更文件或目录的拥有者或所属群组，通过 chown 改变文件的拥有者和群组。用户可以是用户名或者用户 ID；组可以是组名或者组 ID；文件是以空格分开的文件列表，文件名也支持通配符。
命令格式 chown [选项] [用户或组] [文件或目录] -c或--changes #效果类似“-v”参数，但仅回报更改的部分； -f或--quite或—-silent #不显示错误信息； -h或--no-dereference #只对符号连接的文件作修改，而不更改其他任何相关文件； -R或--recursive #递归处理，将指定目录下的所有文件及子目录一并处理； -v或--version #显示指令执行过程； --dereference #效果和“-h”参数相同； --help #在线帮助 --reference=&amp;lt;参考文件或目录&amp;gt; #把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同； --version #显示版本信息。 实例 将文件test.md拥有者改为nic
chown nic test.md 将目录/home/nic/develop及其下面的所有文件、子目录的文件拥有者改为nic
chown -R nic /home/nic/develop </description>
    </item>
    <item>
      <title>每天学命令-tree 显示目录结构</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-tree%E6%98%BE%E7%A4%BA%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 04 Dec 2022 16:31:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-tree%E6%98%BE%E7%A4%BA%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</guid>
      <description>-a #显示所有文件 -d #只显示目录（名称） -l #显示链接文件的原始文件 -f #显示所列出的文件或目录的完整目录路径 -i #不以阶梯的形式显示文件或目录名称 -q #将控制字符以?字符代替，显示文件和目录名称 -N #直接显示文件或目录的名称 -p #显示每个文件的权限信息 -u #显示文件所有者或者uid -g #显示文件所属组或者gid -s #显示每个文件的大小信息 -h #以可读的方式显示文件的大小信息 -D #显示最后修改日期 -v #按字母数字正序显示文件 -r #按字母数字倒序显示文件 -t #按最后时间排序显示文件 -C #在文件和目录列表上加上色彩，便于区分文件类型 -P pattern #只显示匹配正则表式的文件或目录名称 -I pattern #与上结果相反 实例 显示当前目录及其子目录下的文件及目录名称
$ tree . ├── CODE_OF_CONDUCT.md ├── CONTRIBUTING.md ├── Fedora-35 │ ├── Dockerfile │ └── Readme.md ├── LICENSE ├── README.md ├── Ubuntu-20 │ ├── Dockerfile │ ├── Readme.md │ ├── init_edkrepo_conf.</description>
    </item>
    <item>
      <title>CodeReview 中常见缩写</title>
      <link>http://localhost:8888/posts/codereview%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%BC%A9%E5%86%99/</link>
      <pubDate>Sat, 03 Dec 2022 19:55:07 +0000</pubDate>
      <guid>http://localhost:8888/posts/codereview%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%BC%A9%E5%86%99/</guid>
      <description>ASAP: As Soon As Possible. 请尽快完成 ACK: Acknowledgement. 承认，同意。表示接受代码的改动 CR: Code Review. 请求代码审查 CCN: Code Comments Needed.需要的代码注释：在这里有一些简短的注释在高层次上描述每个主要代码块的作用（例如，“处理 HTTP 请求中的标头”）会很有帮助 DOODOO: Documentation Out Of Date Or Obsolete.文档过时或过时：此文档似乎不正确：是否过时？ DNM: Do not merge. 不要合并 ditto: 多个重复的表述，下一次可以用 ditto 表示同上 IMO: In My Opinion 在我看来、依我看、依我所见 LGT1: Looks Good To 1. 如果有一个回复 LGTM 则可以添加为 LGT1，1 代表目前有 1 个赞 LGT2: Looks Good To 2. 如果有两个回复 LGTM 则可以添加为 LGT2，2 代表目前有 2 个赞 LGTM: Looks Good To Me. 代码已经过 review，可以合并 MCE: Must Check for Errors.</description>
    </item>
    <item>
      <title>OFFICE-解决 Word 编辑卡顿</title>
      <link>http://localhost:8888/posts/office-%E8%A7%A3%E5%86%B3word%E7%BC%96%E8%BE%91%E5%8D%A1%E9%A1%BF/</link>
      <pubDate>Sat, 03 Dec 2022 19:01:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/office-%E8%A7%A3%E5%86%B3word%E7%BC%96%E8%BE%91%E5%8D%A1%E9%A1%BF/</guid>
      <description>打开 Word 很快，但是一编辑就特别卡，尤其时拖动表格时几乎是逐帧移动。这是硬件图形加速问题。解决方式如下。
打开 Word，点击左上角—&amp;gt;文件—&amp;gt;选项—&amp;gt;高级，一直拉到“显示”； 勾选禁用硬件图形加速； 取消勾选子像素定位平滑屏幕上的字体。 </description>
    </item>
    <item>
      <title>Git clone下来的分支不完整</title>
      <link>http://localhost:8888/posts/git-clone%E4%B8%8B%E6%9D%A5%E7%9A%84%E5%88%86%E6%94%AF%E4%B8%8D%E5%AE%8C%E6%95%B4/</link>
      <pubDate>Sat, 03 Dec 2022 18:52:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/git-clone%E4%B8%8B%E6%9D%A5%E7%9A%84%E5%88%86%E6%94%AF%E4%B8%8D%E5%AE%8C%E6%95%B4/</guid>
      <description>将仓库git clone到本地后发现本地缺失了一些远程仓库的分支。一般发生在git clone —depth 1设置克隆深度时发生。因为有些大型项目一次性克隆容易出错，所以只克隆一层深度。
如远程有分支branch_a，克隆下来后使用git branch -av命令查看所有分支没有显示该分支，该如何解决？
git remote set-branches origin &amp;#39;branch_a&amp;#39; git fetch -v </description>
    </item>
    <item>
      <title>手把手教你向开源社区提 Patch</title>
      <link>http://localhost:8888/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%90%91%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8F%90patch/</link>
      <pubDate>Sun, 20 Nov 2022 15:11:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%90%91%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8F%90patch/</guid>
      <description>提交补丁的最佳实践 本文翻译自官方教程Git - MyFirstContribution，原文包含开发到提交的整个周期。但是想要提交的人应该都已经开发完代码了，所以本文用自己的实际例子重新写了一遍，省去了开发代码等流程，重点介绍如何使用 git send-email。
环境准备 下载 OpenSBI 仓库 git clone https://github.com/riscv-software-src/opensbi.git cd opensbi 安装依赖 要从源代码构建 OpenSBI：
make 注：OpenSBI 的构建是可并行的。上面的命令可以添加-j#参数，如-j12。
确认要解决的问题 在本文档中，我们将模拟提交一个简单的 Patch，.gitignore文件可以过滤不必要的文件，现在使用 VSCode 的用户越来越多，使用 VSCode 开发时常常会生成.vscode目录，但是这些文件不该被推送至远程，原仓库中的.gitignore文件中没有过滤该文件，我们给他加上。
为了能够模拟一次发送多个commit的场景，我们将再添加一个.so用来过滤编译过程中生成的.so文件。
建立工作空间 让我们先建立一个开发分支来进行我们的修改。
git checkout -b update_gitignore origin/master 我们将在这里做一些提交，以演示如何将一个带有多个补丁的主题同时送审。
实现代码 过滤 .vscode 打开文件.gitignore，为该文件添加/.vscode/：
# Object files *.o *.a *.dep #Build &amp;amp; install directories build/ install/ # Development friendly files tags cscope* /.vscode/ 为以上修改做一次提交：
$ git status On branch update_gitignore Your branch is up to date with &amp;#39;origin/master&amp;#39;.</description>
    </item>
    <item>
      <title>更换 Debian 软件更新源</title>
      <link>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2debian%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</link>
      <pubDate>Sat, 05 Nov 2022 09:27:52 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2debian%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</guid>
      <description>确认 Debian 版本 $ cat /etc/os-release PRETTY_NAME=&amp;#34;Debian GNU/Linux 10 (buster)&amp;#34; NAME=&amp;#34;Debian GNU/Linux&amp;#34; VERSION_ID=&amp;#34;10&amp;#34; VERSION=&amp;#34;10 (buster)&amp;#34; VERSION_CODENAME=buster ID=debian HOME_URL=&amp;#34;https://www.debian.org/&amp;#34; SUPPORT_URL=&amp;#34;https://www.debian.org/support&amp;#34; BUG_REPORT_URL=&amp;#34;https://bugs.debian.org/&amp;#34; 括号里的buster就是版本信息。
获取镜像地址 打开debian | 清华大学开源软件镜像站，选择buster版本，复制所有镜像地址。
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free deb https://mirrors.</description>
    </item>
    <item>
      <title>QEMU&#39;s instance_init() vs. realize()</title>
      <link>http://localhost:8888/posts/qemu-s-instance-init-vs-realize/</link>
      <pubDate>Tue, 01 Nov 2022 09:51:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu-s-instance-init-vs-realize/</guid>
      <description>转载自huth (Thomas Huth)的一篇文章，原文已经 404，从网页快照中找回的文章。
Note that this is a blog post for (new) QEMU developers. If you are just interested in using QEMU, you can certainly skip this text. Otherwise, in case you have ever been in touch with the QEMU device model (&amp;ldquo;qdev&amp;rdquo;), you are likely aware of the basic qdev code boilerplate already:
static void mydev_realize(DeviceState *dev, Error **errp) { } static void mydev_instance_init(Object *obj) { } static Property mydev_properties[] = { DEFINE_PROP_xxx(&amp;#34;myprop&amp;#34;, MyDevState, field, .</description>
    </item>
    <item>
      <title>ZH-UEFI 规范 -1-引言</title>
      <link>http://localhost:8888/posts/zh-uefi%E8%A7%84%E8%8C%83-1-%E5%BC%95%E8%A8%80/</link>
      <pubDate>Tue, 18 Oct 2022 20:07:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-uefi%E8%A7%84%E8%8C%83-1-%E5%BC%95%E8%A8%80/</guid>
      <description>引言 统一可扩展固件接口 (UEFI) 规范描述了操作系统和平台固件之间的接口。UEFI 之前是可扩展固件接口规范 1.10 (EFI)。因此，一些代码和某些协议名称保留了 EFI 名称。除非另有说明，本规范中的 EFI 名称可假定为 UEFI 的一部分。
该接口采用数据表的形式，其中包含与平台相关的信息，以及可供 OS 加载程序和 OS 使用的引导和运行时服务调用。它们共同提供了一个引导操作系统的标准环境。本规范是作为一个纯粹的接口规范设计的。因此，该规范定义了平台固件必须实现的接口和结构集。类似地，该规范定义了操作系统在引导时可能使用的一组接口和结构。无论是固件开发者选择如何实现所需的元素，还是操作系统开发者选择如何利用这些接口和结构，都由开发者自己决定。
该规范的目的是定义一种方法，使操作系统和平台固件仅通信支持操作系统引导过程所必需的信息。这是通过平台和固件提供给操作系统的软件可见接口的正式和完整的抽象规范来实现的。
本规范的目的是为操作系统和平台固件定义一种方式，以仅传递支持操作系统启动过程所需的信息。这是通过平台和固件呈现给操作系统的软件可见接口的抽象规范来实现的。
使用这一正式定义，旨在运行在与受支持的处理器规范兼容的平台上的收缩包装操作系统将能够在各种系统设计上启动，而无需进一步的平台或操作系统定制。该定义还允许平台创新引入新特性和功能，以增强平台的能力，而不需要按照操作系统的引导顺序编写新代码。
此外，抽象规范开辟了一条替代遗留设备和固件代码的路径。新的设备类型和相关代码可以通过相同定义的抽象接口提供同等的功能，同样不会影响 OS 引导支持代码。
该规范适用于从移动系统到服务器的所有硬件平台。该规范提供了一组核心服务以及一组协议接口。协议接口的选择可以随着时间的推移而发展，并针对不同的平台市场细分进行优化。与此同时，该规范允许 oem 提供最大限度的可扩展性和定制能力，以实现差异化。在这方面，UEFI 的目的是定义一个从传统的“PC-AT”风格的引导世界到一个没有遗留 API 的环境的进化路径。
UEFI 驱动模型扩展 对启动设备的访问是通过一系列的协议接口提供的。UEFI 驱动模型的一个目的是为 &amp;ldquo;PC-AT&amp;quot;式的 Option ROM（TODO）提供一个替代品。需要指出的是，写在 UEFI 驱动模型上的驱动，被设计为在预启动环境中访问启动设备。它们并不是为了取代高性能的、针对操作系统的驱动程序。
UEFI 驱动模型被设计为支持执行模块化的代码，也被称为驱动，在预启动环境中运行。这些驱动程序可以管理或控制平台上的硬件总线和设备，也可以提供一些软件衍生的、平台特定的服务。
UEFI 驱动模型还包含了 UEFI 驱动编写者所需的信息，以设计和实现平台启动 UEFI 兼容的操作系统可能需要的任何总线驱动和设备驱动的组合。
UEFI 驱动模型被设计为通用的，可以适应任何类型的总线或设备。UEFI 规范描述了如何编写 PCI 总线驱动程序、PCI 设备驱动程序、USB 总线驱动程序、USB 设备驱动程序和 SCSI 驱动程序。提供了允许将 UEFI 驱动程序存储在 PCI Option ROM 中的其他详细信息，同时保持了与旧 Option ROM 镜像的兼容性。
UEFI 规范的一个设计目标是使驱动镜像尽可能的小。然而，如果一个驱动程序需要支持多个处理器架构，那么也需要为每个支持的处理器架构提供一个驱动程序对象文件。为了解决这个空间问题，本规范还定义了 EFI 字节代码虚拟机（EFI Byte Code Virtual Machine）。一个 UEFI 驱动可以被编译成一个 EFI 字节代码对象文件。UEFI Specification-complaint（TODO）的固件必须包含一个 EFI 字节代码解释器。这使得支持多种处理器架构的单一 EFI 字节代码对象文件可以被运出。另一种节省空间的技术是使用压缩。该规范定义了压缩和解压算法，可用于减少 UEFI 驱动程序的大小，从而减少 UEFI 驱动程序存储在 ROM 设备中时的开销。</description>
    </item>
    <item>
      <title>解决 VSCode 远程登录失败 Error: WebSocket close with status code 1006</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vscode%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5error-websocket-close-with-status-code-1006/</link>
      <pubDate>Sat, 15 Oct 2022 18:53:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vscode%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5error-websocket-close-with-status-code-1006/</guid>
      <description>保留现场 使用 VSCode 远程登录失败，报错：Failed to connect to the remote extension host server (Error: WebSocket close with status code 1006)。
解决方法 vim /etc/ssh/sshd_config AllowTcpForwarding no AllowAgentForwarding no # 替换为 AllowTcpForwarding yes AllowAgentForwarding yes 保存后重启 sshd 服务：
systemctl restart sshd </description>
    </item>
    <item>
      <title>如何使用 GitHub Actions</title>
      <link>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8github-actions/</link>
      <pubDate>Fri, 14 Oct 2022 22:08:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8github-actions/</guid>
      <description>简介 GitHub Actions 是 GitHub 在 2018 年推出的持续集成服务。它可以自动完成一些开发周期内的任务，如 Push 代码时自动编译，Pull 代码时自动执行测试脚本等等。
我了解 GitHub Actions 的契机是，我在 GitHub 上保存了一些 Markdown 文档，我希望每次更新文档后自动使用 Pandoc 转换成 PDF 文档。接下来我们一起学习如何通过 GitHub Actions 实现这样的需求。
首先我们先直观的了解一下它在 GitHub 的位置，如果打开一个仓库，它有图中绿色对号√，或者红色叉号×，说明这个项目配置了 GitHub Actions，绿色表示自动化的流程运行成功了，红色表示失败了。
我们点开Actions按钮就可以查看具体的任务详情。下面我们先学习如何配置一个简单的 GitHub Actions。
配置 GitHub Actions GitHub Actions 可以简单理解为一些自动化脚本，工具，目的就是为了减少重复工作，所以这些工具都可以做成普适性的工具。而 GitHub 官方就开放了一个这类工具的市场，我们可以在上面搜索自己想要的工具。因为初学 GitHub Actions 所以也不知道怎么写配置文件，我们可以直接搜索一个并应用它，看看别人是怎么写的。
我们进入一个自己的仓库，点击Actions，搜索框中搜索PDF，在搜索结果中找到Create PDF · Actions这个工具。如果搜索到点击Configure。如果显示未找到，则点击set up a workflow yourself，同样搜索PDF。
打开详情页面，拉到底，将Example usage。里的内容复制到编辑框中。点击右上角Start commit将会把我们新建的main.yml提交到仓库中。这就相当于创建了一个生成 PDF 的 GitHub Actions。当然每个 Actions 都有一些使用要求，比如这里还要根据介绍，创建几个文件夹，比如从哪个文件夹获取源文件，生成后的 PDF 又会放到哪个文件夹等。这里就不再介绍，我们先了解如何创建一个 Actions。
Workflow 配置 GitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的.</description>
    </item>
    <item>
      <title>加密算法总结</title>
      <link>http://localhost:8888/posts/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Mon, 10 Oct 2022 13:44:32 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
      <description>基本概念 明文与密文 Plaintext，明文，未经加密的消息，任何人都可以读 Ciphertext，密文，加密后的消息，不可读 Key，密钥，用于加密和解密（核心是算法） 加密与解密概念 加密 数据加密 的基本过程，就是对原来为 明文 的文件或数据按 某种算法 进行处理，使其成为 不可读 的一段代码，通常称为“密文”。通过这样的途径，来达到 保护数据 不被 非法人窃取、阅读的目的。
解密 加密 的 逆过程 为 解密，即将该 编码信息 转化为其 原来数据 的过程。
对称加密和非对称加密 加密算法分 对称加密 和 非对称加密，其中对称加密算法的加密与解密 密钥相同，非对称加密算法的加密密钥与解密 密钥不同，此外，还有一类 不需要密钥 的 散列算法。
对称加密 对称加密算法 是应用较早的加密算法，又称为 共享密钥加密算法。在 对称加密算法 中，使用的密钥只有一个，发送 和 接收 双方都使用这个密钥对数据进行 加密 和 解密。这就要求加密和解密方事先都必须知道加密的密钥。
数据加密过程：在对称加密算法中，数据发送方 将 明文 (原始数据) 和 加密密钥 一起经过特殊 加密处理，生成复杂的 加密密文 进行发送。
数据解密过程：数据接收方 收到密文后，若想读取原数据，则需要使用 加密使用的密钥 及相同算法的 逆算法 对加密的密文进行解密，才能使其恢复成 可读明文。
非对称加密 非对称加密算法，又称为 公开密钥加密算法。它需要两个密钥，一个称为 公开密钥 (public key)，即 公钥，另一个称为 私有密钥 (private key)，即 私钥。 因为 加密 和 解密 使用的是两个不同的密钥，所以这种算法称为 非对称加密算法。</description>
    </item>
    <item>
      <title>如何使用 git-send-mail 给开源社区提交 Patch</title>
      <link>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8git-send-mail%E7%BB%99%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8F%90%E4%BA%A4patch/</link>
      <pubDate>Wed, 28 Sep 2022 21:08:29 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8git-send-mail%E7%BB%99%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E6%8F%90%E4%BA%A4patch/</guid>
      <description>需求背景 如果参与 Linux、QEMU 或者 OpenSBI 等开源项目，不能通过在 GitHub 或者 Gitlab 平台提交pull request。而是需要将修改的代码，通过 Patch 形式提交到对应的listserv供 Maintainer 审核。那么如何创建 Patch 并发送呢？
这里以向 OpenSBI 提交一个 Patch 为例。
创建 Patch 首先将官方 Repository，Fork 到自己的 GitHub：
回到自己的主页，找到刚刚 Fork 的 Repository，将其 Clone 到本地：
修改代码与正常开发流程一直，修改完在git commit时需要加上Signed-off-by字段，因为 Merge 代码的人通常不是提交代码的人，有该字段才能证明是你修改了对应的代码。
-s参数会自动加上Signed-off-by字段：
$ git commit -s doc:fix some typos Signed-off-by: dominic &amp;lt;dominic@gmail.com&amp;gt; # Please enter the commit message for your changes. Lines starting # with &amp;#39;#&amp;#39; will be ignored, and an empty message aborts the commit.</description>
    </item>
    <item>
      <title>Makefile 基础</title>
      <link>http://localhost:8888/posts/makefile%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Mon, 26 Sep 2022 21:36:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/makefile%E5%9F%BA%E7%A1%80/</guid>
      <description>目标、依赖、命令 目标就是我们要去 make xxx 的那个 xxx，就是我们最终要生成的东西。 依赖是用来生成目录的原材料 命令就是加工方法，所以 make xxx 的过程其实就是使用命令将依赖加工成目标的过程。 通配符 % 和 Makefile 自动推导 % 是 Makefile 中的通配符，代表一个或几个字母。也就是说%.o就代表所有以.o为结尾的文件。 所谓自动推导其实就是 Makefile 的规则。当 Makefile 需要某一个目标时，他会把这个目标去套规则说明，一旦套上了某个规则说明，则 Makefile 会试图寻找这个规则中的依赖，如果能找到则会执行这个规则用依赖生成目标。 Makefile 中定义和使用变量 Makefile 中定义和使用变量，和 shell 脚本中非常相似。相似的是都没有变量类型，直接定义使用，引用变量时用$var。 伪目标（.PHONY） 伪目标意思是这个目标本身不代表一个文件，执行这个目标不是为了得到某个文件或东西，而是单纯为了执行这个目标下面的命令。 伪目标一般都没有依赖，因为执行伪目标就是为了执行目标下面的命令。既然一定要执行命令了那就不必加依赖，因为不加依赖意思就是无条件执行。 伪目标可以直接写，不影响使用；但是有时候为了明确声明这个目标是伪目标会在伪目标的前面用.PHONY来明确声明它是伪目标。 Makfile 中引用其他 Makefile 有时候 Makefile 总体比较复杂，因此分成好几个 Makefile 来写。然后在主 Makefile 中引用其他的，用 include 指令来引用。引用的效果也是原地展开，和 C 语言中的头文件包含非常相似。 赋值 =最简单的赋值 :=一般也是赋值 以上这两个大部分情况下效果是一样的，但是有时候不一样。用=赋值的变量，在被解析时他的值取决于最后一次赋值时的值，所以你看变量引用的值时不能只往前面看，还要往后面看。用:=来赋值的，则是就地直接解析，只用往前看即可。
?=如果变量前面并没有赋值过则执行这条赋值，如果前面已经赋值过了则本行被忽略。（实验可以看出：所谓的没有赋值过其实就是这个变量没有被定义过） +=用来给一个已经赋值的变量接续赋值，意思就是把这次的值加到原来的值的后面，有点类似于 strcat。（注意一个细节，+=续接的内容和原来的内容之间会自动加一个空格隔开） 注意：Makefile 中并不要求赋值运算符两边一定要有空格或者无空格，这一点比 shell 的格式要求要松一些。
Makefile 的环境变量 makefile 中用 export 导出的就是环境变量。一般情况下要求环境变量名用大写，普通变量名用小写。 环境变量和普通变量不同，可以这样理解：环境变量类似于整个工程中所有 Makefile 之间可以共享的全局变量，而普通变量只是当前本 Makefile 中使用的局部变量。所以要注意：定义了一个环境变量会影响到工程中别的 Makefile 文件，因此要小心。 Makefile 中可能有一些环境变量可能是 makefile 本身自己定义的内部的环境变量或者是当前的执行环境提供的环境变量（譬如我们在 make 执行时给 makefile 传参。make CC=arm-linux-gcc，其实就是给当前 Makefile 传了一个环境变量 CC，值是 arm-linux-gcc。我们在 make 时给 makefile 传的环境变量值优先级最高的，可以覆盖 makefile 中的赋值）。这就好像 C 语言中编译器预定义的宏__LINE__ __FUNCTION__等一样。 Makefile 中使用通配符 *：若干个任意字符 ?</description>
    </item>
    <item>
      <title>嵌入式 Shell 基础</title>
      <link>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Fshell%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Sun, 25 Sep 2022 22:35:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Fshell%E5%9F%BA%E7%A1%80/</guid>
      <description>脚本语言 常用的脚本语言有 sh、bash、csh、ksh、perl、python； 在 Linux 下常用的脚本语言其实就是 bash、sh； 脚本语言一般在嵌入式中应用，主要是用来做配置。（一个复杂的嵌入式程序都是可配置的，配置过程就是用脚本语言来实现的）自然不会使用过于复杂的脚本语言特性，因此只需要针对性的学习即可。 shell 脚本的运行机制 C/C++ 语言这种编写过程是：编写出源代码（源代码是不能直接运行的）然后编译链接形成可执行二进制程序，然后才能运行；而脚本程序不同，脚本程序编写好后源代码即可直接运行（没有编译链接过程）； shell 程序是解释运行的，所谓解释运行就是说当我们执行一个 shell 程序时，shell 解析器会逐行的解释 shell 程序代码，然后一行一行的去运行。（顺序结构） CPU 实际只认识二进制代码，根本不认识源代码。脚本程序源代码其实也不是二进制代码，CPU 也不认识，也不能直接执行。只不过脚本程序的编译链接过程不是以脚本程序源代码为单位进行的，而是在脚本运行过程中逐行的解释执行时才去完成脚本程序源代码转成二进制的过程（不一定是编译链接，因为这行脚本程序可能早就编译连接好了，这里我们只是调用它）。 动手写第一个 shell 编辑器与编译器 shell 程序是文本格式的，只要是文本编辑器都可以。但是因为我们的 shell 是要在 Linux 系统下运行的，所以换行符必须是\n，而 Windows 下的换行符是\r\n，因此 Windows 中的编辑器写的 shell 不能在 Linux 下运行。 编译器不涉及，因为 shell 是解释性语言，直接编辑完就可以运行。 shell 程序运行的运行的三种方法 ./xx.sh，和运行二进制可执行程序方法一样。这样运行 shell 要求 shell 程序必须具有可执行权限。chmod a+x xx.sh 来添加可执行权限。 source xx.sh，source 是 Linux 的一个命令，这个命令就是用来执行脚本程序的。这样运行不需要脚本具有可执行权限。 bash xx.sh，bash 是一个脚本程序解释器，本质上是一个可执行程序。这样执行相当于我们执行了 bash 程序，然后把 xx.sh 作为 argv[1] 传给他运行。 hello world 程序和解释 shell 程序的第一行一般都是以#!</description>
    </item>
    <item>
      <title>每天学命令-chattr 修改文件与目录属性防止误删除</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chattr%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E5%B1%9E%E6%80%A7%E9%98%B2%E6%AD%A2%E8%AF%AF%E5%88%A0%E9%99%A4/</link>
      <pubDate>Sun, 25 Sep 2022 11:20:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chattr%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E5%B1%9E%E6%80%A7%E9%98%B2%E6%AD%A2%E8%AF%AF%E5%88%A0%E9%99%A4/</guid>
      <description>使用背景 chattr命令可以修改 Linux 的文件属性，在类 Unix 等发行版中，该命令能够有效防止文件和目录被意外的删除或修改。文件在 Linux 中被描述为一个数据结构，chattr 命令在大多数现代 Linux 操作系统中是可用的，可以修改文件属性，一旦定义文件的隐藏属性，那么该文件的拥有者和 root 用户也无权操作该文件，只能解除文件的隐藏属性。这就可以有效的避免被误删除。
命令格式 一个完整的命令一般由命令 (chattr)，可选项 (option)，操作符 (operator) 与属性 (attribute) 组成：
chattr [option] [operator] [attribute] file [option] 可选项：
-R， 递归更改目录及其内容的属性。 -V， 详细说明chattr的输出并打印程序版本。 -f， 隐藏大多数错误消息。 [operator] 操作符：
+，追加指定属性到文件已存在属性中 -， 删除指定属性 =，直接设置文件属性为指定属性 [attribute] 属性如下：
a， 只能向文件中添加数据 A，不更新文件或目录的最后访问时间 i， 文件或目录不可改变 使用实例 lsattr 命令检查文件已有属性 -d：如果目标是目录，只会列出目录本身的隐藏属性，而不会列出所含文件或子目录的隐藏属性信息 -R：作用于目录时，会显示所有的子目录和文件的隐藏信息 $ lsattr clash --------------e------- clash/glados.yaml --------------e------- clash/clash-linux-386-v1.10.0 --------------e------- clash/Country.mmdb --------------e------- clash/cache.db --------------e------- clash/clash-linux-amd64-v1.10.0 --------------e------- clash/dashboard $ lsattr -d clash --------------e------- clash $ lsattr -R clash --------------e------- clash/glados.</description>
    </item>
    <item>
      <title>解决 Pandoc 将 MD 转换为 PDF 时报错 (error)\tightlist</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3pandoc%E5%B0%86md%E8%BD%AC%E6%8D%A2%E4%B8%BApdf%E6%97%B6%E6%8A%A5%E9%94%99-error-tightlist/</link>
      <pubDate>Sat, 24 Sep 2022 17:27:00 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3pandoc%E5%B0%86md%E8%BD%AC%E6%8D%A2%E4%B8%BApdf%E6%97%B6%E6%8A%A5%E9%94%99-error-tightlist/</guid>
      <description>使用 Pandoc 将test.md转换位 PDF 时，出现如下错误：
! Undefined control sequence. &amp;lt;recently read&amp;gt; \tightlist l.213 \end{frame} pandoc: Error producing PDF from TeX source make: *** [test.pdf] Error 43 这是因为在 Markdown 文件中使用-表示无序列表，被转化成了\tightlist但是 Pandoc 版本太老，不支持这个命令。（严格来说是 Pandoc 没有处理这个 LaTeX 命令，不是不支持，因为这是 LaTeX 命令和 Pandoc 没关系）。
有两种方式解决，一是升级 Pandoc 版本，二是将处理\tightlist的命令加到自己使用的模板中。
\providecommand{\tightlist}{% \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}} 或者
\def\tightlist{} </description>
    </item>
    <item>
      <title>Markdown 语法简明教程</title>
      <link>http://localhost:8888/posts/markdown%E8%AF%AD%E6%B3%95%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/</link>
      <pubDate>Sat, 24 Sep 2022 15:05:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/markdown%E8%AF%AD%E6%B3%95%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/</guid>
      <description>Markdown 简介 Markdown 是什么？ Markdown是一种轻量级标记语言，它以纯文本形式 (易读、易写、易更改) 编写文档，并最终以 HTML 格式发布。
Markdown也可以理解为将以 Markdown 语法编写的语言转换成 HTML 内容的工具。
谁创造了它？ 它由Aaron Swartz和John共同设计，Aaron Swartz就是那位于去年（2013 年 1 月 11 日）自杀，有着开挂一般人生经历的程序员。维基百科对他的介绍是：软件工程师、作家、政治组织者、互联网活动家、维基百科人。
14 岁参与 RSS 1.0 规格标准的制订。 2004年入读斯坦福，之后退学。 2005年创建Infogami，之后与Reddit合并成为其合伙人。 2010年创立求进会（Demand Progress），积极参与禁止网络盗版法案（SOPA）活动，最终该提案被撤回。 2011年 7 月 19 日，因被控从 MIT 和 JSTOR 下载 480 万篇学术论文并以免费形式上传于网络被捕。 2013年 1 月自杀身亡。 为什么要使用它？ 它是易读（看起来舒服）、易写（语法简单）、易更改纯文本。处处体现着极简主义的影子。 兼容 HTML，可以转换为 HTML 格式发布。 跨平台使用。 越来越多的网站支持 Markdown。 更方便清晰地组织你的电子邮件。（Markdown-here, Airmail） 摆脱 Word 怎么使用？ 如果不算扩展，Markdown 的语法绝对简单到让你爱不释手。
Markdown 语法主要分为如下几大部分：
标题，段落，区块引用，代码区块，强调，列表，分割线，链接，图片，反斜杠 \，符号&amp;rsquo;`&amp;rsquo;。
谁在用？ Markdown 的使用者：
GitHub 简书 Stack Overflow Apollo Moodle Reddit 等等 语法介绍 标题 两种形式：</description>
    </item>
    <item>
      <title>Markdown 表格竖线自动对齐</title>
      <link>http://localhost:8888/posts/markdown%E8%A1%A8%E6%A0%BC%E7%AB%96%E7%BA%BF%E8%87%AA%E5%8A%A8%E5%AF%B9%E9%BD%90/</link>
      <pubDate>Sat, 24 Sep 2022 15:01:41 +0000</pubDate>
      <guid>http://localhost:8888/posts/markdown%E8%A1%A8%E6%A0%BC%E7%AB%96%E7%BA%BF%E8%87%AA%E5%8A%A8%E5%AF%B9%E9%BD%90/</guid>
      <description>需求背景 Markdown 中的表格，只要符合语法就能够正常渲染显示，但是符合语法但是 Markdown 源码却不一定易读。就如以下的这个表格，可以正常显示，但是源码在源文件中竖线不对齐，就阅读困难。
源码：
|诗名|作者|朝代| |-|-|-| |白头吟|卓文君|两汉| |锦瑟|李商隐|唐代| |登科后|孟郊|唐代| 显示效果：
诗名 作者 朝代 白头吟 卓文君 两汉 锦瑟 李商隐 唐代 登科后 孟郊 唐代 我们可以手动将其竖线对齐，如下这样就易读许多：
| 诗名 | 作者 | 朝代 | | ------ | ------ | ---- | | 白头吟 | 卓文君 | 两汉 | | 锦瑟 | 李商隐 | 唐代 | | 登科后 | 孟郊 | 唐代 | 显示效果保持一致。但是如果一个字符一个字符去手动对齐效率太低，也不符合 Markdown 设计初衷。这就用到了额外的插件，能够辅助我们完成这个工作。
Markdown All in One VSCode 插件中心搜索Markdown All in One安装。</description>
    </item>
    <item>
      <title>ZH-The RISC-V Instruction Set Manual Volume 2-特权级架构</title>
      <link>http://localhost:8888/posts/zh-the-risc-v-instruction-set-manual-volume-2-%E7%89%B9%E6%9D%83%E7%BA%A7%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Thu, 22 Sep 2022 09:37:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-the-risc-v-instruction-set-manual-volume-2-%E7%89%B9%E6%9D%83%E7%BA%A7%E6%9E%B6%E6%9E%84/</guid>
      <description>Introduction Document Version 20211203
Control and Status Registers (CSRs) Machine-Level ISA, Version 1.12 本章介绍了机器模式（M-mode）中可用的机器级操作，这是 RISC-V 系统中最高权限的模式。M 模式用于对硬件平台的低级访问，是复位时进入的第一个模式。M 模式也可以用来实现那些在硬件中直接实现过于困难或成本高昂的功能。RISC-V 的机器级 ISA 包含一个共同的核心，根据支持的其他权限级别和硬件实现的其他细节来扩展。
Machine-Level CSRs 除了本节中描述的机器级 CSRs 外，M-mode 代码还可以访问较低特权级别的所有 CSRs。
Machine ISA Register misa misa CSR 是 WARL 读写寄存器，报告硬件 (hart) 支持的 ISA。该寄存器在任何实现中都必须是可读的，但是可以返回零值以指示未实现 misa 寄存器，这就需要通过一个单独的非标准机制确定 CPU 功能。
MXL（机器 XLEN）字段编码本机基本整数 ISA 宽度，如表 3.1 所示。MXL 字段在支持多个基本 ISA 宽度的实现中可能是可写的。M-mode 下的有效 XLEN, MXLEN，由 MXL 的设置给出，如果 misa 为零，则有一个固定的值。重置时，MXL 字段始终设置为最广泛支持的 ISA 变种。
misa CSR 为 MXLEN 位宽。如果从 misa 读取的值不为零，该值的 MXL 字段总是表示当前的 MXLEN。如果对 misa 的写操作导致 MXLEN 发生更改，则 MXL 的位置将以新的宽度移动到 misa 的最高有效两位。</description>
    </item>
    <item>
      <title>使用 Markdownlint 对 Markdown 文本格式检查</title>
      <link>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8markdownlint%E5%AF%B9markdown%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E6%A3%80%E6%9F%A5/</link>
      <pubDate>Sat, 17 Sep 2022 11:07:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8markdownlint%E5%AF%B9markdown%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E6%A3%80%E6%9F%A5/</guid>
      <description>Markdownlint 简介 Markdown 标记语言旨在易于阅读、编写和理解。它的灵活性既是优点也是缺点。语法众多，因此格式可能不一致。某些构造在所有解析器中都不能很好地工作，应该避免。CommonMark 规范标准化解析器。
Markdownlint 是一个用于 Node.js 的静态分析工具，有一个标准规范，用于强制执行 Markdown 文件的标准和一致性。
Markdownlint 插件使用 markdownlint提供了多种使用场景下的解决方案，如命令行，编辑器甚至 GitHub Action。因为我平时写 Markdown 文档都是使用 VSCode，所以介绍一下 VSCode 下的使用。其他编辑器包括 VIM，Sublime 也都支持，可以前往官网查阅方法。
VSCode 需要下载插件，Ctrl+Shift+X打开插件中心，搜索Markdownlint安装即可。
安装插件后打开 Markdown 文档，如果有不符合规范的语法将会警告标识。如，标题前后没有空行，将会标识：
提示违反了第 22 条规范，第 22 条规范的就是标题前后需要有空行隔开。
目前有 53 条规范，可以在markdownlint/Rules.md查看所有规范的内容。
当然这些规范也都可以自定义是否检查，比如第 24 条规定，文档内不可以有重复的标题，但是我就有重复标题的需求，那该如何关闭这个检查呢，Markdownlint 提供了配置的方式。
Ctrl+Shift+P打开运行窗口，输入 Markdownlint，找到Creat or open the markdownlint configuration file。
创建一个配置文件，并输入以下内容，表示关闭第 24 条规范的检查：
{ &amp;#34;MD024&amp;#34;: false, } 这样文档中将不会有第 24 条规范的检查警告，其他检查同理。
Markdownlint 自定义规则 MD001 - Heading levels should only increment by one level at a time 标题等级一次只能增加一级，不能跨级。</description>
    </item>
    <item>
      <title>VSCode 字体快速切换</title>
      <link>http://localhost:8888/posts/vscode%E5%AD%97%E4%BD%93%E5%BF%AB%E9%80%9F%E5%88%87%E6%8D%A2/</link>
      <pubDate>Mon, 12 Sep 2022 15:05:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E5%AD%97%E4%BD%93%E5%BF%AB%E9%80%9F%E5%88%87%E6%8D%A2/</guid>
      <description>需求背景 在写 MD 文档时为了追求美观，表格通常都是对齐的，这就需要字体必须等宽，但是写代码时等宽字体的因为很瘦小，不容易阅读，所以想要一个插件能够在多个字体直接快速切换。万能 VSCode 啥都有，插件中心就有一款专门切换字体的插件Font Switcher。直接搜索安装。
配置与使用 打开配置脚本settings.json，如果以前修改过字体，找到&amp;quot;editor.fontFamily&amp;quot;配置项，如果没有就直接添加。
这是我的字体，添加你们机器上安装的字体，每个逗号间隔都是不同的字体，可以使用Font Switcher切换，需要注意的是，字体名没有空格不需要加单引号，加了也无妨，如果有空格，一定要加引号。
&amp;#34;editor.fontFamily&amp;#34;: &amp;#34;&amp;#39;Sarasa Mono SC&amp;#39;, 微软雅黑，&amp;#39;Noto Sans Mono CJK SC&amp;#39;, &amp;#39;JetBrains Mono&amp;#39;, Consolas, monospace&amp;#34;, Ctrl+Shift+P打开运行窗口，输入Switch Font，选择切换的字体。如图：
![](https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img//2022/09/12/15-17-44-dd742307432154f630585e05a1f57956-GIF 2022-9-12 15-17-27-836285.gif)</description>
    </item>
    <item>
      <title>解决 Linux 终端回车键变成字符 M</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E9%94%AE%E5%8F%98%E6%88%90%E5%AD%97%E7%AC%A6m/</link>
      <pubDate>Mon, 12 Sep 2022 14:52:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E9%94%AE%E5%8F%98%E6%88%90%E5%AD%97%E7%AC%A6m/</guid>
      <description>保留现场 解决方法 命令行执行
stty sane </description>
    </item>
    <item>
      <title>Linux 下切换 Python 版本</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E4%B8%8B%E5%88%87%E6%8D%A2python%E7%89%88%E6%9C%AC/</link>
      <pubDate>Mon, 12 Sep 2022 14:05:17 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E4%B8%8B%E5%88%87%E6%8D%A2python%E7%89%88%E6%9C%AC/</guid>
      <description>需求背景 用过 Python 的都知道，Python 是不向后兼容的，也就是 Python3.X 开发的程序，使用 Python2.X 环境就无法正常运行。因为很多语法都改变了。现在接触到的大部分 Python 程序都是 Python3.X 开发的，但是偶尔也会遇到使用 Python2.X 的时候。这就需要灵活切换版本。
一般 Linux 的各个发行版都预装了 Python2.X。我使用的 Debian 就预装了 Python2.7。
$ python -V Python 2.7.16 但是我同时也安装了 Python3.7
$ ls /usr/bin | grep &amp;#34;python*&amp;#34; dh_python2 python python2 python2.7 python3 python3.7 python3.7m python3m alias 修改别名 $ alias python=/usr/bin/python3 $ python -V Python 3.7.3 上面的别名修改只对当前终端有效。如果要使每个窗口都使用这个别名，将别名加入~/.bashrc，如 zsh 是则是~/.zshrc。
软链接 和修改别名类似
ln -s python /usr/bin/python3 update-alternatives update-alternatives是 Debian 系统提供的一个工具，Ubuntu 是基于 Debian 的，所以 Ubuntu 也可以使用，其他发行版没有该工具。它可以用来方便快捷地切换应用版本，不仅仅用来切换 Python，其他应用程序有多个版本的也可以使用该工具。</description>
    </item>
    <item>
      <title>解决 Python No module named &#39;ConfigParser&#39;</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3python-no-module-named-configparser/</link>
      <pubDate>Sun, 11 Sep 2022 23:20:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3python-no-module-named-configparser/</guid>
      <description>保留现场 ImportError: No module named &amp;#39;ConfigParser&amp;#39; Command &amp;#34;python setup.py egg_info&amp;#34; failed with error code 1 in 解决方法 在 Python 3.x 版本后，ConfigParser.py 已经更名为 configparser.py 所以出错！
可以切换 Python2 执行。
也可以尝试将文件重命名为ConfigParser.py。
以下为参考，每个人安装路径可能不一样，可以全局搜索configparser.py。
cp /usr/lib/python3.7/configparser.py /usr/lib/python3.7/ConfigParser.py </description>
    </item>
    <item>
      <title>解决 LaTeX 编译 Missing character There is no (U&#43;00A0) in font</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3latex%E7%BC%96%E8%AF%91missing-character-there-is-no-u-00a0-u-00a0-in-font/</link>
      <pubDate>Sun, 11 Sep 2022 22:20:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3latex%E7%BC%96%E8%AF%91missing-character-there-is-no-u-00a0-u-00a0-in-font/</guid>
      <description>保留现场 在 LaTeX 编译中报错：Missing character: There is no (U+00A0) (U+00A0) in font JetBrains Mono。
探究原因 如果要搞清楚具体原因，就得从字符与字符编码说起了。解决办法直接跳到下一节吧。
字符，就是“a”，“A”，“你”等书写符号。
字符集，通常就是某种语言字符集合，比如英语就是ASCII 字符集，中文有GBK 字符集等
注意，不是每种语言只对应一种字符集（比如 GB2312，GBK，GB18030 都包含了常用汉字，后者是前者的超集），而且字符集也不是只对应一种语言，例如 Unicode 字符集就包含所有语言字符，字符集只是设计者为了给字符编码（Code Point/Numbering）设计编码时，为了收录到命名的字符集合，但是通常设计者都为字符集设计了对应的编码规范。
字符编码,给字符集里的字符编号。
编码页，在 unicode 发明之前，各个地区都用 2 字节编码自己的字符集，相同的编码对应不同的字符，为了本地化，Windows 发明了编码页，来对应不同的字符集。
字符编码，对给定的字符编码编码成字节表示。
早期，字符被编号后，存储时就按照编号的方式存储，没有 encoding 的过程，后来发明 Unicode 后，发现如果按照 Unicode 的编号直接存储的话，对于英文字符就有很大存储浪费，因为任意字符都需要 2 字节存储，后来人们发明 UTF-8 这种编码方式，这样 UTF-8 就可以一个字节表示英文字符，2 个以上字节表示汉字字符。
字体，定义了字符的图形表示，现在的软件展示字符时用 Unicode 表示，字体是 Unicode 编码和字符图形的映射，而以往比如 WindowsCMD 控制台，没有对应 Unicode，则用编码页来区分，所以字体就是字符编码金和代码页到字符图形的映射。
文本文件存储在磁盘上，都是一系列的字节流，如果不告诉文本编辑器该文件的编码方式，编辑器会尝试用默认的编码（依赖于操作系统设置）又或者自己探测（detect，比如文件开头有 FFEF 或者 EFFF 字节就表明 UTF-16 编码，有很多 10，110 开头的字节，很可能是 UTF-8 编码）并尝试解码，如果没有猜对，那就会显示乱码。
回到出错的问题，提示我们在字体 JetBrains Mono中没有U+00A0，我们搜索一下就知道这是一个 Unicode 字符NO-BREAK SPACE。我们通过上面的了解也知道了，字体就是字符编码到字符图像的映射，但是一个字体尤其是一些有专门用途的字体（比如 JetBrains Mono 设计初衷是为软件工程显示代码用的），它不会映射所有的字符，JetBrains Mono 这个字体里就没有映射 U+00A0。这就导致在 LaTeX 编译时无法在字体中找到对应的字符图像显示。</description>
    </item>
    <item>
      <title>每天学命令-nohup 后台运行</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-nohup%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/</link>
      <pubDate>Sat, 10 Sep 2022 17:14:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-nohup%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/</guid>
      <description>使用 MobaXertm 连接服务器后，想要在运行一个下载任务，使用&amp;amp;挂在后台后，退出 MobaXterm，后台的任务也随之中断，于是搜到这个nohup命令，可以完成我的需求。
nohup意思是 No Hang Up，不要挂起的意思，即使退出终端也不会中断任务。
为了方便以后查阅，这里总结一下关于后台运行相关的命令。首先是最常用的&amp;amp;符号。
&amp;amp; 后台运行 比如执行编译任务时通常会占用终端前台，这时候无法再执行其他命令，除非再开一个终端，对于有 GUI 界面时，再开一个终端很方便，但是如果是服务器就只能再想办法了。 &amp;amp;可以将命令执行过程放在后台运行，如：
$ make &amp;gt; make.log 2&amp;gt;&amp;amp;1 &amp;amp; [1] 16586 2&amp;gt;&amp;amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了make.log文件，即将标准出错也输出到make.log文件中。最后一个&amp;amp;，是让该命令在后台执行。 试想2&amp;gt;1代表什么，2与&amp;gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&amp;gt;&amp;amp;1，&amp;amp;与1结合就代表标准输出了，就变成错误重定向到标准输出。
在后台运行make进行编译，并将输出结果（错误和正常输出）都保存到make.log文件中，提交任务成功后，会显示进程 ID，编译的进程 ID 为 16586。
有了进程 ID 我们可以监控，也可以中断进程：
# 查看进程状态 ps -ef | grep 16586 # 中断进程 kill -9 16586 但是使用 &amp;amp;时关闭终端后，进程也会随之关闭。如果想要在后台持续运行程序，就需要nohup命令。
nohup 使用 $ nohup make &amp;gt; make.log 2&amp;gt;&amp;amp;1 &amp;amp; [1] 112233 命令功能同上，但是终端关闭，后台程序也会继续执行。
NOTE：终端关闭，是指带 GUI 的界面里终端，如果使用 SSH 等登陆，比如使用 MobaXterm，一个 session 相当于一个登陆账户，如果异常退出了这个账户，那么后台执行的程序也会中断。如果需要继续执行，需要正常退出账户，执行exit命令。
汇总 fg # 将后台中的命令调至前台继续运行 bg # 将一个在后台暂停的命令，变成继续执行 (在后台执行) jobs # 查看当前有多少在后台运行的命令 kill %num # 终止进程num &amp;amp; # 加在命令后可以将其置于后台运行 ctrl + z # 置于后台，并且暂停不可执行 ctrl + c # 终止前台进程 ctrl + \ # 退出 ctrl + d # 结束当前输入(即用户不再给当前程序发出指令)，那么Linux通常将结束当前程序 </description>
    </item>
    <item>
      <title>从零开始搭建一台 NAS 存储服务器</title>
      <link>http://localhost:8888/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0nas%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Sat, 10 Sep 2022 11:37:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0nas%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>技术没学多少，教程下满了硬盘，一直想专门部署 NAS 来存文件，但是一来要花钱，二来搭建 NAS 没有经验怕部署不好，没有现在硬盘直连舒适，所以将就用吧。
自从有天忘了忘了休眠电脑，一个自动备份任务开启，在 40 度的高温天，满速跑了一天，下班回来硬盘直接报废。这就加速我折腾部署 NAS 的进程。
准备阶段 威联通的几款中意的 NAS 放购物车很久了，如果硬盘没有这么早坏掉，可能在双十一就买整机了，现在离双十一还早，硬件价格都不便宜，想来想去还是买二手硬件攒一台更划算。如果买整机，硬盘加 NAS 主机就得五千大洋，只是用来存文件，部署个 Jellyfin 看电影用，属实奢侈了。
￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥
买二手就得从零开始学。生命不休，折腾不止。经过一次完整的 NAS 攒机过程发现，其实 NAS 就是安装了专用系统的一台电脑而已。这个专用系统就是面向网络存储开发的，如群晖，威联通，开源的 OMV，FreeNAS 等等。
既然是一台电脑，其实攒 NAS 就和攒电脑一样，选配好以下几大件即可。
CPU 主板 散热器 机箱 内存 电源 机箱风扇 下面分别介绍在攒机过程中遇到的一些概念，参数到底是什么意思。
CPU CPU 型号字母数字都是什么意思 Intel 是英特尔的英文名称，也是目前热门的 CPU 品牌； “酷睿”代表英特尔品牌下面向普通消费者的一个 CPU 系列，一般划分为 Core（酷睿）、Pentium（奔腾）、Celeron（赛扬）、Xeon（至强）、Atom（凌动）等； i5 代表这款 CPU 定位中端，在其下面还有 i3，在其上面还有 i7 和 i9，同一代中，数字越大，性能越强；但是不同代 - 数之间，性能不能直接相比，比如 12 代的 i5 在理论性能上是强于 10 代 i7 的。 12 代表这款 CPU 的代数，说明其已经发展到第十二代了，数字越大越新； 600 这三位数字代表 Intel SKU 型号划分，一般来说 Core i7 有固定几个 SKU，比方说 700；Core i5有600/500/400；Core i3有300/100等等，一般来说数字越大说明隶属的Core系列越高级，同级别下比较，数字越大频率越高，换句话说性能就越强，比方说Core i5-8600 默认 3.</description>
    </item>
    <item>
      <title>Linux 下使用 Clash 作代理并配置开机启动</title>
      <link>http://localhost:8888/posts/linux%E4%B8%8B%E4%BD%BF%E7%94%A8clash%E4%BD%9C%E4%BB%A3%E7%90%86%E5%B9%B6%E9%85%8D%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Sat, 10 Sep 2022 10:03:25 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E4%B8%8B%E4%BD%BF%E7%94%A8clash%E4%BD%9C%E4%BB%A3%E7%90%86%E5%B9%B6%E9%85%8D%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8/</guid>
      <description>下载安装 点击下载 Linux 版本的 Clash，下载完成后解压缩。
unzip clash-linux.zip sudo mv clash-linux /usr/local/bin/clash sudo chmod +x /usr/local/bin/clash 初步使用 下载配置文件，配置文件一般由订阅商（机场）提供，是一个 yaml 文件，编写了代理服务器的信息，以及访问规则等。这是最关键的一步。
clash-linux-amd64-v1.10.0 -f 从订阅商那获取的配置文件.ymal -d . 可以尝试在 Git clone 时使用代理，如果可以正常下载，说明代理配置成功。
git clone https://github.com/twbs/bootstrap.git --config &amp;#34;http.proxy=127.0.0.1:7890&amp;#34; # 即可正常下载 开机启动 cd ~ sudo cp /usr/local/bin/clash /etc/ sudo vim /etc/systemd/system/clash.service 添加如下内容，并保存：
[Unit] Description=Clash Daemon [Service] ExecStart=/usr/local/bin/clash -f /etc/clash/订阅的配置文件.yaml -d /etc/clash/ Restart=on-failure [Install] WantedBy=multi-user.target 启用 clash 服务
sudo systemctl enable clash.service 启动 clash 服务
sudo systemctl start clash.</description>
    </item>
    <item>
      <title>解决 No module named &#39;ConfigParser&#39;</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3no-module-named-configparser/</link>
      <pubDate>Mon, 05 Sep 2022 15:43:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3no-module-named-configparser/</guid>
      <description></description>
    </item>
    <item>
      <title>Linux 终端回车变成^M</title>
      <link>http://localhost:8888/posts/linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E5%8F%98%E6%88%90-m/</link>
      <pubDate>Mon, 05 Sep 2022 15:37:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E5%8F%98%E6%88%90-m/</guid>
      <description>解决方法 终端执行：
stty sane 参考 command line - Pressing enter produces ^M instead of a newline - Ask Ubuntu</description>
    </item>
    <item>
      <title>Linux 切换不同 Python 版本</title>
      <link>http://localhost:8888/posts/linux%E5%88%87%E6%8D%A2%E4%B8%8D%E5%90%8Cpython%E7%89%88%E6%9C%AC/</link>
      <pubDate>Mon, 05 Sep 2022 15:31:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%88%87%E6%8D%A2%E4%B8%8D%E5%90%8Cpython%E7%89%88%E6%9C%AC/</guid>
      <description></description>
    </item>
    <item>
      <title>HEXO 博客嵌入 PDF</title>
      <link>http://localhost:8888/posts/hexo%E5%8D%9A%E5%AE%A2%E5%B5%8C%E5%85%A5pdf/</link>
      <pubDate>Sat, 03 Sep 2022 17:01:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/hexo%E5%8D%9A%E5%AE%A2%E5%B5%8C%E5%85%A5pdf/</guid>
      <description>效果 下载 pdf.js 前往官网下载pdf.js。
为了保证兼容性，建议下载旧版：
添加 pdfjs 到主题中 将下载文件夹命名为 pdfjs，拷贝到 themes/fluid/source/myjs 中。myjs目录为自己新建目录。并将该目录skip_render。
打开 HEXO 的配置文件（不是主题的配置文件）_config.yml，搜索skip_render，配置如下：
skip_render: [myjs/**] 如果不配置该选项，嵌入的 PDF 将会带有博客主题边框。如图：
修改 viewer.js 直接使用下载的文件会报错：
Error: file origin does not match viewer&amp;#39;s 注释web/viewer.js文件中的相应内容：
使用方法 在 Markdown 文档中使用 &amp;lt;iframe&amp;gt; 控件配合pdf.js 库完成 pdf 显示
&amp;lt;iframe src=&amp;#39;/myjs/pdfjs/web/viewer.html?file=&amp;lt;src-to-pdf&amp;gt;&amp;#39; style=&amp;#39;width:100%;height:100%&amp;#39;&amp;gt;&amp;lt;/iframe&amp;gt; &amp;lt;src-to-pdf&amp;gt;：需要显示的 pdf 文件的链接 /myjs/pdfjs/web/viewer.html：改为自己的 pdfjs 目录 参考 Fluid -3- pdf.js PC，移动端查看 PDF - 又见苍岚 </description>
    </item>
    <item>
      <title>RISC-V 入门 - 系统调用</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</link>
      <pubDate>Mon, 29 Aug 2022 13:16:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</guid>
      <description>用户态与内核态 目前为止的学习过程中，所有的程序都是运行在 Machine 模式下，但是在哪决定程序运行在什么模式下的呢？
在学习抢占式多任务时，我们有了创建任务的概念，在汇编代码中有这么一段，使用到了mstatus寄存器：
# Notice: default mstatus is 0 # Set mstatus.MPP to 3, so we still run in Machine mode after MRET. # Set mstatus.MPIE to 1, so MRET will enable the interrupt. li t0, 3 &amp;lt;&amp;lt; 11 | 1 &amp;lt;&amp;lt; 7 csrr a1, mstatus # a1 = mstatus or t0, t0, a1 # t0 = t0 | a1 csrw mstatus, t0 # mstatus = t0 j start_kernel # hart 0 jump to c mret返回后，是根据寄存器mstatus的MPP来决定接来来是处于什么模式，我们在上面将MPP配置为3， MPP的功能是 记录 Machine 模式下，前一个，特权级。这里解实现了在mret之后将模式设置为 Machine 模式（3）。</description>
    </item>
    <item>
      <title>浏览器任务栏多窗口命名</title>
      <link>http://localhost:8888/posts/%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%A4%9A%E7%AA%97%E5%8F%A3%E5%91%BD%E5%90%8D/</link>
      <pubDate>Sun, 28 Aug 2022 08:56:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%A4%9A%E7%AA%97%E5%8F%A3%E5%91%BD%E5%90%8D/</guid>
      <description>需求 工作时需要开启多个标签页，在同一个窗口里打开又查找不变，于是分为多个窗口，每个窗口里的标签页工作内容一致。如所有文档放在一个窗口，需要百度，Google 搜索时用单独的一个问题搜索窗口。这样就避免每次打开窗口都要挨个点一遍。
Edge 设置 打开设置-更多工具 - 为窗口命名。即可重命名窗口
Chrome 设置 同上，路径基本一致都是在设置-更多工具中。
升级 在使用过程中发现窗口太多任务栏太挤了，Chrome 自身有标签分组的功能，其实完全可以替代窗口。也可以满足我的需求。少数派有介绍，就不造轮子了。体验一段时间确实很好用。</description>
    </item>
    <item>
      <title>VSCode 任务栏多窗口命名</title>
      <link>http://localhost:8888/posts/vscode%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%A4%9A%E7%AA%97%E5%8F%A3%E5%91%BD%E5%90%8D/</link>
      <pubDate>Sun, 28 Aug 2022 08:55:55 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%A4%9A%E7%AA%97%E5%8F%A3%E5%91%BD%E5%90%8D/</guid>
      <description>调教背景 当有多个项目同时打开时，VSCode 窗口开得太多就找不到自己想要打开的窗口，因为窗口命名默认按照当前打开的文件命名的，不是很清楚。就需要挨个打开才能确定自己想要打开的窗口。
如果能按照项目名命名窗口就会便捷许多，好在 VSCode 提供重命名的方式。同样的需求可能在浏览器中也会遇到，可以参考浏览器任务栏多窗口命名 - 如云泊。
修改方式 File -&amp;gt; Preferences -&amp;gt; Setting 搜索 Window: Title 改成：
${dirty}${rootName}${separator}${activeEditorMedium}${separator}${appName} 其他可用配置说明：
&amp;#34;${activeEditorShort}&amp;#34;: 文件名 (例如 myFile.txt)。&amp;#34;${activeEditorMedium}&amp;#34;: 相对于工作区文件夹的文件路径 (例如, myFolder/myFileFolder/myFile.txt)。&amp;#34;${activeEditorLong}&amp;#34;: 文件的完整路径 (例如 /Users/Development/myFolder/myFileFolder/myFile.txt)。&amp;#34;${activeFolderShort}&amp;#34;: 文件所在的文件夹名称 (例如, myFileFolder)。&amp;#34;${activeFolderMedium}&amp;#34;: 相对于工作区文件夹的、包含文件的文件夹的路径, (例如 myFolder/myFileFolder)。&amp;#34;${activeFolderLong}&amp;#34;: 文件所在文件夹的完整路径 (例如 /Users/Development/myFolder/myFileFolder)。&amp;#34;${folderName}&amp;#34;: 文件所在工作区文件夹的名称 (例如 myFolder)。&amp;#34;${folderpath}&amp;#34;: 文件所在工作区文件夹的路径 (例如 /Users/Development/myFolder)。&amp;#34;${rootName}&amp;#34;: 打开的工作区或文件夹的名称 (例如 myFolder 或 myWorkspace)。&amp;#34;${rootPath}&amp;#34;: 打开的工作区或文件夹的文件路径 (例如 /Users/Development/myWorkspace)。&amp;#34;${appName}&amp;#34;: 例如 VS Code。“${remoteName}”: 例如 SSH${dirty}: 表明活动编辑器具有未保存更改的时间的指示器。&amp;#34;${separator}&amp;#34;: 一种条件分隔符 (&amp;#34;-&amp;#34;), 仅在被包含值或静态文本的变量包围时显示 </description>
    </item>
    <item>
      <title>解决 ERROR Could not install packages due to an EnvironmentError 拒绝访问</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3error-could-not-install-packages-due-to-an-environmenterror-%E6%8B%92%E7%BB%9D%E8%AE%BF%E9%97%AE/</link>
      <pubDate>Sat, 27 Aug 2022 21:55:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3error-could-not-install-packages-due-to-an-environmenterror-%E6%8B%92%E7%BB%9D%E8%AE%BF%E9%97%AE/</guid>
      <description>保留现场 升级pip时出现报错：
解决方法 加上--user
python -m pip install --upgrade pip --user </description>
    </item>
    <item>
      <title>编码字体与阅读字体推荐</title>
      <link>http://localhost:8888/posts/%E7%BC%96%E7%A0%81%E5%AD%97%E4%BD%93%E4%B8%8E%E9%98%85%E8%AF%BB%E5%AD%97%E4%BD%93%E6%8E%A8%E8%8D%90/</link>
      <pubDate>Sat, 27 Aug 2022 19:59:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E7%BC%96%E7%A0%81%E5%AD%97%E4%BD%93%E4%B8%8E%E9%98%85%E8%AF%BB%E5%AD%97%E4%BD%93%E6%8E%A8%E8%8D%90/</guid>
      <description>编码字体 编码字体首要原则：等宽，等宽，还是 TMD 等宽！
JetBrains Mono Hack Source Code Pro Fira Mono Consolas 保底字体，基本上 Windows 电脑都有预装。
阅读字体 看多了黑体，其实有衬线的宋体才能体现中文文字之美。
思源宋体 华文中宋 中文等宽字体 对于既想要满足编程字体又想要中文书写的，有几款等宽中文字体也不错。
Sarasa Gothic / 更纱黑体 思源黑体/Source Han Sans </description>
    </item>
    <item>
      <title>多版本 Python 使用 pip 安装 package 问题</title>
      <link>http://localhost:8888/posts/%E5%A4%9A%E7%89%88%E6%9C%ACpython%E4%BD%BF%E7%94%A8pip%E5%AE%89%E8%A3%85package%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 27 Aug 2022 15:30:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%A4%9A%E7%89%88%E6%9C%ACpython%E4%BD%BF%E7%94%A8pip%E5%AE%89%E8%A3%85package%E9%97%AE%E9%A2%98/</guid>
      <description>最简单的方式 使用参数指定安装路径：
pip install -t D:\python3.5(32bit)\Lib\site-packages numpy 叨叨叨 如果电脑上安装了多个版本的Python的话，在需要使用pip安装新package时，就会遇到这个问题：我把package安装到哪了？
因为每个版本的 Python 是有自己独立的pip，也有独立的lib目录的，管理的包也各不同。一般来说，使用默认的pip命令安装的位置，就是默认的python位置。
比如我在终端敲下python，使用的是python3.6那么安装的package就会在C:\Python36\Lib\site-packages（根据自己安装 Python 的路径稍有区别）。
情景一：安装的都是 Python3.x 版本 有时候会遇到这样的需求，我准备跑的项目只能用python3.8，我得把package安装到python38里，怎么办？
方法 1 把其中一个python环境变量删掉，留下（如果没有需要添加）python38的路径和script添加到环境变量。
使用以下命令安装：
python -m pip install xxxxx 因为默认Python已经被修改为python38。
方法 2 使用文章开头的方式，最方便，直接指定 python 全局路径
pip install -t D:\python3.5(32bit)\Lib\site-packages numpy 情景二：安装 Python2.x 与 Python3.x Python3.x 使用：
py -3 -m pip install numpy Python2.x 使用：
py -2 -m pip install numpy </description>
    </item>
    <item>
      <title>解决 Unable to 加载 picture or PDF file</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-load-picture-or-pdf-file/</link>
      <pubDate>Fri, 26 Aug 2022 19:22:24 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-load-picture-or-pdf-file/</guid>
      <description>保留现场 Unable to load picture or PDF file &amp;#39;xxxxxx&amp;#39; &amp;lt;to be read again&amp;gt; xxxx 探究原因 图片链接错误，转换 PDF 过程中会先下载所有图片到AppData/Local/Temp/tex2pdf.****文件夹里，因为无法正常下载图片，所有报错。检查图片链接是否有效。
解决方法 检查图片链接是否有效。</description>
    </item>
    <item>
      <title>VSCode搜索结果/匹配高亮</title>
      <link>http://localhost:8888/posts/vscode%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C-%E5%8C%B9%E9%85%8D%E9%AB%98%E4%BA%AE/</link>
      <pubDate>Fri, 26 Aug 2022 16:42:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C-%E5%8C%B9%E9%85%8D%E9%AB%98%E4%BA%AE/</guid>
      <description>调教背景 在VSCode使用搜索/替换时，匹配的字符会“高亮”（高亮个屁），知道自己当前搜到到什么位置，如果匹配字符较少还好，如果匹配太多，默认的高亮就很难发现当前已经搜索到什么位置了。比如我当前在搜索“搜索”这两个字：
大家还能看到我当前搜索到哪了吗？
但是如果设置成这样呢？
配置 搜索匹配时高亮颜色 添加如下配置：
&amp;#34;workbench.colorCustomizations&amp;#34;: { &amp;#34;editor.findMatchBackground&amp;#34;: &amp;#34;#ff0000&amp;#34;, } 表示搜索匹配时高亮，高亮颜色为红色。自己可以选择合适的颜色。
搜索结果高亮 与上面不同的是，搜索时会高亮所有的结果，但是点击箭头匹配到当前结果时就是上面的高亮，其余未匹配的状态就是下面的高亮：
&amp;#34;workbench.colorCustomizations&amp;#34;: { &amp;#34;editor.findMatchHighlightBackground&amp;#34;: &amp;#34;#ff00ff&amp;#34;, } 选择时颜色 &amp;#34;workbench.colorCustomizations&amp;#34;: { &amp;#34;editor.selectionBackground&amp;#34;: &amp;#34;#2f00ff&amp;#34;, } 范围搜索时背景颜色 有时候搜索不是全局搜索，是在自己选中的范围内搜索，那这个范围也是可以高亮的，开启范围搜索需要点击搜索框的按钮，如图所示：
&amp;#34;workbench.colorCustomizations&amp;#34;: { &amp;#34;editor.findMatchHighlightBackground&amp;#34;: &amp;#34;#ff00ff&amp;#34;, &amp;#34;editor.findRangeHighlightBackground&amp;#34;: &amp;#34;#ff9900&amp;#34; } </description>
    </item>
    <item>
      <title>RISC-V 入门 - 任务切换与锁</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E4%BB%BB%E5%8A%A1%E5%88%87%E6%8D%A2%E4%B8%8E%E9%94%81/</link>
      <pubDate>Fri, 26 Aug 2022 15:15:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E4%BB%BB%E5%8A%A1%E5%88%87%E6%8D%A2%E4%B8%8E%E9%94%81/</guid>
      <description>任务切换 任务简介 多任务与上下文 任务就是一个指令执行流。
如果有多个 HART，那就可以同时执行多个指令执行流。
协作式多任务
协作式环境下，下一个任务被调度的前提是当前任务主动放弃处理器。
抢占式多任务
抢占式环境下，操作系统完全决定任务调度方案，操作系统可以剥夺当前任务对处理器的使用，将处理器提供给其它任务。
协作式多任务 上下文切换 切换过程需要完成：
保存上文（保存上一个任务的寄存器信息） 恢复下文（恢复下一个任务的寄存器信息） CPU 中有 32 个寄存器，保存各种状态，在切换过程中我们主要关注两个寄存器：ra(x1) 存放返回地址，mscratch 一个特权寄存器，指向当前处理的任务。
切换过程 初始化寄存器，根据调用约定，ra都初始化为任务的第一条指令地址。mscratch开始指向 Task A。
Task A 稳定执行，当他想要放弃 CPU 时，就会执行 call swithc_to指令。执行call的过程中，就会把当前指令的下一条指令的地址放到 CPU 的ra寄存器。
接下里跳转到swithc_to函数执行，该函数是切换上下文的核心函数。首先保存上文，将 CPU 中的寄存器信息全部保存：
切换mscratch指针到下一个任务 Task B：
恢复下文：
当swithc_to函数执行到return时，接下来执行的指令就是 CPU 中ra保存的那条指令，也就是地址为j指令，这就是 Task B 的第一条指令，这样就完成了任务的切换。
源码分析 切换核心函数 switch_to switch_to: csrrw t6, mscratch, t6 # swap t6 and mscratch beqz t6, 1f # Notice: previous task may be NULL reg_save t6 # save context of prev task # 把CPU的信息保存到内存 # Save the actual t6 register, which we swapped into # mscratch mv t5, t6 # t5 points to the context of current task csrr t6, mscratch # read t6 back from mscratch sw t6, 120(t5) # save t6 with t5 as base 1: # switch mscratch to point to the context of the next task csrw mscratch, a0 # Restore all GP registers # Use t6 to point to the context of the new task mv t6, a0 reg_restore t6 # 把内存里的信息恢复到CPU # Do actual context switching.</description>
    </item>
    <item>
      <title>RISC-V 入门 - 内存管理</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Tue, 23 Aug 2022 22:33:11 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>如何计算堆的大小，只有算出可用空间才能对其管理。
ENTRY
功能：用于设置入口点，即程序中执行的第一条指令 symbol 参数是一个符号的名称
OUTPUT_ARCH
功能：指定输出文件所适用的计算机体系架构
为什么用 riscv64-unknown-elf-gcc，但是编译出来的文件是 32 位程序？ riscv64 是 host 是 64 位系统，编译 target 是由 gcc 的参数决定
MEMORY
功能：用于描述目标机器上内存区域的位置，大小和相关
MEMORY{/* 内存类型为ROM，起始地址0，长度256K */rom(rx):ORIGIN = 0, LENGTH = 256K/* 内存类型为RAM，起始地址0x40000000，长度4M */ram(!rx):org = 0x40000000, l = 4M} TODO：括号里的 rx 含义是？
SECTION
功能：告诉链接器如何将 input sections 映射到 output sections，以及如何将 output sections 放置到内存中。
SECTION{.=0x0000;.text:{*(.text)}.=0x8000000;.data:{*(.data)}.bss:{*(.bss)}}&amp;gt;ram PROVIDE
功能：
可以在 Linker Script 中定义符号（Symbols） 每个符号包括一个名字（name) 和一个对应的地址值（address） 在代码中可以访问这些符号，等同于访问一个地址。 .</description>
    </item>
    <item>
      <title>LaTex-listing 环境设置</title>
      <link>http://localhost:8888/posts/latex-listing%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</link>
      <pubDate>Sun, 21 Aug 2022 14:28:42 +0000</pubDate>
      <guid>http://localhost:8888/posts/latex-listing%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</guid>
      <description>总览 backgroundcolor 背景颜色 numbers 代码行号 \lstset{ numbers = left, % 行号靠左 basicstyle = \ttfamily, % 基本代码风格 keywordstyle = \bfseries, % 关键字风格 commentstyle = \ttfamily, % 注释的风格 frame = single, % 阴影效果 escapeinside=``, % 英文分号中可写入中文 xleftmargin=2em,xrightmargin=2em, aboveskip=1em, breaklines = true, language = C, % 语言选C } \lstset{ numbers = right, % 行号靠左 basicstyle = \ttfamily, % 基本代码风格 keywordstyle = \bfseries, % 关键字风格 commentstyle = \ttfamily, % 注释的风格 frame = single, % 阴影效果 escapeinside=``, % 英文分号中可写入中文 xleftmargin=2em,xrightmargin=2em, aboveskip=1em, breaklines = true, language = C, % 语言选C } stepnumber 间隔显示行号 \lstset{ numbers = right, % 行号靠左 stepnumber = 2, % 每两行显示一次行号 } firstnumber 开始行号 firstnumber = 10 开始行号为 10 firstnumber = last 开始行号为上一段 listing 的结束行号 xleftmargin/xrightmargin/aboveskip/below 距离外部元素距离 设置代码块上下左右的距离，与外部元素的距离，而不是代码与边框的距离。</description>
    </item>
    <item>
      <title>Markdown 书写 PDF 输出优雅的解决方案</title>
      <link>http://localhost:8888/posts/markdown%E4%B9%A6%E5%86%99pdf%E8%BE%93%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sat, 20 Aug 2022 08:28:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/markdown%E4%B9%A6%E5%86%99pdf%E8%BE%93%E5%87%BA%E4%BC%98%E9%9B%85%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>折腾背景 Markdown 的简便性是 LaTeX 无法替代的，LaTeX 对排版的精准控制能力又是 Markdown 无法比拟的。一直在寻找一种能够将 Markdown 优雅地转换成 PDF 的解决方案，虽然早就听说也使用过 Pandoc 这把瑞士军刀，但是它太过强大，以致于一直都没用明白。只会简单的转换命令，但是实际效果并不好，最近学会了使用 LaTeX 模板的功能，这才让我眼前一亮，这才是我想要的结果。
效果演示 基础环境配置 Markdown 生成 PDF 主要需要使用 Pandoc 和 LaTeX 两个工具，具体安装方式如下：
Pandoc 的安装 Pandoc 是由 John MacFarlane 开发的标记语言转换工具，可实现不同标记语言间的格式转换。
Windows 下的安装：
下载安装包直接安装即可 如果安装了 Chocolate：choco install pandoc 如果安装了 winget：winget install pandoc Linux/FreeBSD下的安装：
Pandoc 已经包含在大部分 Linux 发行版的官方仓库中，直接使用诸如apt/dnf/yum/pacman之类的安装工具直接安装即可 macOS 下的安装：
brew install pandoc 详细的安装说明参见：官方安装文档
LaTeX 的安装 LaTeX 工具，建议安装 texlive。
Windows 下的安装： 参考该文章下载完整 texlive，注意安装后需要再安装 cjk，cjk-fonts 等相关 package Linux/FreeBSD下的安装： 使用 apt/dnf/yum/pacman/pkg 等安装工具安装 texlive、texlive-latex 等相关软件包 macOS 下的安装： 使用 HomeBrew 安装 texlive 即可 模板配置 配置 Pandoc 模板 为保证生成的 pdf 格式（自动插入封面、目录页、页眉页脚等信息），在本地环境中安装模板，具体步骤是：</description>
    </item>
    <item>
      <title>IIC 协议</title>
      <link>http://localhost:8888/posts/iic%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Fri, 19 Aug 2022 14:16:29 +0000</pubDate>
      <guid>http://localhost:8888/posts/iic%E5%8D%8F%E8%AE%AE/</guid>
      <description>IIC 概述 IIC（Inter-Integrated Circuit），也叫 I2C（Inter-IC Communication）总线，是一种串行通信协议，由 Philips 公司在 1980 年代初开发。IIC 总线用于连接微控制器、传感器和其他集成电路，它具有以下特点：
双线制结构简单：由一条数据线（SDA）和一条时钟线（SCL）组成。 多主机并行通信：多个 Master 设备可同时接入同一条 IIC 总线上进行数据交换。 硬件资源占用少：只要两根线就可以连接多个器件。 数据传输速率快：现代 IIC 总线的最高传输速率可达到 400Kbps。 低功耗设计：使用者可以通过软件控制设备进入睡眠模式以减少功耗。 传输协议 写操作 主机要发出一个起始信号 主机发出一个设备地址用来确定是往那一个芯片写数据，以及写标记（0） 从设备回应（用来确定这个设备是香存在，然后就可以传输数据） 主设备发送一个字节数据给从设备，并等待回应 每传输一字节故据，接收方要有一个回应信号（确定故据是否接受完成），然后再传输下一个故据。 数据发送完之后，主机就会发送一个停止信号。 读操作 主机要发出一个起始信号 主机发出一个设备地址用来确定是往那一个芯片读数据，以及读标记（1） 从设备回应（用来确定这个设备是否存在），然后就可以传输数据 从设备发送一个字节放据给主设备，并等待回应 每传输一字节数据，接收方要有一个回应信号（确定数据是否接受完成），然后再传输下一个放据。 数据发送完之后，主芯片就会发送一个停止信号。 状态 空闲状态 SCL 和 SDA 都为高电平 此时各个器件的输出级场效应管均处在截止状态，即释放总线，由两条信号线各自的上拉电阻把电平拉高。
起始状态 SCL 为高电平，SDA 由高电平变为低电平 标志着一次数据传输的开始。起始信号是由主控器主动建立的，在建立该信号之前 I2C 总线必须处于空闲状态。
结束状态 SCL 为高电平，SDA 由低电平变为高电平 数据传输状态 SCL 高电平期间，SDL 保持稳定 SDL 为高电平表示 1，低电平表示 0 在 IIC 总线上传送的每一位数据都有一个时钟脉冲相对应 (或同步控制)，即在 SCL 串行时钟的配合下，数据在 SDA 上从高位向低位依次串行传送每一位的数据。进行数据传送时，在 SCL 呈现高电平期间，SDA 上的电平必须保持稳定，低电平为数据 0，高电平为数据 1。只有在 SCL 为低电平期间，才允许 SDA 上的电平改变状态。下图是 0xaa 在 IIC 总线上有效传输 (有效传输是指第 9 个时钟的高电平期间，从机给主机反馈了一个有效的应答位 0) 的图示</description>
    </item>
    <item>
      <title>编译错误以英文输出</title>
      <link>http://localhost:8888/posts/%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF%E4%BB%A5%E8%8B%B1%E6%96%87%E8%BE%93%E5%87%BA/</link>
      <pubDate>Tue, 16 Aug 2022 22:31:43 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E7%BC%96%E8%AF%91%E9%94%99%E8%AF%AF%E4%BB%A5%E8%8B%B1%E6%96%87%E8%BE%93%E5%87%BA/</guid>
      <description>因为终端配置的原因，编译的结果输出是中文，这样搜索问题不如英文的表述精确。配置终端的语言为英文，就可以输出英文。
export LANG=en_US </description>
    </item>
    <item>
      <title>解决 cast from pointer to integer of different size</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3cast-from-pointer-to-integer-of-different-size/</link>
      <pubDate>Tue, 16 Aug 2022 11:42:24 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3cast-from-pointer-to-integer-of-different-size/</guid>
      <description>保留现场 void* foo(void *dst, ...) { // some code unsigned int offset = (unsigned int) dst % 8; // warning here! // some code continue... } 写驱动程序时经常会直接对地址进行修改，配置寄存器的值，也会将地址的值作为数据进行传递，这就会遇到一个问题，指针强转成整型，类型不匹配数据丢失的问题。
探究原因 出现这个警告的原因是，将void*类型强转成unsigned int是不可移植的。什么叫不可移植呢？
我们知道指针类型，在 32 位系统下是 4 字节，在 64 位系统下是 8 字节，而unsigned int不管在什么系统下都是是 4 字节，所以，如果将void*类型强转成unsigned int，在 64 位系统下就没有足够的空间保存真正的数据。
解决方法 粗暴地用double来接收 先接收，再截断：
void* foo(void *dst, ...) { // some code unsigned int offset = (unsigned int)(unsigned double) dst % 8; // warning here! // some code continue.</description>
    </item>
    <item>
      <title>DEBUG 原理</title>
      <link>http://localhost:8888/posts/debug%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 14 Aug 2022 14:17:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/debug%E5%8E%9F%E7%90%86/</guid>
      <description>了解调试原理时看到了一个质量比较高的视频，【蛋饼嵌入式】一起探究调试原理。UP 通俗，形象地讲解了 DEBUG 的一些原理，值得反复观看，但是视频不如文字查阅效率高，遂记录了以下文稿内容。
什么是 JTAG 1985 年，几家半导体厂商为了解决板级测试的问题，成立了 Joint Test Action Group（JTAG）联合测试行动小组，他们希望将测试点和测试电路集成在芯片内部引脚处。同时，留出一个统一协议的接口，大家都能通过这个接口来访问芯片的输入与输出状态。这样就省去了板级测试是的物理接触，同时还能进行逻辑性调试。后来 IEEE 组织，将这个方案制定成了标准 IEEE 1149.1，这就是现在我们常听到的 JTAG 调试。
边界扫描技术 实现 JTAG 调试最重要的一个技术就是边界扫描技术，核心思想是给芯片的每一个输入输出引脚，添加一个移位寄存器单元，也称为边界扫描单元（Boundary Scan Cell，BSC）。通过它一边可以实现对芯片输出数据的截取，另一边可以完成对输入数据的替代。正常运行状态下，这些寄存器又是透明般的存在。
这些位于引脚边界的移位寄存器，还可以串在一起，形成一条边界扫描链，以串行的方式从外部更新扫描单元上的数据，以及对外输出边界扫描单元捕获的数据。如果板上有多个这样的芯片，他们还能以菊花链的形式串联在一起，这样就大大方便了测试的过程。
要实现对内部移位寄存器单元或者说对整个扫描链的访问和操作，便依赖于 JTAG 调试协议和相应的物理接口。JTAG 标准接口包括以下几个部分：
TDI(Test Data In) TDO(Test Data Out) TCLK(Test Clock) TMS(Test Mode Select) TRST(Test Reset)：可选，用于复位 调试逻辑的实现，是通过芯片内部的 TAP（Test Access Port）来完成的。模式状态信号 TMS 配合测试时钟信号 TCLK，以一定的时序进入到 TAP 控制器后，由 TAP 控制器内部的状态机转化为相应的控制动作。从而完成数据的移位，引脚状态的捕获和更新。
设备 ID 寄存器构成的扫描链，板卡一连上调试器，通过对这条扫描链的访问，就能够识别到被调试芯片的信号。存放调试机制相关配置的数据寄存器，所构成的扫描链，后面断点和单步调试时就会用到。以及移位的 BYPASS 寄存器，当调试链路上有多个芯片连接时，来减少总调试链路的长度。
以上都属于数据寄存器构成扫描链，因为想要在他们之间进行切换，需要引入另外的指令寄存器，以及对应的扫描链，这样调试主机将不同的调试命令写到指令寄存器中，就可以选通需要调试的数据链路。数据与指令寄存器两种链路的切换，就通过 TAP 控制器完成。
补充： 如果芯片支持 JTAG 调试，那么芯片上就必须有上述的四个接口，TDI，TDO，TCLK，TMS。 芯片外有个 Adapter 与之 Pin to Pin 连接，负责协议转换，把 USB 的 JTAG 控制信息按 JTAG 协议转换输出，满足协议定义的电气特性。 Adapter 与 Host 连接，Host 可以是我们的 PC，也可以是另一个嵌入式调试器。 Host 上通常需要运行一些软件，如 OpenOCD，负责把 GDB 的高级别命令转换成 JTAG 命令，并通过特定 Adapter 的要求进行打包，调用 OS 提供的 USB/ETH/PCI 驱动发送出去。 GDB 与 OpenOCD 通过一些远程协议，如 TCP/IP，进行通信。这样就能够调试 Chip。</description>
    </item>
    <item>
      <title>保持 SSH 连接</title>
      <link>http://localhost:8888/posts/%E4%BF%9D%E6%8C%81ssh%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Sat, 13 Aug 2022 20:28:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BF%9D%E6%8C%81ssh%E8%BF%9E%E6%8E%A5/</guid>
      <description>SSH 总是被强行中断，尤其是用 VSCode 代码写的好好的，突然刷新窗口，不仅效率低，更惹人恼火。
可以通过配置服务端或客户端的 SSH 来保持 SSH 链接：
方法一：配置服务端 可以在服务端配置，让 server 每隔 30 秒向 client 发送一个 keep-alive 包来保持连接：
vim /etc/ssh/sshd_config ClientAliveInterval 30 ClientAliveCountMax 60 第二行配置表示如果发送 keep-alive 包数量达到 60 次，客户端依然没有反应，则服务端 sshd 断开连接。如果什么都不操作，该配置可以让连接保持 30s*60，30 min
重启本地 ssh
sudo service ssh restart 如果找不到 ssh,”Failed to restart ssh.service: Unit ssh.service not found.” ，需要安装
sudo apt-get install openssh-server 方法二：配置客户端 如果服务端没有权限配置，或者无法配置，可以配置客户端 ssh，使客户端发起的所有会话都保持连接：
vim /etc/ssh/ssh_config ServerAliveInterval 30 ServerAliveCountMax 60 本地 ssh 每隔 30s 向 server 端 sshd 发送 keep-alive 包，如果发送 60 次，server 无回应断开连接。</description>
    </item>
    <item>
      <title>VSCode 隐藏编辑页面右上角的按钮</title>
      <link>http://localhost:8888/posts/vscode%E9%9A%90%E8%97%8F%E7%BC%96%E8%BE%91%E9%A1%B5%E9%9D%A2%E5%8F%B3%E4%B8%8A%E8%A7%92%E7%9A%84%E6%8C%89%E9%92%AE/</link>
      <pubDate>Tue, 02 Aug 2022 22:10:55 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E9%9A%90%E8%97%8F%E7%BC%96%E8%BE%91%E9%A1%B5%E9%9D%A2%E5%8F%B3%E4%B8%8A%E8%A7%92%E7%9A%84%E6%8C%89%E9%92%AE/</guid>
      <description>随着插件越装越多，标签栏右侧的按钮也越来越多，严重缩小了标题栏显示范围。这片按钮区域又有最大长度的限制，当按钮太多，就会隐藏到下拉菜单里（最右侧的三个点）。这样就会导致一些常用的按钮被隐藏，而不常用的按钮又占地方。那么怎样才能隐藏不需要的按钮呢？
&amp;#34;gitlens.menus&amp;#34;: { &amp;#34;editorGroup&amp;#34;: { &amp;#34;blame&amp;#34;: false, &amp;#34;compare&amp;#34;: true }, }, </description>
    </item>
    <item>
      <title>Jellyfin 打造本地影音库</title>
      <link>http://localhost:8888/posts/jellyfin%E6%89%93%E9%80%A0%E6%9C%AC%E5%9C%B0%E5%BD%B1%E9%9F%B3%E5%BA%93/</link>
      <pubDate>Mon, 01 Aug 2022 23:05:52 +0000</pubDate>
      <guid>http://localhost:8888/posts/jellyfin%E6%89%93%E9%80%A0%E6%9C%AC%E5%9C%B0%E5%BD%B1%E9%9F%B3%E5%BA%93/</guid>
      <description>Docker 启动 version: &amp;#34;3.7&amp;#34; services: jellyfin: image: dockerproxy.com/linuxserver/jellyfin:latest container_name: jellyfin hostname: RISCX environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - HTTP_PROXY:&amp;#39;http://192.168.1.9:7890&amp;#39; - HTTPS_PROXY:&amp;#39;http://192.168.1.9:7890&amp;#39; volumes: - /root/sharedfolder/appdata/jellyfin/config:/config - /root/sharedfolder/media:/media - /root/sharedfolder/appdata/jellyfin/cache:/cache devices: - /dev/dri:/dev/dri extra_hosts: - &amp;#34;api.themoviedb.org:108.138.246.55&amp;#34; - &amp;#34;image.themoviedb.org:104.16.61.155&amp;#34; - &amp;#34;www.36dm.com:104.21.80.200&amp;#34; network_mode: &amp;#34;host&amp;#34; restart: unless-stopped 初始化配置 就不挨个贴图了，建议将页面都设置为中文，有一点需要注意的是选择国家的时候，中国的英文全称是 People&amp;rsquo;s Republic of China，不是 China，需要仔细找一下。
转码配置 主要配置硬解码，这样可以大大降低 CPU 的使用率，提高播放的流畅度。能够开启硬解需要 GPU 支持，如果 CPU 有核显，那么就可以开启硬解，如果没有，那么就算了吧，跳过。也可以通过下面的命令查看是否支持硬解。
cat /proc/cpuinfo | grep &amp;#34;flags&amp;#34; 该命令将输出 CPU 的系统信息，并在输出结果中搜索&amp;quot;flags&amp;quot;（标志）行。如果该行中包含&amp;quot;vme&amp;quot;、&amp;ldquo;cmov&amp;rdquo;、&amp;ldquo;cx8&amp;rdquo;、&amp;ldquo;mmx&amp;rdquo;、&amp;ldquo;sse&amp;rdquo;、&amp;ldquo;sse2&amp;rdquo;、&amp;ldquo;sse3&amp;rdquo;、&amp;ldquo;ssse3&amp;rdquo;、&amp;ldquo;sse4_1&amp;rdquo;、&amp;ldquo;sse4_2&amp;rdquo;、&amp;ldquo;avx&amp;quot;等关键词，则说明该 CPU 支持视频硬解码。
调用Potplayer本地解码 使用下面这个插件可以实现调用本地播放器播放视频，这样就可以使用 Potplayer 等播放器进行播放，而不是使用 Jellyfin 的内置播放器。文档写的十分详细，在这里就不再赘述了。</description>
    </item>
    <item>
      <title>使用 Syncthing 多端丝滑同步与备份</title>
      <link>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8syncthing%E5%A4%9A%E7%AB%AF%E4%B8%9D%E6%BB%91%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%A4%87%E4%BB%BD/</link>
      <pubDate>Mon, 01 Aug 2022 22:48:21 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BD%BF%E7%94%A8syncthing%E5%A4%9A%E7%AB%AF%E4%B8%9D%E6%BB%91%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%A4%87%E4%BB%BD/</guid>
      <description>折腾背景 一直想找一个能够快速同步手机与电脑数据的工具，因为手机云服务的空间少的可怜，所以习惯隔一段时间将手机里的照片、视频还有一些文件导出到电脑上。但是每次备份文件都得连接数据线，并且没法增量备份，得手动挑选，也还挺麻烦的。
逛 GitHub 时，无意间发现了 Syncthing，几乎符合了我所有的预期。
开源，免费，自己电脑就可以当服务器，以后入了 NAS，可以自己搭建本地服务器。 同步速度快，取决 WIFI 的速度，目前使用 30M/s，基本满速。 多端支持，除了 IOS（反正我也没有 iOS 设备，嘿嘿），几乎全平台支持，包括 NAS 及路由器。 增量同步，再也不用挑文件备份了。 话不多说，开整。
下载安装 直接进入Syncthing官网，下载安装。在 Ubuntu 下安装参考这里。Android 版本下载Syncthing。
接下来以 Windows 与 Android 手机同步为例，下载安装后，打开syncthing.exe，即可打开管理界面，或者浏览器输入http://127.0.0.1:8384也可进入管理界面。
Windows 界面：
Android 界面： 设备配对 Windows 管理页面-&amp;gt;操作-&amp;gt;显示 ID，会显示本机的二维码：
Android 手机打开应用，切换到设备界面，点击右上角加号，点击二维码标识，即可扫描二维码，完成设备添加。
如果正确添加，Windows 管理界面会显示 Android 设备：
Android 同步至 Windows 打开 Android 应用，切换到文件夹界面，点击右上角加号，配置同步的文件夹： 根据下图提示，配置应用，记得保存： 目录列表显示刚刚的配置： 点击打开，开启与远程设备 Windows 同步：
当返回时，Windows 端将会弹出通知，提示有 Android 设备的文件要分享到电脑，点击添加： 至此，Android 同步至 Windows 完成。此时在 Android 设备的文件夹中添加任意文件，都会同步到 Windows。
如果是局域网内，发现设备的速度很慢，可以尝试设置静态的 IP。手机端 -&amp;gt; 设备 -&amp;gt; 链接图标。默认为 dynamic，将其改为 Windows 的 IP 和 syncthing 的端口。如tcp://192.</description>
    </item>
    <item>
      <title>解决提交 gerrit missing Change-Id</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E6%8F%90%E4%BA%A4gerrit-missing-change-id/</link>
      <pubDate>Sat, 30 Jul 2022 15:05:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E6%8F%90%E4%BA%A4gerrit-missing-change-id/</guid>
      <description>保留现场 remote: Resolving deltas: 100% (114/114) remote: Processing changes: refs: 1,done remote: ERROR: missing Change-Idincommit message footer remote: remote: Hint: To automatically insert Change-Id,installthe hook: remote: gitdir=$(git rev-parse --git-dir);scp-p -P XX XX@gerrit.xxxxx.com:hooks/commit-msg${gitdir}/hooks/ remote: And then amend the commit: remote: git commit --amend 探究原因 理解 change-id 代码审核是要对一个完整的变更进行审核，比如一次 Bug 修复，有多次提交 Commit，每次的 Commit Id 都不同，那么如何将多个不同的 Commit ID 关联到同一个 Chanege-Id 呢？我们需要将 Change-Id 添加到 Commit 的 footer（最后一行）中，这样就可以将多个 Commit 关联到同一个 Change-Id 了。
Change-Id 为避免与提交 Id 冲突，通常以大写字母 I 为前缀。此外，我们需要明确，Change-Id 是 Gerrit 的概念，不是 Git 的概念。你只有用 Gerrit 才会有 Change-Id，而 Git 只有提交 Id。</description>
    </item>
    <item>
      <title>Gerrit 批量添加抄送提醒</title>
      <link>http://localhost:8888/posts/gerrit%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E6%8A%84%E9%80%81%E6%8F%90%E9%86%92/</link>
      <pubDate>Fri, 29 Jul 2022 13:58:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/gerrit%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E6%8A%84%E9%80%81%E6%8F%90%E9%86%92/</guid>
      <description>背景 公司使用 Gerrit 作为 Review 平台，但是每次提交代码都需要手动添加 Reviewer，还要抄送组内成员，这种重复性劳动，程序员是绝不能容忍的。gerrit 提供了发送邮件的功能。
解决方法 官方示例：
git push ssh://john.doe@git.example.com:29418/kernel/common HEAD:refs/for/experimental%r=a@a.com,cc=b@o.com 最后的%是个分隔符，r=&#39;a@a.com表示 Reviewer 是a@a.com，cc=b@o.com表示抄送组内成员是b@o.com。
注意！邮箱之间不能有空格！
以一个仓库为例：
git push origin HEAD:refs/for/branch_dev_name%cc=zhangsan@qq.com,cc=lisi@qq.com,cc=wangerma@qq.com,cc=chenwu@qq.com 但是要这么写，岂不是把操作搞更复杂了。
终极办法，打开项目路径下的.git目录。编辑config文件：
原文件里有如下字段：
[core]repositoryformatversion = 0filemode = falsebare = falselogallrefupdates = trueignorecase = true[remote &amp;#34;origin&amp;#34;]url = git@github.com:Dunky-Z/Dunky-Z.github.io.gitfetch = +refs/heads/*:refs/remotes/origin/* 我们可以将远程仓库名换成容易区分的名字，自己随意：
[core]repositoryformatversion = 0filemode = falsebare = falselogallrefupdates = trueignorecase = true[remote &amp;#34;origin&amp;#34;]url = git@github.</description>
    </item>
    <item>
      <title>Makefile 确定宏定义</title>
      <link>http://localhost:8888/posts/makefile%E7%A1%AE%E5%AE%9A%E5%AE%8F%E5%AE%9A%E4%B9%89/</link>
      <pubDate>Wed, 27 Jul 2022 08:28:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/makefile%E7%A1%AE%E5%AE%9A%E5%AE%8F%E5%AE%9A%E4%B9%89/</guid>
      <description>有时需要通过make编译命令时确定代码中的宏定义，如编译不同的版本只需要使用不同的编译命令即可，而不需要修改内部代码。
当前的需求是代码中有一部分代码通过宏定义来确定编译的是 DIE0 版本还是 DIE1 版本，如果定义了DIE_ORDINAL_0 就使用 DIE0 的基地址，如果未定义就使用 DIE1 的基地址。
#define DIE_ORDINAL_0 #ifdef DIE_ORDINAL_0 #define PERIPH_BASE (SYS_BASE_ADDR_DIE0) #else #define PERIPH_BASE (SYS_BASE_ADDR_DIE1) #endif gcc 命令支持-D宏定义，相当于 C 中的全局#define，在 Makefile 中我们可以通过宏定义来控制源程序的编译。只要在 Makefile 中的 CFLAGS 中通过选项-D 来指定你于定义的宏即可。
CFLAGS += -D DIE_ORDINAL_0 # 在编译的时候加上此选项就可以了 $(CC) $(CFLAGS) $^ -o $@ 这样的话，相当于设置了DIE_ORDINAL_0这个宏定义。但是我们想通过命令行的参数来决定是否使用这个宏定义，可以通过一些简单的方法获取：
ifeq ($(DIE0), y) CFLAGS +=-DDIE_ORDINAL_0 else CFLAGS +=-DDIE_ORDINAL_1 endif $(CC) $(CFLAGS) $^ -o $@ 从命令行找到DIE0这个参数，如果它等于y表示使用DIE_ORDINAL_0。如果不等于y则使用DIE_ORDINAL_1，因为我们代码里没有DIE_ORDINAL_1，所以就相当于没有定义DIE_ORDINAL_0。
命令行示例：
# 编译DIE0 make DIE0=&amp;#34;y&amp;#34; # 编译DIE1 make DIE0=&amp;#34;n&amp;#34; </description>
    </item>
    <item>
      <title>每天学命令-生成指定大小文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 23 Jul 2022 16:14:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E6%96%87%E4%BB%B6/</guid>
      <description>使用背景 在测试下载速度，或者测试加解密文件，亦或者制作文件系统时都需要一些指定大小的文件。Linux 有一些命令可以快速完成这样的任务。接下来介绍几个好用的命令。
空洞文件 在 Unix 文件操作中，操作文件的位移量可以大于文件的当前长度，在下一次写操作时，就会把文件撑大（Extend），在文件里创建空洞（Hole），没有被实际写入的部分都是 0。空洞文件是否占用实际磁盘空间由文件系统觉得，Linux 中空洞文件不占用实际磁盘空间。
fallocate fallocate用于将块预分配给文件。对于支持fallocate系统调用的文件系统，这可以通过分配块并将其标记为未初始化来快速完成，因此不需要对数据块进行 I/O 操作。这是创建文件而不是用零填充的更快的方法。大文件几乎可以立即创建，而不必等待任何 I/O 操作完成。
语法：
fallocate [-n] [-o offset] -l length filename d: 检测零并替换为空洞。 -n：指定文件的大小，单位为字节。 -o：指定文件的偏移量，可以跟二进制$2^{N}$后缀KiB，MiB，GiB，TiB，PiB和EiB（iB为可选，例如，K的含义与KiB的含义相同或后缀KB，MB，GB，PB和EB的十进制（$10^{N}$）。 -l：指定文件的大小，单位同上。 -p, --punch-hole: 将某个范围替换为空洞 (连带打开 -n)。 filename：指定文件名。 示例： 分配一个大小为512MB的文件，文件名为efi.img：
fallocate -l 512M efi.img 将efi.img文件中的0替换为空洞：
fallocate -d efi.img 从偏移 128M 的位置挖一个 10M 大小的洞
fallocate -p -o 128M -l 10M efi.img dd Linux dd 命令用于读取、转换并输出数据。dd 可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出
dd 的原意为 data duplicator，但由于 dd 属于较低阶的资料处理工具，通常都会以管理者（root）权限来执行，如果稍有不慎，也很容易造成严重的后果（例如整颗硬碟的资料不见等等），所以有些人也把 dd 取名为 data destroyer。dd 指令教学与实用范例，备份与回复资料的小工具 - GT Wang</description>
    </item>
    <item>
      <title>SPI 协议</title>
      <link>http://localhost:8888/posts/spi%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Tue, 19 Jul 2022 14:23:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/spi%E5%8D%8F%E8%AE%AE/</guid>
      <description>SPI 概述 SPI 是一种同步的、全双工的、高速的串行通信总线。
4 线制 SPI 四个信号：
SCLK：串行时钟信号，由主设备产生，用于同步数据传输。 CS：片选信号，由主设备产生，用于选择从设备。 MOSI：主设备输出，从设备输入，用于主设备向从设备传输数据。 MISO：主设备输入，从设备输出，用于从设备向主设备传输数据。 除了四线式 SPI 总线之外，还有三线式 SPI 总线和双线式 SPI 总线。
四线式 SPI 总线，也称为标准 SPI 总线，由 SCLK、MOSI、MISO 和 SS（Slave Select）四个信号线组成。其中，SCLK 是时钟信号线；MOSI 是主设备向从设备发送数据的信号线；MISO 是从设备向主设备发送数据的信号线；SS 是从设备的片选信号线，用于选择要通信的从设备。
三线式 SPI 总线将 MOSI 和 MISO 合并为单一的信号线。这种 SPI 总线有一个专门的叫做 MOMI 的信号线，既可以作为主设备向从设备发送数据的信号线，又可以作为从设备向主设备发送数据的信号线。
双线式 SPI 总线（也称为 MICROWIRE 或 uWire），由一个串行数据线和一个时钟线组成。在这种 SPI 总线上，没有单独的片选信号线，而是使用一个帧选择控制位来选择相应的从设备。
他们传输速率有差别吗？ 是的，SPI 总线的不同类型之间存在传输速率上的差别。一般情况下，四线式 SPI 总线的传输速度最快，而双线式 SPI 总线的传输速度最慢。但具体的传输速度会受到很多因素的影响，例如工作频率、数据线长度等等。如果要在实际应用中选择合适的 SPI 总线类型，需要考虑诸如这些因素的影响，并根据具体情况进行权衡取舍。 SPI 总线的传输速度快慢与其信号线数量有关。双线式 SPI 总线一共只有两条信号线：一个主设备 (Master) 输出时钟信号 (SCLK)，一个主设备通过该信号线读取从设备 (Slave) 的应答信号。而四线式 SPI 总线除了上述两条信号线外，还有两条用于数据传输的信号线：主设备通过 MOSI 信号线向从设备发送数据，从设备则通过 MISO 信号线将数据返回给主设备。由于四线式 SPI 总线有专门的数据传输信号线，故可以通过同时在这两条信号线上传输数据来实现更高的传输速率，从而比双线式 SPI 总线快一些。</description>
    </item>
    <item>
      <title>理解虚拟内存</title>
      <link>http://localhost:8888/posts/%E7%90%86%E8%A7%A3%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</link>
      <pubDate>Sun, 17 Jul 2022 21:45:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E7%90%86%E8%A7%A3%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</guid>
      <description>为什么需要虚拟内存？ CPU 访问内存的最自然的方式就是使用物理地址，这种方式称为物理寻址。1，计算机中并不是只有一个程序在运行，如果它们都是用物理寻址的方式，那么所有程序必须在链接之前确定好自己所用到的内存范围，否则两个程序就可能会发生冲突。2，程序大于内存的问题早在上世纪六十年代就出现，后来出现了覆盖技术（Overlay），把程序分割成许多片段。程序开始执行时，将覆盖管理模块装入内存，该管理模块立即装入并运行覆盖 0。执行完成后，覆盖 0 通知管理模块装入覆盖 1，或者占用覆盖 0 的上方位置（如果有空间），或者占用覆盖 0（如果没有空间）。把一个大程序分割成小的、模块化的片段是非常费时和枯燥的，并且易于出错。很少程序员擅长使用覆盖技术。
为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存(VM)。主要有三个功能：
它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 它为每个进程提供了一致的地址空间，从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 什么是虚拟寻址？ 如果主存被分为长度为$M$的单字节大小的数组，每个字节都对应一个物理地址，CPU 通过这个唯一的地址访问主存，这样的方式就是物理寻址。 现代处理器使用虚拟寻址的方式。CPU 通过生成的虚拟地址来访问内存，这个地址在送到内存之前会被转换成物理地址。这个过程称为地址翻译。CPU 芯片上叫做内存管理单元（Memory Management Unit, MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。 虚拟内存作为缓存的工具 概念上而言，虚拟内存被组织成为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组，也就是字节数组。每个字节都有一个唯一的虚拟地址作为数组的索引。磁盘上活动的数组内容被缓存在主存中。在存储器结构中，较低层次上的磁盘的数据被分割成块，这些块作为和较高层次的主存之间的传输单元。主存作为虚拟内存的缓存。
虚拟内存被分割为大小固定的块，这些块叫虚拟页（Virtual Page，VP），类似的物理内存也有物理页(Physical Page, PP)。虚拟页有三种不同的状态：
未分配：VM 系统还未分配 (或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。 已缓存：当前已缓存在物理内存中的已分配页。 未缓存：未缓存在物理内存中的已分配页。 为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语SRAM缓存来表示位于 CPU 和主存之间的 Ll、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页。
在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。回想一下，DRAM 比 SRAM 要慢大约 10 倍，而磁盘要比 DRAM 慢大约 100000 多倍。因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多。因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。（这些替换算法超出了我们的讨论范围）。最后，因为对磁盘的访问时间很长，DRAM 缓存总是使用写回，而不是直写。
页表 虚拟内存系统可以完成以下这些功能，
判定一个虚拟页是否缓存在 DRAM 中的某个地方； 可以确定这个虚拟页存放在哪个物理页中； 如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。 这些功能是由软硬件联合提供的，包括操作系统软件、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表（page table）的数据结构。页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页。</description>
    </item>
    <item>
      <title>C 语言 getopt() 函数的用法</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80getopt-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/</link>
      <pubDate>Sat, 16 Jul 2022 22:42:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80getopt-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/</guid>
      <description>在做CSAPP_LAB-Cache Lab时，实验要求对输入参数进行处理，如程序csim执行需要 4 个参数：
./csim -s 4 -E 6 -b 4 -t &amp;lt;tracefile&amp;gt; 原先想通过字符串解析，一个个处理，但是看到了其他参考代码后发现了一个更简单的方法，可以通过getopt()函数来解析参数。
函数的功能：解析命令行参数。 头文件 #include &amp;lt;unistd.h&amp;gt;
在学习函数前需要了解与该函数相关的四个变量：
int opterr：控制是否输出错误； 如果此变量的值非零，则 getopt 在遇到未知选项字符或缺少必需参数的选项时将错误消息打印到标准错误流 (终端)。该值默认为非零。如果将此变量设置为零，getopt 不会打印任何消息，但仍会返回问号?提示错误。
int optopt：保存未知的选项； 当 getopt 遇到未知选项字符或缺少必需参数的选项时，它将该选项字符存储在此变量中。
int optind：指向下一个要处理的参数； 此变量由 getopt 设置为要处理的 argv 数组的下一个元素的索引。一旦 getopt 找到所有选项参数，就可以使用此变量来确定其余非选项参数的开始位置。该变量的初始值为 1。
char * optarg：保存选项参数； 对于那些接受参数的选项，此变量由 getopt 设置为指向选项参数的值。
函数原型：
int getopt(int argc, char * const argv[], const char * options); 参数解析：
参数argc 和argv 是由main()传递的参数个数和内容。 options 参数是一个字符串，它指定对该程序有效的选项字符。此字符串中的选项字符后面可以跟一个冒号（:），表示它需要一个必需的参数，这个参数可以与选项连写也可以空格分开，如-a13 or -a 13。如果选项字符后跟两个冒号（::），则其参数是可选的，如果有参数，那么参数不能与选项分割，如只能写成-a13而不能写成-a 13；这是一个 GNU 扩展。 实例：</description>
    </item>
    <item>
      <title>解决 VS Code 终端使用 git bash 时中文乱码</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vs-code%E7%BB%88%E7%AB%AF%E4%BD%BF%E7%94%A8git-bash%E6%97%B6%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/</link>
      <pubDate>Sat, 16 Jul 2022 21:59:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vs-code%E7%BB%88%E7%AB%AF%E4%BD%BF%E7%94%A8git-bash%E6%97%B6%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/</guid>
      <description>保留现场 Windows 环境下，使用 VSCode 的终端时，中文显示为乱码，如使用git status命令查看修改文件时，中文文件名就无法正常显示： 探究原因 因为终端被替换成了 git bash，它对所有非英文的字符进行了转义。
官方文档提到：
输出路径的命令（例如ls-files、diff）将通过将路径名括在双引号中并以与 C 转义控制字符相同的方式用反斜杠转义这些字符来引用路径名中的异常字符（例如\t用于 TAB, \n 表示LF，\\表示反斜杠）或值大于 0x80 的字节（例如，八进制 \302\265 表示 UTF-8 中的“micro”）。如果此变量设置为 false，则高于 0x80 的字节不再被视为异常。无论此变量的设置如何，双引号、反斜杠和控制字符总是被转义。一个简单的空格字符不被认为是异常的。许多命令可以使用 -z 选项完全逐字输出路径名。默认值是 true。
解决方法 命令行输入，取消转义：
git config --global core.quotepath false </description>
    </item>
    <item>
      <title>NOC(net-on-chip) 总线互联构架</title>
      <link>http://localhost:8888/posts/noc-net-on-chip-%E6%80%BB%E7%BA%BF%E4%BA%92%E8%81%94%E6%9E%84%E6%9E%B6/</link>
      <pubDate>Tue, 12 Jul 2022 23:13:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/noc-net-on-chip-%E6%80%BB%E7%BA%BF%E4%BA%92%E8%81%94%E6%9E%84%E6%9E%B6/</guid>
      <description>技术背景 转载自^[片上网络（NoC）技术的背景、意义以及发展_碎碎思的博客-CSDN 博客]
在过去的几十年里，集成电路制造工艺技术、封装与测试技术、设计方法学和 EDA 工具等微电子相关技术始终保持着快速的发展。根据国际半导体技术发展路线图（International Technology Roadmap for Semiconductors, ITRS）预测，到 2024 年 IC 制造技术将达到 2 nm。但是，全局互连线的性能提升程度明显低于晶体管性能提升程度。受到亚阈值漏电流功耗、动态功耗、器件可靠性以及全局互连线等影响，通过提升单个处理器核的性能来提升系统整体性能已变得非常难以实现，同时芯片设计的难度和复杂度也在进一步增加。片上系统（System on Chip, SoC）具有集成度高、功耗低、成本低、体积小等优点，已经成为超大规模集成电路系统设计的主流方向。随着片上系统 SoC 的应用需求越来越丰富、越来越复杂，片上多核 MPSoC (MultiprocessorSystem on Chip, MPSoC) 已经成为发展的必然趋势，同时 MPSoC 上集成的 IP 核数量也将会按照摩尔定律继续发展。目前，MPSoC 已经逐渐应用于网络通信、多媒体等嵌入式电子设备中。半导体工艺技术的快速发展为集成电路设计提供了很大的发展空间，同时也带来了一系列新的问题和挑战，如芯片的性能、功耗、可靠性、可扩展性等等。
随着系统性能需求越来越高，处理器核之间的互连架构必须能够提供具有较低延迟和高吞吐率的服务，并且具有良好的可扩展性。传统的基于总线的集中式互连架构已经难以满足现今系统的性能需求，而基于报文交换的**片上网络（Network on Chip, NoC）**逐渐成为片上多核间通讯的首选互连架构。在 NoC 中，路由节点之间通过局部互连线相连接，每一个路由节点通过网络接口 NI 与一个本地 IP 核相连接，源路由节点和目的路由节点之间的数据通讯需要经过多个跳步来实现。因此，NoC 技术的出现使得片上系统 SoC 的设计也将从以计算为中心逐渐过渡到以通讯为中心。
传统的 SoC 系统采用总线互连结构，如 所示。虽然人们已经提出了很多改进的总线结构，例如将共享总线改进为桥接多总线结构、层次化总线结构等更复杂的结构。但是当进入 MPSoC 时代，单芯片上集成的处理器核数越来越多时，总线结构在通讯性能、功耗、全局时钟同步、信号完整性以及信号可靠性等方面面临着巨大的挑战，这些复杂的改进型总线结构仍无法解决片上多核间通信所面临的问题。因此，MPSoC 上多核间的通讯问题已经成为制约系统性能提升的主要瓶颈。
NoC 的概念是由 Agarwal（1999 年）、Guerrier 和 Greiner（2000 年）、Dally 和 Towles（2001 年）、Benini 和 Micheli（2002 年）、Jantsch 和 Tenhunen（2003 年）等人逐步提出的。目前，对于 NoC 还没有一个统一的定义，大多数 NoC 研究者认为 NoC 是 SoC 系统的通讯子集，并且应该引入互联网络技术来解决片上多核的通讯问题。</description>
    </item>
    <item>
      <title>构建和测试 RISC-V 架构下启用 ACPI 的内核</title>
      <link>http://localhost:8888/posts/%E6%9E%84%E5%BB%BA%E5%92%8C%E6%B5%8B%E8%AF%95risc-v%E6%9E%B6%E6%9E%84%E4%B8%8B%E5%90%AF%E7%94%A8acpi%E7%9A%84%E5%86%85%E6%A0%B8/</link>
      <pubDate>Tue, 12 Jul 2022 15:06:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%9E%84%E5%BB%BA%E5%92%8C%E6%B5%8B%E8%AF%95risc-v%E6%9E%B6%E6%9E%84%E4%B8%8B%E5%90%AF%E7%94%A8acpi%E7%9A%84%E5%86%85%E6%A0%B8/</guid>
      <description>参考自PoC : How to build and test ACPI enabled kernel · riscv-non-isa/riscv-acpi Wiki
准备环境及工具链 安装 RISC-V 工具链，需下载原发行版。好在 apt 可以安装。
如果报错：riscv64-linux-gnu-gcc: error: unrecognized command line option ‘-mno-relax’; did you mean ‘-Wno-vla’?，多半是工具链原因，请按照以下方法安装！！！
sudo apt remove gcc-riscv64-linux-gnu sudo apt install gcc-8-riscv64-linux-gnu 安装必要的三方库，以下为Ubuntu下的命令，其他平台可以参考这个文档。
sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \ gawk build-essential bison flex texinfo gperf libtool patchutils bc \ zlib1g-dev libexpat-dev git 下载源码 可能无法一次搭建成功，一些环境变量会经常用到，所以干脆把所有环境变量放到.bashrc。
vim ~/.bashrc # 添加以下内容 export WORK_DIR=~/riscv64-acpi export GCC5_RISCV64_PREFIX=riscv64-unknown-elf- export MAINSPACE=~/riscv64-acpi/tianocore export PACKAGES_PATH=$MAINSPACE/edk2:$MAINSPACE/edk2-platforms export EDK_TOOLS_PATH=$MAINSPACE/edk2/BaseTools 首先，创建一个工作目录，我们将在其中下载并构建所有源代码。</description>
    </item>
    <item>
      <title>CSAPP-LAB-Cache Lab</title>
      <link>http://localhost:8888/posts/csapp-lab-cache-lab/</link>
      <pubDate>Mon, 11 Jul 2022 09:55:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/csapp-lab-cache-lab/</guid>
      <description>预备知识 开始这个实验前，需要学习《CSAPP 第六章-存储器层次结构》的相关内容，与缓存相关的内容，我也做了相关的CPU Cache 高速缓存学习记录可以参考。
实验相关的文件可以从CS:APP3e, Bryant and O&amp;rsquo;Hallaron下载。
其中，
README：介绍实验目的和实验要求，以及实验的相关文件。需要注意的是，必须在 64-bit x86-64 system 上运行实验。需要安装 Valgrind 工具。 Writeup：实验指导。 Release Notes：版本发布信息。 Self-Study Handout：需要下载的压缩包，里面包含了待修改的源码文件等。 下载 Self-Study Handout 并解压，得到如下文件：
├── cachelab.c # 一些辅助函数，如打印输出等，不需要修改 ├── cachelab.h # 同上 ├── csim.c # 需要完善的主文件，需要在这里模拟Cache ├── csim-ref # 已经编译好的程序，我们模拟的Cache需要与这个程序运行的结果保持一致 ├── driver.py # 驱动程序，运行 test-csim 和 test-trans ├── Makefile # 用来编译csim程序 ├── README # ├── test-csim # 测试缓存模拟器 ├── test-trans.c # 测试转置功能 ├── tracegen.c # test-trans 辅助程序 ├── traces # test-csim.</description>
    </item>
    <item>
      <title>CPU Cache 高速缓存</title>
      <link>http://localhost:8888/posts/cpu-cache%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Sun, 10 Jul 2022 10:43:17 +0000</pubDate>
      <guid>http://localhost:8888/posts/cpu-cache%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</guid>
      <description>存储器的层次结构 从 Cache、内存，到 SSD 和 HDD 硬盘，一台现代计算机中，就用上了所有这些存储器设备。其中，容量越小的设备速度越快，而且，CPU 并不是直接和每一种存储器设备打交道，而是每一种存储器设备，只和它相邻的存储设备打交道。比如，CPUCache 是从内存里加载而来的，或者需要写回内存，并不会直接写回数据到硬盘，也不会直接从硬盘加载数据到 CPUCache 中，而是先加载到内存，再从内存加载到 Cache 中。
这样，各个存储器只和相邻的一层存储器打交道，并且随着一层层向下，存储器的容量逐层增大，访问速度逐层变慢，而单位存储成本也逐层下降，也就构成了我们日常所说的存储器层次结构。
高速缓存 缓存不是 CPU 的专属功能，可以把它当成一种策略，任何时候想要增加数据传输性能，都可以通过加一层缓存试试。
存储器层次结构的中心思想是，对于每个$k$，位于$k$层的更快更小的存储设备作为位于$k+1$层的更大更慢的存储设备的缓存。下图展示了存储器层次结构中缓存的一般性概念。
数据总是以块block为单位，在层与层之间来回复制。
说回高速缓存，按照摩尔定律，CPU 的访问速度每 18 个月便会翻一翻，相当于每年增长 60%。内存的访问速度虽然不断增长，却远没有那么快，每年只增长 7% 左右。这样就导致 CPU 性能和内存访问的差距不断拉大。为了弥补两者之间差异，现代 CPU 引入了高速缓存。
CPU 的读（load）实质上就是从缓存中读取数据到寄存器（register）里，在多级缓存的架构中，如果缓存中找不到数据（Cache miss），就会层层读取二级缓存三级缓存，一旦所有的缓存里都找不到对应的数据，就要去内存里寻址了。寻址到的数据首先放到寄存器里，其副本会驻留到 CPU 的缓存中。
CPU 的写（store）也是针对缓存作写入。并不会直接和内存打交道，而是通过某种机制实现数据从缓存到内存的写回（write back）。
缓存到底如何与 CPU 和主存数据交换的？CPU 如何从缓存中读写数据的？缓存中没有读的数据，或者缓存写满了怎么办？我们先从 CPU 如何读取数据说起。
缓存读取 CPU 发起一个读取请求后，返回的结果会有如下几种情况：
缓存命中 (cache hit) 要读取的数据刚好在缓存中，叫做缓存命中。 缓存不命中 (cache miss) 发送缓存不命中，缓存就得执行一直放置策略(placement policy)，比如 LRU。来决定从主存中取出的数据放到哪里。 强制性不命中(compulsory miss)/冷不命中(cold miss)：缓存中没有要读取的数据，需要从主存读取数据，并将数据放入缓存。 冲突不命中(conflict miss)：缓存中有要读的数据，在采取放置策略时，从主存中取数据放到缓存时发生了冲突，这叫做冲突不命中。 高速缓存存储器组织结构 整个 Cache 被划分为 1 个或多个组 (Set)，$S$ 表示组的个数。每个组包含 1 个或多个缓存行(Cache line)，$E$ 表示一个组中缓存行的行数。每个缓存行由三部分组成：有效位(valid)，标记位（tag），数据块（cache block）。</description>
    </item>
    <item>
      <title>密码管理器-KeePass</title>
      <link>http://localhost:8888/posts/%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%99%A8-keepass/</link>
      <pubDate>Sat, 09 Jul 2022 19:11:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%99%A8-keepass/</guid>
      <description>KeePass 安装 下载与安装
官网： https://keepass.info/download.html
下载完成后进行安装，默认安装位置是：C:\Program Files (x86)\KeePass Password Safe 2文件夹下，可以根据自己需要选择安装路径。
更改中文语言
中文语言包： KeePass-Chinese_Simplified
将语言包下载后复制到安装路径下的Languages文件夹下，默认为：C:\Program Files (x86)\KeePass Password Safe 2\Languages。重启软件。
点击 View-&amp;gt;Change Language. 选择中文简体（Chinese-Simplified）。重启软件，即可完成语言更改。
中文界面：
基本使用 1.创建一个数据库
点击 文件-》新建。弹出对话框为数据库创建管理密码。这个密码是唯一需要记忆的密码。当然如果追求更高的安全性，可以点击显示高级选项，提供更多的密码选项。
2.添加记录
点击添加记录，在弹出的窗口填入相关信息。即可完成密码添加。
如果是第一次使用的网站，第一次注册密码。可以通过密码生成器，生成一个高强度的密码来添加记录。
3.创建一个密码生成模板
正常国内的网站可以使用的密码长度 6-16 位，可以使用大小写，数字，下划线。我们把这些选项勾选，密码长度设置 16 位。
点击保存并给模板设置个名字方便下次使用
如果保存后想更改一下，比如再加个可以使用空格，可以重新勾选刚刚的选项，保存时点击小三角，选择刚刚保存的方案就可以覆盖。
导入 Chrome 已保存的密码
很多小伙伴在使用 KeePass 之前肯定在 Chrome 等浏览器里也保存了很多密码。想将其导入 KeePass 方便管理。Chrome 是可以导出密码的，KeePass 也可以导入密码。
点击浏览器右上角，打开设置界面。找到密码
找到已保存的密码-》导出密码。选择方便找到的路径，保存密码记录。
打开 KeePass，点击文件-》导入，选择 Chrome 浏览器的格式。点击文件夹图标找到刚刚导出的密码文件。
高级配置 KeePass 搭配坚果云实现云同步 登录坚果云创建个人同步文件夹，若没有先注册。
最好单独建一个专门的文件夹
将已经生成的数据库上传到这个文件夹下
点击右上角进入账户信息，点击安全选项：
点击添加应用
输入应用名称，应用名称只是方便区分作用，所以和要同步的应用名称一致就好：
点击生成密码：
此时云盘端配置完成，切回到 KeePass 进行客户端配置。点击文件-》同步-》与网址（URL）同步</description>
    </item>
    <item>
      <title>volatile 能否解决缓存一致性问题</title>
      <link>http://localhost:8888/posts/volatile%E8%83%BD%E5%90%A6%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 08 Jul 2022 09:10:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/volatile%E8%83%BD%E5%90%A6%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</guid>
      <description>volatile 能否解决缓存一致性问题 为何会产生这样的疑问，还得从一个工作中的 Bug 说起。在使用 PMP（Physical Memory Protect）对物理内存进行保护时，无法成功保护，简单来说 PMP 可以对一段物理内存设置保护，如保护这段内存不可写。测试时，先对这段内存写入0x1234，再读取这段内存。如果读取的值为0x0表示保护成功，但实际总能成功读取0x1234。
volatile int test; test = read(0xFF740000); print(&amp;#34;Before = %x\n&amp;#34;, test); // 保护之前数据 Before = 0x1111 PMP(0xFF740000, 0x400); // 保护这段内存不可写 write(0xFF740000, 0x1234); // 写入数据 test = read(0xFF740000); print(&amp;#34;After = %x\n&amp;#34;, test); // 预期读取为0x0，实际总能成功读取0x1234 因为读取的变量test设置为volatile，所以按照以往的理解，系统总是重新从它所在的内存读取数据，这里应该能正确读取出数据。
但是忽略了一点，当使用volatile变量时，CPU 只是不再使用寄存器中的值，直接去内存中读取数据，这里的内存实际上是包括 Cache 的。
所以当数据被 Cached 之后，当再次读取时，CPU 可能会直接读取 Cached 的数据，而不是去读取真正内存中的数据。因此，volatile 不能解决缓存一致性问题。
关于 Cache 的详细信息，请参考CPU Cache 高速缓存 - 如云泊。</description>
    </item>
    <item>
      <title>ZH-CS 可视化 - 常用的 Git 命令</title>
      <link>http://localhost:8888/posts/zh-cs%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%B8%B8%E7%94%A8%E7%9A%84git%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Thu, 07 Jul 2022 16:20:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-cs%E5%8F%AF%E8%A7%86%E5%8C%96-%E5%B8%B8%E7%94%A8%E7%9A%84git%E5%91%BD%E4%BB%A4/</guid>
      <description>CS 可视化 - 常用的 Git 命令 Author：Lydia Hallie 译：🌳🚀 CS Visualized: Useful Git Commands - DEV Community
尽管 Git 是一个非常强大的工具，但我想大多数人都会同意，当我说它也可能是……一场彻头彻尾的噩梦当我执行某个命令时分支交互，它将如何影响历史记录？当我在master分支执行hard reset、force push到 origin、在.git文件夹执行rimraf的时候，为什么我的同事都哭了？
我认为这将是创建一些最常见和最有用命令的可视化示例的完美用例！我介绍的许多命令都有可选参数，您可以使用这些参数来更改它们的行为。在我的示例中，我将介绍命令的默认行为，而不添加（太多）配置选项！
Merging 拥有多个分支非常方便，可以将新更改彼此分开，并确保您不会意外地将未经批准或损坏的更改推送到生产环境。一旦更改获得批准，我们希望在我们的生产分支中获得这些更改！
将更改从一个分支转移到另一个分支的一种方法是执行 git merge！Git 可以执行两种类型的合并：fast-forward 或​​ no-fast-forward。
现在这可能没有多大意义，所以让我们看看差异！
Fast-forward (--ff) 如果当前分支与即将合并过来的分支相比，没有额外的提交，这种就是fast-forward合并。Git 很会偷懒，它会首先尝试最简单的方案，即fast-forward。这种合并方式不会创建新的提交，只是把另一个分支的提交记录直接合并到当前分支。
完美的！我们现在可以在 master 分支上使用在 dev 分支上所做的所有更改。那么，no-fast-forward 到底是什么？
No-fast-foward (--no-ff) 如果与您要合并的分支相比，您当前的分支没有任何额外的提交，那就太好了，但不幸的是，这种情况很少见！如果我们在当前分支上提交了我们想要合并的分支没有的更改，Git 将执行 no-fast-forward 合并。
使用 no-fast-forward 合并，Git 在活动分支上创建一个新的合并提交。提交的父提交指向活动分支和我们要合并的分支！
没什么大不了的，完美的合并！ master 分支现在包含我们在 dev 分支上所做的所有更改。
Merge Conflicts 尽管 Git 擅长决定如何合并分支和向文件添加更改，但它不能总是自己做出这个决定。当我们尝试合并的两个分支在同一个文件的同一行上发生更改时，可能会发生这种情况，或者如果一个分支删除了另一个分支修改的文件，等等。
在这种情况下，Git 会要求您帮助决定我们要保留两个选项中的哪一个！假设在两个分支上，我们编辑了 README.md 中的第一行。
如果我们想将 dev 合并到 master 中，这将导致合并冲突：您希望标题是 Hello!</description>
    </item>
    <item>
      <title>C语言数组/结构体/结构体数组/联合体初始化</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84-%E7%BB%93%E6%9E%84%E4%BD%93-%E7%BB%93%E6%9E%84%E4%BD%93%E6%95%B0%E7%BB%84-%E8%81%94%E5%90%88%E4%BD%93%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
      <pubDate>Thu, 30 Jun 2022 15:30:41 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E6%95%B0%E7%BB%84-%E7%BB%93%E6%9E%84%E4%BD%93-%E7%BB%93%E6%9E%84%E4%BD%93%E6%95%B0%E7%BB%84-%E8%81%94%E5%90%88%E4%BD%93%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
      <description>数组初始化 int arr[6] = { [0]=5, [1]=6, [3] =10, [4]=11 }; 或 int arr[6] = { [0]=5, 6, [3] =10, 11 }; 或 int arr[6] = { [3] =10, 11, [0]=5, 6 }; (指定顺序可变) 均等效于：int arr[6] = {5, 6, 0, 10, 11, 0}; Note:
若在某个指定初始化项目后跟有不至一个值，如[3]=10,11。则多出的数值用于对后续的数组元素进行初始化，即数值 11 用来初始化 arr[4]。 C 数组初始化一个或多个元素后，未初始化的元素将被自动地初始化为 0 或 NULL(针对指针变量)。未经过任何初始化的数组，所有元素的值都是不确定的。 GNU C 还支持[first … last]=value(…两侧有空格) 的形式，将该范围内的若干元素初始化为相同值。如：
int arr[]={ [0 ... 3]=1, [4 ... 5]=2, [6 ... 9] =3}; 或 int arr[]={ [0 .</description>
    </item>
    <item>
      <title>每天学命令-watch 周期执行命令</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-watch%E5%91%A8%E6%9C%9F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Thu, 09 Jun 2022 22:50:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-watch%E5%91%A8%E6%9C%9F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/</guid>
      <description>功能 watch 命令的功能如其名，可以监视命令的执行结果。它实现的原理就是每隔一段时间执行一次命令，然后显示结果。他的用途很广，具体怎么用就靠想象力了。
命令参数 -n # 或--interval watch默认每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。-d # 或--differences 用-d或--differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。-t # 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。-h # 或--help # 查看帮助文档 实例 watch -d &amp;#39;ls -l | grep tmp&amp;#39; # 监测当前目录中 scf&amp;#39; 的文件的变化 </description>
    </item>
    <item>
      <title>Git hooks 钩子的使用</title>
      <link>http://localhost:8888/posts/git-hooks%E9%92%A9%E5%AD%90%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 30 May 2022 12:16:11 +0000</pubDate>
      <guid>http://localhost:8888/posts/git-hooks%E9%92%A9%E5%AD%90%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>Git hooks 简介 Git 能在特定的重要动作发生时触发自定义脚本。比如，commit之前检查commit message是否符合约定的格式，push之前检查代码格式是否正确，是否编译通过等等。Git 就提供了hooks这样的机制。
我们在哪能找到hooks呢？在初始化代码仓库git init时，Git 会自动为我们创建一个.git/hooks目录，里面存放了所有的钩子。因为.git是隐藏目录，显示隐藏目录后就可以找到hooks这个目录。
在 VSCode 里一般默认把.git目录排除显示，所以打开项目目录时不会显示该目录，我们可以收到在 VSCode 显示.git目录：打开设置界面，搜索exclude找到图中的设置，将.git目录从排除列表中移除，即可在 VSCode 中显示.git目录。
现在我们找到了hooks，该如何使用呢？ 所有默认的hooks都是以.sample为后缀，只需要移除.sample即可激活hooks。
随便打开一个hooks文件，我们可以发现，实际是hooks就是一个个shell脚本。这些脚本会在特定的动作发生时被执行。示范的这些hooks都是shell脚本，实际上只要是文件名正确的可执行脚本都可以使用，如将pre-push内容改为python, Ruby等等脚本都可以。
如何使用一个 hooks 以pre-commit这个hooks为例，来示范一下如何使用 Git hooks。
打开.git/hooks/pre-commit.sample，这个hooks的大体功能是检查文件名是否包含非ASCII字符，如果包含，则无法执行commit操作，并提示用户修改文件名。
删除pre-commit.sample的后缀
➜ mv .git/hooks/pre-commit.sample .git/hooks/pre-commit 添加一个有汉字的文件名，如测试.md
➜ touch 测试.md 将新文件提交
➜ git add 测试.md➜ git commit -m &amp;#34;测试&amp;#34;Error: Attempt to add a non-ASCII file name.This can cause problems if you want to work with people on other platforms.To be portable it is advisable to rename the file.</description>
    </item>
    <item>
      <title>CPU 缓存一致性 MESI 协议</title>
      <link>http://localhost:8888/posts/cpu%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7mesi%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Sun, 29 May 2022 15:04:59 +0000</pubDate>
      <guid>http://localhost:8888/posts/cpu%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7mesi%E5%8D%8F%E8%AE%AE/</guid>
      <description>为什么需要缓存一致 目前主流电脑的 CPU 都是多核心的，多核心的有点就是在不能提升 CPU 主频后，通过增加核心来提升 CPU 吞吐量。每个核心都有自己的 L1 Cache 和 L2 Cache，只是共用 L3 Cache 和主内存。每个核心操作是独立的，每个核心的 Cache 就不是同步更新的，这样就会带来缓存一致性（Cache Coherence）的问题。
举个例子，如图： 有 2 个 CPU，主内存里有个变量x=0。CPU A 中有个需要将变量x加1。CPU A 就将变量x加载到自己的缓存中，然后将变量x加1。因为此时 CPU A 还未将缓存数据写回主内存，CPU B 再读取变量x时，变量x的值依然是0。
这里的问题就是所谓的缓存一致性问题，因为 CPU A 的缓存与 CPU B 的缓存是不一致的。
如何解决缓存一致性问题 通过在总线加 LOCK 锁的方式 在锁住总线上加一个 LOCK 标识，CPU A 进行读写操作时，锁住总线，其他 CPU 此时无法进行内存读写操作，只有等解锁了才能进行操作。
该方式因为锁住了整个总线，所以效率低。
缓存一致性协议 MESI 该方式对单个缓存行的数据进行加锁，不会影响到内存其他数据的读写。
在学习 MESI 协议之前，简单了解一下总线嗅探机制（Bus Snooping）。要对自己的缓存加锁，需要通知其他 CPU，多个 CPU 核心之间的数据传播问题。最常见的一种解决方案就是总线嗅探。
这个策略，本质上就是把所有的读写请求都通过总线广播给所有的 CPU 核心，然后让各个核心去“嗅探”这些请求，再根据本地的情况进行响应。MESI 就是基于总线嗅探机制的缓存一致性协议。
MESI 协议的由来是对 Cache Line 的四个不同的标记，分别是：</description>
    </item>
    <item>
      <title>VSCode 设置终端为 Gitbash</title>
      <link>http://localhost:8888/posts/vscode%E8%AE%BE%E7%BD%AE%E7%BB%88%E7%AB%AF%E4%B8%BAgitbash/</link>
      <pubDate>Tue, 24 May 2022 14:42:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E8%AE%BE%E7%BD%AE%E7%BB%88%E7%AB%AF%E4%B8%BAgitbash/</guid>
      <description>设置终端为 Gitbash 用惯了 Linux 终端的命令，Windows 的 shell 真的太不顺手了，但是 Gitbash 很多命令相似，可以将默认的 shell 换成 Gitbash。
打开settings.json配置文件，添加如下
&amp;#34;terminal.integrated.profiles.windows&amp;#34;: { &amp;#34;PowerShell -NoProfile&amp;#34;: { &amp;#34;source&amp;#34;: &amp;#34;PowerShell&amp;#34;, &amp;#34;args&amp;#34;: [ &amp;#34;-NoProfile&amp;#34; ] }, &amp;#34;Git-Bash&amp;#34;: { &amp;#34;path&amp;#34;: &amp;#34;D:\\Software\\Git\\bin\\bash.exe&amp;#34;, //bin路径下的bash，不是git-bash.exe。否则会打开外部窗口 &amp;#34;args&amp;#34;: [] } }, &amp;#34;terminal.integrated.defaultProfile.windows&amp;#34;: &amp;#34;Git-Bash&amp;#34;, 修改终端配色 打开Base16 Terminal Colors for Visual Studio Code，选择一款配置复制
打开 VScodesettings.json，替换如下
&amp;#34;workbench.colorCustomizations&amp;#34;: { &amp;#34;terminal.background&amp;#34;:&amp;#34;#1C2023&amp;#34;, &amp;#34;terminal.foreground&amp;#34;:&amp;#34;#C7CCD1&amp;#34;, &amp;#34;terminalCursor.background&amp;#34;:&amp;#34;#C7CCD1&amp;#34;, &amp;#34;terminalCursor.foreground&amp;#34;:&amp;#34;#C7CCD1&amp;#34;, &amp;#34;terminal.ansiBlack&amp;#34;:&amp;#34;#1C2023&amp;#34;, &amp;#34;terminal.ansiBlue&amp;#34;:&amp;#34;#AE95C7&amp;#34;, &amp;#34;terminal.ansiBrightBlack&amp;#34;:&amp;#34;#747C84&amp;#34;, &amp;#34;terminal.ansiBrightBlue&amp;#34;:&amp;#34;#AE95C7&amp;#34;, &amp;#34;terminal.ansiBrightCyan&amp;#34;:&amp;#34;#95AEC7&amp;#34;, &amp;#34;terminal.ansiBrightGreen&amp;#34;:&amp;#34;#95C7AE&amp;#34;, &amp;#34;terminal.ansiBrightMagenta&amp;#34;:&amp;#34;#C795AE&amp;#34;, &amp;#34;terminal.ansiBrightRed&amp;#34;:&amp;#34;#C7AE95&amp;#34;, &amp;#34;terminal.ansiBrightWhite&amp;#34;:&amp;#34;#F3F4F5&amp;#34;, &amp;#34;terminal.ansiBrightYellow&amp;#34;:&amp;#34;#AEC795&amp;#34;, &amp;#34;terminal.ansiCyan&amp;#34;:&amp;#34;#95AEC7&amp;#34;, &amp;#34;terminal.ansiGreen&amp;#34;:&amp;#34;#95C7AE&amp;#34;, &amp;#34;terminal.ansiMagenta&amp;#34;:&amp;#34;#C795AE&amp;#34;, &amp;#34;terminal.ansiRed&amp;#34;:&amp;#34;#C7AE95&amp;#34;, &amp;#34;terminal.ansiWhite&amp;#34;:&amp;#34;#C7CCD1&amp;#34;, &amp;#34;terminal.ansiYellow&amp;#34;:&amp;#34;#AEC795&amp;#34; }, 修改后效果</description>
    </item>
    <item>
      <title>CPU 亲和性与中断亲和性</title>
      <link>http://localhost:8888/posts/cpu%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E4%B8%AD%E6%96%AD%E4%BA%B2%E5%92%8C%E6%80%A7/</link>
      <pubDate>Mon, 23 May 2022 22:38:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/cpu%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E4%B8%AD%E6%96%AD%E4%BA%B2%E5%92%8C%E6%80%A7/</guid>
      <description>预备知识 超线程技术 (Hyper-Threading)：就是利用特殊的硬件指令，把两个逻辑内核 (CPU core) 模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了 CPU 的闲置时间，提高的 CPU 的运行效率。
我们常听到的双核四线程/四核八线程指的就是支持超线程技术的CPU.
物理 CPU：机器上安装的实际 CPU, 比如说你的主板上安装了一个 8 核 CPU，那么物理 CPU 个数就是 1 个，所以物理 CPU 个数就是主板上安装的 CPU 个数。
逻辑 CPU：一般情况，我们认为一颗 CPU 可以有多核，加上 Intel 的超线程技术 (HT), 可以在逻辑上再分一倍数量的 CPU core 出来；
逻辑CPU数量 = 物理CPU数量 x CPU cores x 2(如果支持并开启HT) //前提是CPU的型号一致，如果不一致只能一个一个的加起来，不用直接乘以物理CPU数量//比如你的电脑安装了一块4核CPU，并且支持且开启了超线程（HT）技术，那么逻辑CPU数量 = 1 × 4 × 2 = 8 Linux 下查看 CPU 相关信息, CPU 的信息主要都在/proc/cupinfo中。
# 查看物理CPU个数➜ ~ cat /proc/cpuinfo|grep &amp;#34;physical id&amp;#34;|sort -u|wc -l32# 查看每个物理CPU中core的个数(即核数)➜ ~ cat /proc/cpuinfo|grep &amp;#34;cpu cores&amp;#34;|uniq1# 或者➜ cat /proc/cpuinfo | grep &amp;#39;process&amp;#39; | sort | uniq | wc -l1# 查看逻辑CPU的个数➜ ~ cat /proc/cpuinfo|grep &amp;#34;processor&amp;#34;|wc -l32# 查看CPU的名称型号➜ ~ cat /proc/cpuinfo|grep &amp;#34;name&amp;#34;|cut -f2 -d:|uniqIntel Xeon Processor (Skylake, IBRS) Linux 查看某个进程运行在哪个逻辑 CPU 上</description>
    </item>
    <item>
      <title>SoC 存储器比较</title>
      <link>http://localhost:8888/posts/soc%E5%AD%98%E5%82%A8%E5%99%A8%E6%AF%94%E8%BE%83/</link>
      <pubDate>Sat, 21 May 2022 17:13:33 +0000</pubDate>
      <guid>http://localhost:8888/posts/soc%E5%AD%98%E5%82%A8%E5%99%A8%E6%AF%94%E8%BE%83/</guid>
      <description>内存 也就是内部存储器，主要用来运行程序的，典型的就是 RAM 随机存储器（Random Access Memory），那么随机是什么意思？所谓随机，指的是当存储器中的数据被读取或写入时，所需要的时间与这段信息所在的位置无关（任何位置读写速度一样）。
DRAM（Dynamic Random Access Memory，动态随机存储器）是最为常见的系统内存。我们使用的电脑和手机的运行内存都是 DRAM。DRAM 使用电容存储，DRAM 只能将数据保持很短的时间。为了保持数据，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。数据的存储，请参考数据存储模型。我们知道，电容中的电荷很容易变化，所以随着时间推移，电容中的电荷数会增加或减少，为了确保数据不会丢失，DRAM 每隔一段时间会给电容刷新（充电或放电）。动态：定时刷新数据
SRAM（Static Random Access Memory，静态随机存储器），它是一种具有静止存取功能的内存，其内部机构比 DRAM 复杂，可以做到不刷新电路即能保存它内部存储的数据。静态：不需要刷新
DDR SDRAM（Double Data Rate SDRAM）：为双信道同步动态随机存取内存，是新一代的 SDRAM 技术。DDR 内存芯片的数据预取宽度（Prefetch）为 2 bit（SDRAM 的两倍）。
DDR2 SDRAM（Double Data Rate Two SDRAM）：为双信道两次同步动态随机存取内存。DDR2 内存 Prefetch 又再度提升至 4 bit（DDR 的两倍）
DDR3 SDRAM（Double Data Rate Three SDRAM）：为双信道三次同步动态随机存取内存。DDR3 内存 Prefetch 提升至 8 bit，即每次会存取 8 bits 为一组的数据。运算频率介于 800MHz -1600MHz 之间。
外存 外部存储器，通常用来存储文件的，一般也叫 ROM（Read-only memory）只读存储器。
CPU 连接内存和外存的连接方式不同。内存需要直接地址访问，所以是通过地址总线&amp;amp;数据总线的总线式访问方式连接的（好处是直接访问，随机访问；坏处是占用 CPU 的地址空间，大小受限）；外存是通过 CPU 的外存接口来连接的（好处是不占用 CPU 的地址空间，坏处是访问速度没有总线式快，访问时序较复杂）</description>
    </item>
    <item>
      <title>Interlaken 协议</title>
      <link>http://localhost:8888/posts/interlaken%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Wed, 18 May 2022 22:40:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/interlaken%E5%8D%8F%E8%AE%AE/</guid>
      <description>对 Interlaken 协议文档的翻译加了一些自己的理解；
8b/10b编码：在串行通道上传输时，将 8bits 数据编码为 10bits 数据，做一个转换，使各位数据之间有更多的 1 到 0 和 0 到 1 的跳变，以便接收设备检测这些跳变，能更容易地恢复时钟。64B/67B 编码编码的原因也是类似的。这样，在串行通道上传输 10 位数据，实际上只传输了 8 位。
协议层（Protocol Layer） 传输格式 数据通过可配置数量的 SerDes 通道（Lane），再由 Interlaken 接口传输。在本文档中，通道被定义为两个 IC 之间的单工串行链路（simplex serial link）。该协议旨在与任意数量的通道一起运行（1 个或多个，没有上限）。实际实现时会固定一个数值，不会设计为可变值。
接口发送数据的基本单位是一个 8 字节的字（Word）。用 8 字节是为了符合64B/67B 编码，用于描述突发（Burst）的控制字的大小也是 8 字节。通过使基本传输单元与控制字大小相等，可以很容易地调整接口的宽度。
数据和控制字按顺序在通道上传输，从通道 0 开始，到通道 M 结束，并在下一个数据块中重复。图 4 说明了该过程
64B/67B编码在每个通道上独立进行。传输通过两种基本数据类型实现：数据字和控制字，他们通过64B/67B 帧位（framing bits）进行区分。这两种数据字类型的格式如下图所示：
数据和控制信息都是以位 66～0 的顺序传输的，框架层引入了 4 个附加控制字，详细信息后面将描述。
Burst 结构（Burst Structure） 数据传输流程 Interlaken 接口的带宽在支持的通道上被划分为 Bursts。数据包通过一个或多个 Burst 在接口上传输。Burst 通过一个或多个控制字来描述。为了将任意大小的数据包分割成 Burst，定义以下两个参数：
BurstMax：Burst 的最大大小（64Bytes 的倍数） BurstShort：Burst 的最小大小（最小 32Bytes，增量为 8Bytes） 该接口通常通过发送一个 BurstMax 长度的数据突发来运行，然后是一个控制字。发送设备中的调度逻辑可以自由选择信道服务的顺序，受流控状态的约束。Burst 在每个通道上传输，直到数据包完全传输，此时该通道上的新数据包传输才开始。</description>
    </item>
    <item>
      <title>AMBA 总线协议-AXI 协议</title>
      <link>http://localhost:8888/posts/amba%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE-axi%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Tue, 17 May 2022 21:16:45 +0000</pubDate>
      <guid>http://localhost:8888/posts/amba%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE-axi%E5%8D%8F%E8%AE%AE/</guid>
      <description>AXI 组成部分：
AXI4 协议中包含五种信道，通道之间相互独立且存在差别，通过通道进行通信之前需要使用 VALID/READY 进行握手，Read 和 Write 根据 Master 定义：
读地址信道（Read Address Channel） 写地址信道（Write Address Channel） 读数据信道（Read Data Channel） 写数据信道（Write Data Channel） 写响应信道（Write Response Channel） 还有两种 Component
Master component Slave component 通信由 Master 发起，Master 可以对 Slave 进行读数据（read）或写（write）数据。每次读写操作都需要一个地址，读地址信道（Read Address Channel）和写地址信道（Write Address Channel）用于传输地址。在写完数据后，Master 需要确认 Slave 有没有收完数据，Slave 收到完整数据后，会通过写响应信道（Write Response Channel）给 Master 一个反馈（completion），表示写操作已经完成。
VALID/READY 握手机制 AXI 五个信道相互独立，但是使用同一个握手机制来实现信息传递。
在握手机制中，通信双方分别扮演发送方(Source) 和接收方（Destination），两者的操作（技能）并不相同。
发送方置高 VALID 信号表示发送方已经将数据，地址或者控制信息已经就绪，并保持于消息总线上。
接收方置高 READY 信号表示接收方已经做好接收的准备。
当双方的 VALID/READY 信号同时为高，在时钟 ACLK 上升沿，完成一次数据传输。所有数据传输完毕后，双方同时置低自己的信号。
每个通道都有自己的 VALID /READY 握手信号对：</description>
    </item>
    <item>
      <title>C 语言实现简单有限状态机</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA/</link>
      <pubDate>Sun, 15 May 2022 12:41:30 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA/</guid>
      <description>简介 常说的状态机是有限状态机 FSM，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型。 三个特征：
状态总数（state）是有限的。 任一时刻，只处在一种状态之中。 某种条件下，会从一种状态转变（transition）到另一种状态。 设计状态机的关键点：当前状态、外部输入、下一个状态。
状态机分类 Moore 型状态机 Moore 型状态机特点是：输出只与当前状态有关（与输入信号无关）。相对简单，考虑状态机的下一个状态时只需要考虑它的当前状态就行了。
Mealy 型状态机 Mealy 型状态机的特点是：输出不只和当前状态有关，还与输入信号有关。状态机接收到一个输入信号需要跳转到下一个状态时，状态机综合考虑 2 个条件（当前状态、输入值）后才决定跳转到哪个状态。
实现一个简单的状态机 代码参考AstarLight/FSM-framework。
以小明的一天设计出一个状态机，下图为状态转移图：
首先，有限状态机的状态是有限的，我们可以定义一天中的状态：
enum { GET_UP, GO_TO_SCHOOL, HAVE_LUNCH, DO_HOMEWORK, SLEEP, }; 状态机在没有事件的驱动下就是一潭死水，所以我们还需要定义出一些会发生的事件，去驱动状态机的运转：
enum { EVENT1 = 1, EVENT2, EVENT3, }; 再定义一些在某个状态下需要处理的动作，也就是函数：
void GetUp() { // do something printf(&amp;#34;xiao ming gets up!\n&amp;#34;); } void Go2School() { // do something printf(&amp;#34;xiao ming goes to school!\n&amp;#34;); } void HaveLunch() { // do something printf(&amp;#34;xiao ming has lunch!</description>
    </item>
    <item>
      <title>链接脚本入门</title>
      <link>http://localhost:8888/posts/%E9%93%BE%E6%8E%A5%E8%84%9A%E6%9C%AC%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 08 May 2022 21:32:23 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E9%93%BE%E6%8E%A5%E8%84%9A%E6%9C%AC%E5%85%A5%E9%97%A8/</guid>
      <description>重定位 位置无关编码 (PIC，position independent code)：汇编源文件被编码成二进制可执行程序时编码方式与位置（内存地址）无关。
位置有关编码：汇编源码编码成二进制可执行程序后和内存地址是有关的。
我们在设计一个程序时，会给这个程序指定一个运行地址（链接地址）。就是说我们在编译程序时其实心里是知道我们程序将来被运行时的地址（运行地址）的，而且必须给编译器链接器指定这个地址（链接地址）才行。
最后得到的二进制程序理论上是和你指定的运行地址有关的，将来这个程序被执行时必须放在当时编译链接时给定的那个地址（链接地址）下才行，否则不能运行（就叫位置有关代码）。但是有个别特别的指令他可以跟指定的地址（链接地址）没有关系，也就是说这些代码实际运行时不管放在哪里都能正常运行。
运行地址：由运行时决定的（编译链接时是无法绝对确定运行时地址的）。
链接地址：由程序员在编译链接的过程中，通过Makefile中-Ttext xxx或者在链接脚本中指定的。程序员事先会预知自己的程序的执行要求，并且有一个期望的执行地址，并且会用这个地址来做链接地址。
举例：Linux 中的应用程序。gcc hello.c -o hello，这时使用默认的链接地址就是0x0，所以应用程序都是链接在0x0地址的。因为应用程序运行在操作系统的一个进程中，在这个进程中这个应用程序独享 4G 的虚拟地址空间。所以应用程序都可以链接到 0 地址，因为每个进程都是从 0 地址开始的。（编译时可以不给定链接地址而都使用0x0）
编译链接过程 每个过程的作用 预编译：预编译器执行。替换宏定义，删除注释等工作。 编译：编译器来执行。把源码.c .S编程机器码.o文件。 链接：链接器来执行。把.o文件中的各函数（段）按照一定规则（链接脚本来指定）累积在一起，形成可执行文件。 strip：strip 是把可执行程序中的符号信息给拿掉，以节省空间。（Debug 版本和 Release 版本） objcopy：由可执行程序生成可烧录的镜像bin文件。 编译后生成的段 段就是程序的一部分，我们把整个程序的所有东西分成了一个一个的段，给每个段起个名字，然后在链接时就可以用这个名字来指示这些段。也就是说给段命名就是为了在链接脚本中用段名来让段放在合适的位置。
段名分为 2 种：一种是编译器链接器内部定好的，一种是程序员自己指定的、自定义的段名。 已有段名：
代码段：（.text），又叫文本段，代码段其实就是函数编译后生成的东西 数据段：（.data），数据段就是 C 语言中有显式初始化为非 0 的全局变量 bss 段：（.bss），又叫 ZI（zero initial）段，就是零初始化段，对应 C 语言中初始化为 0 的全局变量。 自定义段名：段名由程序员自己定义，段的属性和特征也由程序员自己定义。 C 语言中全局变量如果未显式初始化，值是 0。本质就是 C 语言把这类全局变量放在了 bss 段，从而保证了为 0。 C 运行时环境如何保证显式初始化为非 0 的全局变量的值在 main 之前就被赋值了？就是因为它把这类变量放在了.data 段中，而.data 段会在 main 执行之前被处理（初始化）。</description>
    </item>
    <item>
      <title>计算机组成原理-存储与 IO 系统</title>
      <link>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Sun, 08 May 2022 10:48:23 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/</guid>
      <description>存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆。它用的是 SRAM 芯片。
SRAM 的“静态”的意思是，只要处于通电状态，里面的数据就保持存在，一旦断电，数据就会丢失。SRAM 里 1bit 数据需要 6-8 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间，能够存的数据有限。因为其电路简单，访问速度非常快。
在 CPU 里，通常会有 L1、L2、L3 这样三层高速缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，通常分成指令缓存和数据缓存，分开存放 CPU 使用的指令和数据。
L2 的 Cache 同样是每个 CPU 核心都有的，不过它往往不在 CPU 核心的内部。所以，L2 Cache 的访问速度会比 L1 稍微慢一些。而 L3Cache，则通常是多个 CPU 核心共用的，尺寸会更大一些，访问速度自然也就更慢一些。
你可以把 CPU 中的 L1Cache 理解为我们的短期记忆，把 L2/L3Cache 理解成长期记忆，把内存当成我们拥有的书架或者书桌。当我们自己记忆中没有资料的时候，可以从书桌或者书架上拿书来翻阅。这个过程中就相当于，数据从内存中加载到 CPU 的寄存器和 Cache 中，然后通过“大脑”，也就是 CPU，进行处理和运算。
DRAM（Dynamic Random Access Memory，动态随机存取存储器） 内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM 的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。</description>
    </item>
    <item>
      <title>计算机组成原理-处理器</title>
      <link>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%A4%84%E7%90%86%E5%99%A8/</link>
      <pubDate>Sun, 01 May 2022 15:42:11 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%A4%84%E7%90%86%E5%99%A8/</guid>
      <description>建立数据通路：指令 + 运算=CPU 指令周期
Fetch（取得指令）：从内存里把指令加载到指令寄存器中。 Decode（指令译码） Execute（执行指令） 重复操作这三步，这个循环称为指令周期。 不同的步骤在不同组件内完成 机器周期/CPU周期：从内存里读取一条指令的最短时间。 时钟周期：就是机器的主频，一个 CPU 周期由多个时钟周期组成。
操作元件：组合逻辑元件，ALU，功能是在特定的输入下，生成特定的输出。 存储元件：状态元件，寄存器。
将操作元件，操作原件通过数据总线的方式连接起来，就建立了数据通路了。
控制器：循环执行取址-译码，产生控制信号交给 ALU 处理。电路特别复杂，CPU 如果支持 2000 个指令，意味着控制器输出的信号有 2000 个不同的组合。
CPU 需要的电路
根据输入计算出结果的一个电路，ALU 能够进行状态读写的电路元件，寄存器 按照固定周期，不停实现 PC 寄存器自增的电路 译码电路，能够对于拿到的内存地址获取对应的数据或者指令 Q : CPU 好像一个永不停歇的机器，一直在不停地读取下一条指令去运行。那 为什么 CPU 还会有满载运行和 Idle 闲置的状态呢？ A：CPU 还会有满载运行和 Idle 闲置的状态，指的系统层面的状态。即使是 Idle 空闲状态，CPU 也在执行循环指令。 操作系统内核有 idle 进程，优先级最低，仅当其他进程都阻塞时被调度器选中。idle 进程循环执行 HLT 指令，关闭 CPU 大部分功能以降低功耗，收到中断信号时 CPU 恢复正常状态。CPU 在空闲状态就会停止执行，即切断时钟信号，CPU 主频会瞬间降低为 0，功耗也会瞬间降为 0。由于这个空闲状态是十分短暂的，所以你在任务管理器也只会看到 CPU 频率下降，不会看到降为 0。当 CPU 从空闲状态中恢复时，就会接通时钟信号，CPU 频率就会上升。所以你会在任务管理器里面看到 CPU 的频率起伏变化。</description>
    </item>
    <item>
      <title>替换 Gitee 图床为腾讯云 COS</title>
      <link>http://localhost:8888/posts/%E6%9B%BF%E6%8D%A2gitee%E5%9B%BE%E5%BA%8A%E4%B8%BA%E8%85%BE%E8%AE%AF%E4%BA%91cos/</link>
      <pubDate>Sat, 09 Apr 2022 16:43:08 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%9B%BF%E6%8D%A2gitee%E5%9B%BE%E5%BA%8A%E4%B8%BA%E8%85%BE%E8%AE%AF%E4%BA%91cos/</guid>
      <description>Gitee 图床挂了，但是各大云服务厂商提供的对象存储服务免费额度，对于个人小博客来说也够用了。下面介绍如何将图床更换为腾讯云 COS。
下载原有图片 从gitee下载整个仓库。保持原有目录结构。
配置腾讯云 COS 注册腾讯云账号，创建 COS 存储桶，选择公有读私有写。创建 COS 存储桶地址：https://console.cloud.tencent.com/cos，创建存储桶后可以在存储桶里打开防盗链设置。
创建桶&amp;ndash;选择地域&amp;ndash;填写名称&amp;ndash;选择公有读私有写&amp;ndash;点击创建。
如果忘了设置读写权限可以按一下方法设置； 选择菜单&amp;ndash;文件列表。上传下载好的文件夹（整个仓库的文件夹）。鼠标放到选择文件出现上传文件夹选项，或者将文件夹拖入浏览器。
配置 Picgo COS 版本：V5 设定 Secreid，设定 Secrekey，设定 APPID： APPID、SecretID 与 SecretKey 点此直达获取。 选择继续使用&amp;ndash;创建秘钥。
设定存储空间名，设定存储区域： 点此获取存储空间名以及存储区域。桶名称即存储空间名，所属区域：ap-shanghai即确认存储区域。
指定存储区域： 指定上传到 COS 的目录，比如我原先从gitee下载来的图床的仓库名是markdown_picbed，图片又保存在markdown_picbed/img目录下，那么就指定markdown_picbed/img目录。
替换旧图床 URL VSCode 全局替换：</description>
    </item>
    <item>
      <title>程序员的自我修养笔记</title>
      <link>http://localhost:8888/posts/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 30 Mar 2022 11:12:31 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <description>静态链接 库是一组目标文件的包，就是一些常用的代码编译成目标文件后打包存放。
第三章 目标文件里有什么 目标文件的格式 目标文件从结构上讲，它是已经编译后的可执行文件格式，只是还没有经过链接的过程，其中可能有些符号或者有些地址还没有被调整。
现在 PC 平台流形的可执行文件格式，主要是 Windows 下的 PE（Portable Executable）和 Linux 下的 ELF（Executable Linkable Format）,它们都是 COFF（Common file format）格式的变种。
指令和数据分开存放的好处：
一方面当程序被装载后，数据和指令分别被映射到两个虚存区域。由于数据区域对于进程来说是可读写的，而指令区域对于进程来说是只读的，所以这两个虚存区域的权限可以被设置成可读写和只读，这样可以防止程序的指令被有意或无意地改写。
另一方面是现代 CPU 有强大的缓存体系，由于缓存很重要，所以程序必须尽量提高缓存命中率。指令区和数据区分离有利于提高程序的局部性。现代 CPU 的缓存一般都被设计成数据缓存和指令缓存，所以程序的指令和数据分开存放对于 CPU 的缓存命中率提高有好处。
第三个原因，也是最重要的原因，就是当系统中运行着多个该进程副本时，他们的指令都是一样的，所以内存中只需要保存一份程序的指令部分。
真正了牛逼的程序员对自己的程序每一个字节都了如指掌。
objdump -h SimpleSsection.o # 打印elf文件各个段的信息size SimpleSsection.o # 查看elf文件各个段的长度objdump -s -d SimpleSsection.o # -s将所有段内容以十六进制打印，-d将所有包含指令的段反汇编 段名称 内容 .data - 初始化的全局变量 - 局部静态变量 .rodata 只读数据段，对这个段的任何修改都是非法的，保证了程序的安全性。 有时候编译器会把字符串放到 data 段 - 只读变量 const 修饰 - 字符串常量 .bss 不占磁盘空间， - 未初始化的全局变量 - 未初始化的局部静态变量 - 初始化为 0 的静态变量 .</description>
    </item>
    <item>
      <title>ZH-什么是 Die-to-Die 接口</title>
      <link>http://localhost:8888/posts/zh-%E4%BB%80%E4%B9%88%E6%98%AFdie-to-die%E6%8E%A5%E5%8F%A3/</link>
      <pubDate>Mon, 28 Mar 2022 19:06:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-%E4%BB%80%E4%B9%88%E6%98%AFdie-to-die%E6%8E%A5%E5%8F%A3/</guid>
      <description>什么是 Die-to-Die 接口 Author：Synopsys 译：What is a Die-to-Die Interface? – How it Works | Synopsys
定义 裸片到裸片（Die2Die）接口是一个功能块，它提供组装在同一封装中的两个硅管芯之间的数据接口。芯片到芯片接口利用非常短的通道连接封装内的两个芯片，以实现功率效率和非常高的带宽效率，这超出了传统芯片到芯片接口所能达到的效果。
Die2Die 接口通常由 PHY 和控制器块组成，控制器块在两个 die 上的内部互连结构之间提供无缝连接。Die2Die 的 PHY 使用高速 SerDes 架构或高密度并行架构实现，经过优化以支持多种先进的 2D、2.5D 和 3D 封装技术。
Die2Die 接口是推动行业趋势从单片 SoC 设计转向同一封装中的多 Die SoC 组件的关键推动力。这种方法减轻了人们对小型工艺节点的高成本/低产量日益增长的担忧，并提供了额外的产品模块化和灵活性。
Die-to-Die 接口如何工作？ Die2Die 的接口，就像任何其他芯片到芯片的接口一样，在两个芯片之间建立了可靠的数据链路。
接口在逻辑上分为物理层、链路层和事务层。它在芯片运行期间建立和维护链路，同时向应用程序提供连接到内部互连结构的标准化并行接口。
通过添加诸如前向纠错 (FEC) 和/或循环冗余码 (CRC) 和重试等错误检测和纠正机制来保证链路可靠性。
物理层架构可以是基于 SerDes 或基于并行的。
基于 SerDes 的架构包括并行到串行（串行到并行）数据转换、阻抗匹配电路和时钟数据恢复或时钟转发功能。它可以支持更高带宽的 NRZ 信令或 PAM-4 信令，最高可达 112 Gbps。SerDes 架构的主要作用是尽量减少简单 2D 类型封装（如有机基板）中的 I/O 互连数量。
基于并行的架构包括许多并行的低速简单收发器，每个收发器都由驱动器和具有转发时钟技术的接收器组成，以进一步简化架构。它支持 DDR 类型的信令。并行架构的主要作用是最大限度地降低密集 2.5D 型封装（如硅中介层）的功耗。</description>
    </item>
    <item>
      <title>Qt 编译后的程序放到指定目录，屏蔽 qDebug 输出</title>
      <link>http://localhost:8888/posts/qt%E7%BC%96%E8%AF%91%E5%90%8E%E7%9A%84%E7%A8%8B%E5%BA%8F%E6%94%BE%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E5%B1%8F%E8%94%BDqdebug%E8%BE%93%E5%87%BA/</link>
      <pubDate>Fri, 18 Mar 2022 13:50:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E7%BC%96%E8%AF%91%E5%90%8E%E7%9A%84%E7%A8%8B%E5%BA%8F%E6%94%BE%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E5%B1%8F%E8%94%BDqdebug%E8%BE%93%E5%87%BA/</guid>
      <description>可执行程序放到指定目录 默认情况下 QtCreator 会将编译链接后的可执行程序与中间生成的文件防盗build-***-文件中，如何能将可执行文件生成在指定目录？
修改.pro:
CONFIG(debug ,debug|release){DESTDIR = ../debug}else{DESTDIR = ../release} debug版本放在../debug目录中，release版本放在../release目录中。
屏蔽 qDebug 输出 CONFIG(debug ,debug|release){DEFINES -= QT_NO_DEBUG_OUTPUT}else{DEFINES += QT_NO_DEBUG_OUTPUT} QT_NO_DEBUG_OUTPUT即为屏蔽 qDebug 输出的宏定义，可以在debug版本中不屏蔽 qDebug 输出，release版本中屏蔽 qDebug 输出。
参考 QT 屏蔽 qDebug()、qWarning() 打印信息_qq_35173114 的博客-CSDN 博客_qwarning QT 的 QDebug 无法输出日志_amwha 的专栏 - 程序员宅基地_qdebug 打印不出来 - 程序员宅基地 Qt Creator 中的.pro 文件的详解_hebbely 的博客-CSDN 博客_qt 的 pro 文件</description>
    </item>
    <item>
      <title>QEMU 源码分析-QOM</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-qom/</link>
      <pubDate>Wed, 09 Mar 2022 16:02:19 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-qom/</guid>
      <description>QOM 简介 QOM(QEMU Object Model) 是 QEMU 的一个模块，用于描述虚拟机的结构，包括虚拟机的 CPU、内存、硬盘、网络、输入输出设备等。QEMU 为了方便整个系统的构建，实现了自己的一套的面向对象机制，也就是 QOM(QEMU Object Model)。它能够方便的表示各个设备（Device）与总线（Bus）之间的关系。
这个模型主要包含四个结构体：
Object: 是所有对象的 基类 Base Object ObjectClass: 是所有类对象的基类 TypeInfo：是用户用来定义一个 Type 的工具型的数据结构 TypeImpl：TypeInfo 抽象数据结构，TypeInfo 的属性与 TypeImpl 的属性对应 在 QEMU 里要初始化一个对象需要完成四步：
将 TypeInfo 注册 TypeImpl 实例化 Class（ObjectClass） 实例化 Object 添加 Property QOM 中的面向对象 继承 在 QEMU 中通过 TypeInfo 来定义一个类。
例如 x86_base_cpu_type_info 就是一个 class，
static const TypeInfo x86_base_cpu_type_info = { .name = X86_CPU_TYPE_NAME(&amp;#34;base&amp;#34;), .parent = TYPE_X86_CPU, .class_init = x86_cpu_base_class_init, }; 利用结构体包含来实现继承。这应该是所有的语言实现继承的方法，在 C++ 中，结构体包含的操作被语言内部实现了，而 C 语言需要自己实现。</description>
    </item>
    <item>
      <title>RGB 与 YUV 颜色空间</title>
      <link>http://localhost:8888/posts/rgb%E4%B8%8Eyuv%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Tue, 01 Mar 2022 16:00:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/rgb%E4%B8%8Eyuv%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/</guid>
      <description>基础概念 RGB 和 YUV 都属于一种颜色编码方式，或者说颜色空间。
RGB 色彩模式是工业界的一种颜色标准，是通过对红、绿、蓝三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，RGB 即是代表红、绿、蓝三个通道的颜色，这个标准几乎包括了人类视力所能感知的所有颜色，是目前运用最广的颜色系统之一。
在 YUV 空间中，Y 代表亮度，其实 Y 就是图像的灰度值；UV 代表色差，U 和 V 是构成彩色的两个分量。在现代彩色电视系统中，通常采用三管彩色摄影机或彩色 CCD 摄影机进行取像，然后把取得的彩色图像信号经分色、分别放大校正后得到 RGB，再经过矩阵变换电路得到亮度信号 Y 和两个色差信号 B&amp;ndash;Y(即 U)、R&amp;ndash;Y(即 V)，最后发送端将亮度和色差三个信号分别进行编码，用同一信道发送出去。这种色彩的表示方法就是所谓的 YUV 色彩空间表示。
解析 RGB 格式 RGB16 RGB16 数据格式主要有二种：RGB565 和 RGB555。
RGB565，每个像素用 16 比特位表示，占 2 个字节，RGB 分量分别使用 5 位、6 位、5 位。
//获取高字节的5个bit R = color &amp;amp; 0xF800; //获取中间6个bit G = color &amp;amp; 0x07E0; //获取低字节5个bit B = color &amp;amp; 0x001F; RGB555，每个像素用 16 比特位表示，占 2 个字节，RGB 分量都使用 5 位 (最高位不用)。</description>
    </item>
    <item>
      <title>计算机组成原理-指令和运算</title>
      <link>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E6%8C%87%E4%BB%A4%E5%92%8C%E8%BF%90%E7%AE%97/</link>
      <pubDate>Mon, 28 Feb 2022 21:28:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E6%8C%87%E4%BB%A4%E5%92%8C%E8%BF%90%E7%AE%97/</guid>
      <description>计算机指令 上世纪 60 年代晚期或 70 年代初期，程序需要先写在纸上，然后转成二进制机器码，再打到打孔卡上（0 表示不打孔，1 表示打孔），送入特殊的计算机中执行。
从硬件的角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑。
从软件的角度来看，CPU 就是一个执行各种计算机指令（Instruction Code）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作机器语言（Machine Language）。
不同的 CPU 能够听懂的语言不太一样。也就是 CPU 支持的语言不一样，这里的语言叫指令集（Instruction Set）。
一个计算机程序由成千上万条指令组成的。但是 CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，我们就叫作存储程序型计算机（Stored-program Computer）。
了解了计算机指令和计算机指令集，接下来我们来看看，平时编写的代码，到底是怎么变成一条条计算机指令，最后被 CPU 执行的呢？我们拿一小段真实的 C 语言程序来看看。
// test.c int main() { int a = 1; int b = 2; a = a + b; } 通过编译器，可以将上述代码编译成汇编代码，再通过汇编器，将汇编代码编译成机器码，最后通过 CPU 执行。
在一个 Linux 操作系统上，我们可以简单地使用 gcc 和 objdump 这样两条命令，把对应的汇编代码和机器码都打印出来。
$ gcc -g -c test.c $ objdump -d -M intel -S test.</description>
    </item>
    <item>
      <title>解决 OpenSSL SSL_read: Connection was reset, errno 10054</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3openssl-ssl-read-connection-was-reset-errno-10054/</link>
      <pubDate>Wed, 16 Feb 2022 11:12:31 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3openssl-ssl-read-connection-was-reset-errno-10054/</guid>
      <description>解决方法 方法一：
git config --global http.sslVerify &amp;#34;false&amp;#34; 方法二：
git config --global https.sslVerify &amp;#34;false&amp;#34; 方法三： 这可能是因为版本库的大小和 git 的默认缓冲区大小，所以通过下述操作（在 git bash 上），git 的缓冲区大小会增加。
//在仓库init后，添加以下配置git config http.postBuffer 524288000//如果仓库不是自己的，可以添加以下配置git config --global http.postBuffer 524288000 方法四： 网速太慢，换个网速快的环境。
Reference windows - git clone error: RPC failed; curl 56 OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054 - Stack Overflow 解决 OpenSSL SSL_read: Connection was reset, errno 10054 問題</description>
    </item>
    <item>
      <title>C 语言中的变长数组与零长数组</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%8F%98%E9%95%BF%E6%95%B0%E7%BB%84%E4%B8%8E%E9%9B%B6%E9%95%BF%E6%95%B0%E7%BB%84/</link>
      <pubDate>Fri, 11 Feb 2022 21:09:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%8F%98%E9%95%BF%E6%95%B0%E7%BB%84%E4%B8%8E%E9%9B%B6%E9%95%BF%E6%95%B0%E7%BB%84/</guid>
      <description>变长数组 想必很多学习 C 语言的人都会在书上看到，数组在初始化时必须要确定长度（维度），也就是说定义数组时，维度一定要用常量。但是在编程中很多人肯定发现了，及时像下面这样写，编译器也不会报错。
int n; int array[n]; 这是怎么回事？难道以前我学的是错的吗？当然不是。最官方的解释应该是 C 语言的规范和编译器的规范说明了。
在 ISO/IEC9899 标准的 6.7.5.2 Array declarators 中明确说明了数组的长度可以为变量的，称为变长数组（VLA，variable length array）。（注：这里的变长指的是数组的长度是在运行时才能决定，但一旦决定在数组的生命周期内就不会再变。） 在 GCC 标准规范的 6.19 Arrays of Variable Length 中指出，作为编译器扩展，GCC 在 C90 模式和 C++ 编译器下遵守 ISO C99 关于变长数组的规范。 原来这种语法确实是 C 语言规范，GCC 非常完美的支持了 ISO C99。但是在 C99 之前的 C 语言中，变长数组的语法是不存在的。
这种变长数组有什么好处呢？它可以实现与alloca函数一样的效果，在栈上进行动态的空间分配，并且在函数返回时自动释放内存，无需手动释放。
alloca 函数用来在栈上分配空间，当函数返回时自动释放，无需手动再去释放；
可变数组示例： 所有可变修改 (VM) 类型的声明必须在块范围或函数原型范围内。使用 static 或 extern 存储类说明符声明的数组对象不能具有可变长度数组 (VLA) 类型。但是，使用静态存储类说明符声明的对象可以具有 VM 类型（即，指向 VLA 类型的指针）。最后，使用 VM 类型声明的所有标识符都必须是普通标识符，因此不能是结构或联合的成员。
extern int n; int A[n]; // Error - file scope VLA.</description>
    </item>
    <item>
      <title>SSH 原理</title>
      <link>http://localhost:8888/posts/ssh%E5%8E%9F%E7%90%86/</link>
      <pubDate>Thu, 27 Jan 2022 21:30:29 +0000</pubDate>
      <guid>http://localhost:8888/posts/ssh%E5%8E%9F%E7%90%86/</guid>
      <description></description>
    </item>
    <item>
      <title>QEMU 源码分析-内存虚拟化</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</link>
      <pubDate>Tue, 25 Jan 2022 13:42:11 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</guid>
      <description>1.大部分转载自QEMU 内存虚拟化源码分析 | Keep Coding | 苏易北 2.原文源码为 QEMU1.2.0，版本较旧，部分源码内容根据 QEMU6.2 版本修改 3.部分内容根据自己理解补充添加
概述 我们知道操作系统给每个进程分配虚拟内存，通过页表映射，变成物理内存进行访问。当有了虚拟机之后，情况会变得更加复杂。因为虚拟机对于物理机来讲是一个进程，但是虚拟机里面也有内核，也有虚拟机里面跑的进程。所以有了虚拟机，内存就变成了四类：
虚拟机里面的虚拟内存（Guest OS Virtual Memory，GVA），这是虚拟机里面的进程看到的内存空间； 虚拟机里面的物理内存（Guest OS Physical Memory，GPA），这是虚拟机里面的操作系统看到的内存，它认为这是物理内存； 物理机的虚拟内存（Host Virtual Memory，HVA），这是物理机上的 qemu 进程看到的内存空间； 物理机的物理内存（Host Physical Memory，HPA），这是物理机上的操作系统看到的内存。 内存虚拟化的关键在于维护 GPA 到 HVA 的映射关系。
页面分配和映射的两种方式 要搞清楚 QEMU system emulation 的仿真架构，首先对于 Host OS，将 QEMU 作为进程启动，然后对于 QEMU 进程，会仿真各种硬件和运行 Guest OS，在这层 OS 上运行要全系统模拟的应用程序，因此对于 Guest OS 管理的内存要实现到 QEMU 进程的虚拟空间的转换需要 softMMU（即需要对 GPA 到 HVA 进行转换）。从 GVA 到 GPA 到 HVA 到 HPA，性能很差，为了解决这个问题，有两种主要的思路。
影子页表 Shadow Page Table，SPT 第一种方式就是软件的方式，影子页表（Shadow Page Table）。</description>
    </item>
    <item>
      <title>解决 VSCode 配置远程连接，过程试图写入的管道不存在</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vscode%E9%85%8D%E7%BD%AE%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E8%AF%95%E5%9B%BE%E5%86%99%E5%85%A5%E7%9A%84%E7%AE%A1%E9%81%93%E4%B8%8D%E5%AD%98%E5%9C%A8/</link>
      <pubDate>Wed, 19 Jan 2022 23:07:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3vscode%E9%85%8D%E7%BD%AE%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E8%AF%95%E5%9B%BE%E5%86%99%E5%85%A5%E7%9A%84%E7%AE%A1%E9%81%93%E4%B8%8D%E5%AD%98%E5%9C%A8/</guid>
      <description>保留现场 探究原因 本地记录的服务器信息和现有的产生了冲突
解决方法 方法一 将known_hosts文件的内容全部删除。
C:\Users\user name\.ssh\known_hosts
方法二 搜遍全网几乎都是上述方法，应该绝大部分人通过上述方法都能解决。如果你也跟我一样不走运，不管是重新生成公私钥，还是删除hnow_hosts都不行，那么可以尝试修改 VSCode 使用的ssh.exe。Windows 下默认使用的是环境变量里配置的OpenSSH提供的ssh.exe。你可以将环境变量里的OpenSSH删除。然后在VSCode设置里搜索remote，也就是设置插件remote ssh。
将 Path 强制设置成Git安装包内的ssh.exe
或者mobaxterm安装包内的ssh.exe
参考 Debug | VSCode | 过程试图写入的管道不存在 - CodeAntenna
VScode 通过 remote ssh 连接虚拟机 &amp;amp; 报错 过程试图写入的管道不存在（已解决）_Tasdily 的博客-CSDN 博客_vscode 过程试图写入的管道不存在</description>
    </item>
    <item>
      <title>Linux 帧缓冲</title>
      <link>http://localhost:8888/posts/linux%E5%B8%A7%E7%BC%93%E5%86%B2/</link>
      <pubDate>Mon, 17 Jan 2022 17:38:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%B8%A7%E7%BC%93%E5%86%B2/</guid>
      <description>简介 FrameBuffer 是内核当中的一种驱动程序接口。Linux 是工作在保护模式下，所以用户态进程是无法象 DOS 那样使用显卡 BIOS 里提供的中断调用来实现直接写屏，Linux 抽象出 FrameBuffer 这个设备来供用户态进程实现直接写屏。
帧缓冲主要结构 fb_info 该结构体记录当前帧缓冲设备的状态信息，如果系统中有多个帧缓冲设备，就需要两个fb_info结构，这个结构只在内核中可以看到，对用户空间不可见。
fb_var_screeninfo 该结构体记录指定的帧缓冲设备和显示模式中可以被修改的信息，其中包括显示器分辨率等信息。
fb_fix_screeninfo 该结构体表示帧缓冲设备中一些不能修改的参数，包括特定的显示模式，屏幕缓冲区的物理地址，显示缓冲区的长度信息。
fb_ops LCD底层硬件操作接口集。比如fb_open、fb_release、fb_read、fb_write、fb_ioctl、fb_mmap等：
fb_cmap fb_cmap指定颜色映射，用于以内核可以理解的方式存储用户的颜色定义。
帧缓冲显示原理 帧缓冲设备是一种显示抽象的设备，也可以被理解为它是一个内存区域，上面的应用程序可以直接对显示缓冲区进行读和写操作，就像访问文件的通用接口一样，用户可以认为帧缓冲是一块内存，能读取数据的内存块也可以向这个内存写入数据，因此显示器显示图形界面实际上根据根据的是指定的内存数据块内的数据。
帧缓冲的显示缓冲区位于 Linux 内核地址空间，应用程序不能直接访问内核地址空间，在 Linux 中，只有一个内存的内核地址空间映射到用户地址空间才可以由用户访问，内存的映射是通过MMAP函数实现的在 Linux 中。对于帧缓冲，虚拟地址是通过内存映射的方法将显示缓冲区内核地址映射到用户空间的，然后用户可以通过读和写这部分的虚拟地址来访问显示缓冲区，在屏幕上绘图。
使用流程 使用帧缓冲之前应该首先确定 Linux 系统上已安装了帧缓冲驱动，可以在目录/dev/下查找fb*如，/dev/fb0, /dev/fb1等设备来确定是否安装。如果没有需要安装一个帧缓冲驱动的模块到内核，或者重新编译内核生成一个带帧缓冲模块的镜像。
使用帧缓冲需要进入控制台模式，即纯命令行的模式进行编程。一般可以通过快捷键CTRL+ALT+F1进入控制台模式，CTRL+ALT+F7切回图形窗口。如果控制台模式没有登录，可以CTRL+ALT+F6尝试登录。
因硬件显示设备的物理显示区是通过帧缓存区操作，而帧缓存区是处于内核空间，应用程序不能随意操作，此时可以通过系统调用mmap把帧缓存映射到用户空间，在用户空间中创建出帧缓存映射区（用户图像数据缓存区），以后只需把用户图像数据写入到帧缓存映射区就可在硬件设备上显示图像。
具体实现流程如下：
打开帧缓冲设备/dev/f0 在Linux的/dev目录的寻找b*设备文件然后使用读写模式打开它，Linux 系统将使用通用的open系统调用来完成功能， open的功能原型如下：
int open(const char *path, int oflags); Path是准备打开的文件或设备的路径参数； oflags指定打开文件时使用的参数； flags参数的指定，是通过组合文件访问模式和其他的可选模式一起的，可以支持多个模式或，参数必须是指定下列文件的访问模式。 只读：O_RDONLLY 只写：O_WRONLY 读写：O_RDWR 简而言之， open函数建立设备文件的访问路径。如果操作成功，它返回一个文件描述符，只是一个文件描述符，它将不使用其他任何正在运行的进程共享。如果两个程序同时打开相同的文件，将得到两个不同的文件描述符。如果他们执行文件写入操作，他们将操作每个文件描述符，不会发生冲突，写完之后退出。他们的数据不会互相交织在一起的，但会互相的彼此覆盖 (后写完的内容覆盖前面写的内容)，两个程序来读取和写入的文件位置看似一样但是有各自不同拷贝所以不会发生交织。如果open调用未能返回1，则将全局变量errno设置为指示失败的原因。
通过系统调用ioctl函数获得帧设备相关信息 通过顿缓冲文件描述符，屏幕的分辨率、颜色深度等信息可以被获得，帧缓冲驱动中存放了这些对应的信息，必须使用 Linux 系统调用ioctl首先将帧缓冲的文件描述符和fb_var_screeninfo 结构体对应起来。
结构体fb_var_screeninfo包含以下三个重要数据结构：
屏幕的 x 方向分辨率，像素作为单位。 屏幕的 Y 方向分辨率，像素作为单位。 屏幕的像素颜色深度，每个像素用多少比特数表示。 ioctl函数原型如下：</description>
    </item>
    <item>
      <title>解决 ssh permission denied(publickey)</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3git-ssh-permission-deniedpublickey/</link>
      <pubDate>Thu, 13 Jan 2022 22:43:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3git-ssh-permission-deniedpublickey/</guid>
      <description>保留现场 linux&amp;gt; ssh -p 2221 xxx@gerrit.com xxx@gerrit.com: Permission denied(publickey) 探究原因 本次出错是在测试是否能连接 gerrit 时。连接 GitHub 也可能会出现。只要用到 ssh 功能的都有可能。
出错的原因：
网页（如 gerrit,github）没有设置公钥，一般为id_rsa.pub内容； 本地生成了多个公私钥，配对配错了； 本地没有配置好git，比如git config时用户名或者邮箱填错； 需要开启 ssh 代理； 解决方法 生成密钥cd ~/.ssh &amp;amp;&amp;amp; ssh-keygen 复制公钥内容，添加到网页中github或者gerrit的设置里。cat id_rsa.pub | xclip 配置git账户 git config --global user.name &amp;quot;bob&amp;quot; git config --global user.email bob@... 以上检查无误，仍然报错
开启ssh代理 eval $(ssh-agent -s) 将私钥加入代理 ssh-add ~/.ssh/id_rsa 登陆用户时启动 ssh-agent 如果不幸你的问题就是需要开启ssh-agent，那么每次重启电脑都需要开启一次。这也是相当麻烦的，可以通过将以下配置添加到~/.bashrc中，让 Linux 启动时自动开启ssh-agent。
# Add following code at the end of ~/.bashrc # Check if ~/.</description>
    </item>
    <item>
      <title>Linux 安装 Node.js 以及 hexo</title>
      <link>http://localhost:8888/posts/linux%E5%AE%89%E8%A3%85nodejs/</link>
      <pubDate>Mon, 10 Jan 2022 11:51:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%AE%89%E8%A3%85nodejs/</guid>
      <description>安装 Node.js 过程 进入该网站下载 | Node.js 也可以进入该网站下载历史版本，Previous Releases | Node.js
进入 download 目录，
cd downloadwget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz -O nodejs.tar.xz 解压
tar -xvf node-v10.16.3-linux-x64.tar.xz 改名 Node.js
mv node-v10.16.3-linux-x64 nodejs 将 npm，node 两个程序建立软连接，能够全局可用
ln -s /download/nodejs/bin/npm /usr/local/bin/ ln -s /download/nodejs/bin/node /usr/local/bin/ 检查是否安装
node -vnpm -v 安装 hexo 过程 npm i hexo-cli -ghexo -v 如果出现命令未找到到错误，说明 hexo 还未加入全局变量。 将下面命令加入
vim ~/.bashrcexport PATH=/usr/local/nodejs/lib/node_modules/hexo-cli/bin/:$PATH Reference Previous Releases | Node.js Linux 安装 Node.js | F2E 前端技术论坛 Linux 下安装 node 及 npm - SegmentFault 思否 超详细 Hexo+Github 博客搭建小白教程 - 知乎</description>
    </item>
    <item>
      <title>C 语言__attribute__使用</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80-attribute-%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 08 Jan 2022 15:40:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80-attribute-%E4%BD%BF%E7%94%A8/</guid>
      <description>简介 __attribute__ 其实是个编译器指令，告诉编译器声明的特性，或者让编译器进行更多的错误检查和高级优化。
__attribute__ 可以设置函数属性（Function Attribute）、变量属性（Variable Attribute）和类型属性（Type Attribute）。每一类都包含数十种属性，本文不会逐一解释，只抛砖引玉，完整属性可以查看链接中的官方文档。
一个属性说明符的形式是__attribute__ ((attribute-list))。一个属性列表是一个可能为空的逗号分隔的属性序列，其中每个属性都是以下的一个。
属性为空。空属性会被忽略。 一个单词（可能是未使用的标识符，也可能是 const 等保留字）。 一个单词，后面跟着括号中的属性参数。这些参数采用以下形式之一： 一个标识符。例如，mode属性使用这种形式。 一个标识符，后跟一个逗号和一个以逗号分隔的非空表达式列表。例如，format属性使用这种形式。 一个可能是空的逗号分隔的表达式列表。例如，format_arg属性使用这种形式，该列表是一个单一的整数常量表达式，而alias属性也使用这种形式，该列表是一个单一的字符串常量。 使用方法 函数属性 alias 该属性可以设置函数的别名。
void __f() { printf(&amp;#34;__attribute__ test\n&amp;#34;); }; void f() __attribute__((weak, alias(&amp;#34;__f&amp;#34;))); int main() { f(); return 0; } /*--- 输出 ---*/ //__attribute__ test 函数f()的别名为__f()，调用f()即调用__f()。
alloc_size alloc_size属性用来告诉编译器，函数的返回值指向内存，其中的大小由一个或两个函数参数给出。GCC 使用这些信息来提高__builtin_object_size的正确性。
alloc_size后面可以跟一到二个参数，alloc_size 后面跟的参数是指定使用函数的第几个参数。
函数的参数的个数只有一个，那么 alloc_size 的参数只能是 1。通过__builtin_object_size 获取的值 就是传入的参数值。如图，我们给函数my_malloc 传入的值是100 ，那么我们通过__builtin_object_size 获取的值就是100。
函数的参数的个数多余两个，那么alloc_size 的最多可以指定两个参数。传入两个参数，__builtin_object_size的值是这两个参数的乘积。传入一个参数，__builtin_object_size的值就是这个参数的值。如图，my_callocd函数指定的参数是alloc_size(2,3)，通过__builtin_object_size获取的值就是my_callocd传入的第二和三个参数的乘积（2*3=6）。
void *my_calloc(int a) __attribute__((alloc_size(1))); void *my_realloc(int a, int b, int c) __attribute__((alloc_size(2, 3))); void *my_calloc(int a) { return NULL; } void *my_realloc(int a, int b, int c) { return NULL; } int main() { void *const p = my_calloc(100); printf(&amp;#34;size : %ld\n&amp;#34;, __builtin_object_size(p, 0)); void *const a = my_realloc(1, 2, 3); printf(&amp;#34;size : %ld\n&amp;#34;, __builtin_object_size(a, 1)); return 0; } /*--- 输出 ---*/ //100 //6 constructor (priority) / destructor (priority) constructor属性使该函数在执行进入main()之前被自动调用。同样地，destructor属性使函数在main()完成后或exit()被调用后被自动调用。具有这些属性的函数对于初始化将在程序执行过程中隐含使用的数据非常有用。</description>
    </item>
    <item>
      <title>C 语言 typedef 用法</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80typedef%E7%94%A8%E6%B3%95/</link>
      <pubDate>Fri, 07 Jan 2022 11:51:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80typedef%E7%94%A8%E6%B3%95/</guid>
      <description>简介 typedef为 C 语言的关键字，作用是为一种数据类型定义一个新名字。这里的数据类型包括内部数据类型（int,char 等）和自定义的数据类型（struct 等）。在使用语法上类似与static，extern等。 typedef 行为有点像 #define 宏，用其实际类型替代同义字。不同点是 typedef在编译时被解释，因此让编译器来应付超越预处理器能力的文本替换。
基本使用方法 示例 1：
int a; ———— 传统变量声明表达式int myint_t; ———— 使用新的类型名myint_t替换变量名atypedef int myint_t; ———— 在语句开头加上typedef关键字，myint_t就是我们定义的新类型 示例 2：
void (*pfunA)(int a); ———— 传统变量（函数）声明表达式void (*PFUNA)(int a); ———— 使用新的类型名PFUNA替换变量名pfunAtypedef void (*PFUNA)(int a); ———— 在语句开头加上typedef关键字，PFUNA就是我们定义的新类型 促使我写这篇文章的原因不是如何去用typedef，而是在代码中看不懂如何简化了一个复杂声明。比如上文的
typedef void (*PFUNA)(int a); 本以为是将void类型替换成了(*PFUNA)(int a)，但是语法上这明显讲不通啊。现在明白了，这就是将void (*pfunA)(int a);类型名换成了PFUNA。以后就可以用PFUNA来声明变量。比如
PFUNA arr[10] 表示声明了一个大小为10的数组，数组的元素是PFUNA类型。将PFUNA类型展开就是，这是一个函数指针，函数参数为int类型，返回值为void类型。完整的含义就是，声明了一个大小为10的数组，数组元素是函数指针，函数参数为int类型，返回值为void类型。
代码简化 typedef可以为复杂的声明定义一个新的简单的别名。关于复杂声明，可以阅读这篇C 语言复杂声明。 方法是：在原来的声明里逐步用别名替换一部分复杂声明，递归操作，把带变量名的部分留到最后替换，得到的就是原声明的最简化版。举例：
//复杂声明void (*b[10]) (void (*)()); 变量名为b，先替换右边部分括号里的，pFunParam为别名
typedef void (*pFunParam)(); 再替换左边的变量b，pFunx为别名二：</description>
    </item>
    <item>
      <title>Windows 批处理定时任务</title>
      <link>http://localhost:8888/posts/windows%E6%89%B9%E5%A4%84%E7%90%86%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</link>
      <pubDate>Wed, 05 Jan 2022 22:39:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/windows%E6%89%B9%E5%A4%84%E7%90%86%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</guid>
      <description>折腾背景 一些常用的离线软件在重新安装，重装电脑或者更好环境时，调教好的配置总需要重新设置一遍，甚是麻烦。但是这些设置通常都保存在配置文件里，只要能备份好这些配置文件，下次重装后覆盖就可以恢复所需设置。
现在的问题就是如何备份这些配置文件，可以选择各类网盘，硬盘等等。但是这些多少都有点炮打蚊子，小题大做。而且定时备份也不是很方便。既然配置文件都很小，其实就是个文本文件，那有个万能免费存储地 GitHub 就派上用场了。我们只要把配置文件定时 push 到 GitHub 即可，以后随时可以 clone 下来。
首先建立一个私密仓库，用来专门存放配置文件。其次通过批处理命令，将配置文件复制到本地仓库的文件夹下。最后设置定时任务。
折腾过程 新建仓库 这一步不用赘述了，主要就是要勾选私密仓库，保护隐私，一些配置文件可能会包含个人信息。
批处理 将仓库克隆到本地后就是个文件夹，这一步主要就是如何能把安装在不同位置的软件的配置文件，都汇集到这个仓库下。通过批处理命令可以快速，方便的完成。
echo Start backup config files! # 打印这句话 copy D:\Tools\MouseInc\MouseInc.json D:\Develop\fxxk-config\mouseinc # 将前者复制到后者 copy D:\Tools\JD\Config.ini D:\Develop\fxxk-config\jd cd /d D:\Develop\fxxk-config # 切换目录 # git推送的一些命令 git add . git commit -m &amp;#34;update&amp;#34; git push # 防止窗口闪退 pause 一些常用命令参考WindowDos 批处理指导。
定时任务 控制面板-管理工具 - 任务计划程序 </description>
    </item>
    <item>
      <title>解决 unable to install libpng12.so.0</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-install-libpng12-so-0/</link>
      <pubDate>Wed, 05 Jan 2022 13:01:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-install-libpng12-so-0/</guid>
      <description>保留现场 apt工具损坏了，在修复时使用了sudo apt-get install -f命令，中途会提示需要安装libpng12-0，但是始终无法安装，会提示如下错误。
Unpacking libpng12-0:amd64 (1.2.50-2+deb8u3) ... dpkg: error processing archive libpng12-0_1.2.50-2+deb8u3_amd64.deb (--install): unable to install new version of &amp;#39;/usr/lib/ x86_64-linux-gnu/libpng12.so.0&amp;#39;: No such file or directory Errors were encountered while processing: libpng12-0_1.2.50-2 +deb8u3_amd64.deb 探究原因 具体原因未知，网上答案众说纷纭。
解决方法 这个问题遇到的人还挺多的，解决方法也各不相同，我先说我自己最终解决的方法。
方法一 将软件源更换成中科院的源，使用 Linux 自带的软件和更新工具，具体方法参考这篇文章。更换完之后可以重新尝试安装，有人换源后即可成功安装。
如果未能安装成功，可能曾经手动添加过软件源，将其删除。
# 将所有内容注释vim /etc/apt/sources.list 方法二 下载已安装的库文件libpng12.so.0，可以从该链接下载。
将该文件复制到它本该安装的位置。
sudo cp libpng12.so.0 /usr/lib/x86_64-linux-gnu/ 方法三 sudo add-apt-repository ppa:linuxuprising/libpng12sudo apt updatesudo apt install libpng12-0 </description>
    </item>
    <item>
      <title>RISC-V 入门-Trap</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-trap%E5%92%8Cexception/</link>
      <pubDate>Thu, 30 Dec 2021 13:42:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-trap%E5%92%8Cexception/</guid>
      <description>Trap 简介 控制流（Control Flow）和 Trap 控制流（Control Flow） 从给处理器加电开始，直到你断电为止，程序计数器假设一个值的序列 $$a_0,a_1,\dotsb,a_{n-1}$$ 每个$a_k$都是指令的地址，每次从$a_{k}$到$a_{k+1}$的过渡称为控制转移，而这样的控制转移序列叫做处理器的控制流。 异常控制流（Exceptional Control Flow, ECF） 系统也必须能够对系统状态的变化做出反应，这些系统状态不是被内部程序变量捕获的，而且也不一定要和程序的执行相关。比如，一个硬件定时器定期产生信号，这个事件必须得到处理。包到达网络适配器后，必须存放在内存中。程序向磁盘请求数据，然后休眠，直到被通知说数据已就绪。现代系统通过使控制流发生突变来对这些情况做出反应。我们把这些突变称为异常控制流。 exception interrupt RISC-V 把 ECF 统称为 Trap。
RISC-V Trap 处理中涉及的寄存器 寄存器 全称 用途说明 mtvec Machine Trap-Vector Base-Address 它保存发生异常时处理器需要跳转到的地址。 mepc Machine Exception Program Counter 当 trap 发生时，hart 会将发生 trap 所对应的指令的地址值（pc）保存在 mepc 中。 mcause Machine Cause 当 trap 发生时，hart 会设置该寄存器通知我们 trap 发生的原因。 mtval Machine Trap Value 它保存了 exception 发生时的附加信息：譬如访问地址出错时的地址信息、或者执行非法指令时的指令本身，对于其他异常，它的值为 0。 mstatus Machine Status 用于跟踪和控制 hart 的当前操作状态（特别地，包括关闭和打开全局中断）。 mscratch Machine Scratch Machine 模式下专用寄存器，我们可以自己定义其用法，譬如用该寄存器保存当前在 hart 上运行的 task 的上下文（context）的地址。 mtvec（Machine Trap-Vector Base-Address） WARL: Write Any Values, Read Legal Values</description>
    </item>
    <item>
      <title>VSCode 使用 sftp 插件上传本地文件至局域网服务器</title>
      <link>http://localhost:8888/posts/vscode%E4%BD%BF%E7%94%A8sftp%E6%8F%92%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%87%B3%E5%B1%80%E5%9F%9F%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Fri, 24 Dec 2021 11:39:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E4%BD%BF%E7%94%A8sftp%E6%8F%92%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%87%B3%E5%B1%80%E5%9F%9F%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>测试代码时经常需要上传文件至服务器端运行，每次上传都需要通过第三方传输工具如 FileZilla，有了SFTP插件，可以直接在 VSCode 上编译成功后，一键上传本地文件。
安装插件 打开插件中心，搜索sftp，安装量最高的就是我们需要的插件，点击安装。
配置插件 插件安装完成后，输入快捷键Control + Shift + P 弹出命令面板，然后输入sftp:config，回车，当前工程的.vscode文件夹下就会自动生成一个sftp.json文件，我们需要在这个文件里配置的内容可以是：
{ &amp;#34;host&amp;#34;: &amp;#34;192.168.xxx.xxx&amp;#34;, //服务器 ip &amp;#34;port&amp;#34;: 22, //端口，sftp 模式是 22 &amp;#34;username&amp;#34;: &amp;#34;&amp;#34;, //用户名 &amp;#34;password&amp;#34;: &amp;#34;&amp;#34;, //密码 &amp;#34;protocol&amp;#34;: &amp;#34;ftp&amp;#34;, //模式，sfpt 或者 ftp &amp;#34;agent&amp;#34;: null, &amp;#34;privateKeyPath&amp;#34;: null, //存放在本地的已配置好的用于登录工作站的密钥文件（也可以是 ppk 文件） &amp;#34;passphrase&amp;#34;: null, &amp;#34;passive&amp;#34;: false, &amp;#34;interactiveAuth&amp;#34;: false, &amp;#34;remotePath&amp;#34;: &amp;#34;/root/node/build/&amp;#34;, //服务器上的文件地址 &amp;#34;context&amp;#34;: &amp;#34;./server/build&amp;#34;, //本地的文件地址 &amp;#34;uploadOnSave&amp;#34;: true, //监听保存并上传 &amp;#34;syncMode&amp;#34;: &amp;#34;update&amp;#34;, &amp;#34;watcher&amp;#34;: { //监听外部文件 &amp;#34;files&amp;#34;: false, //外部文件的绝对路径 &amp;#34;autoUpload&amp;#34;: false, &amp;#34;autoDelete&amp;#34;: false }, &amp;#34;ignore&amp;#34;: [ //指定在使用 sftp: sync to remote 的时候忽略的文件及文件夹 //注意每一行后面有逗号，最后一行没有逗号 //忽略项 &amp;#34;**/.</description>
    </item>
    <item>
      <title>C 程序内存区域分配</title>
      <link>http://localhost:8888/posts/c%E7%A8%8B%E5%BA%8F%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%86%E9%85%8D/</link>
      <pubDate>Wed, 22 Dec 2021 09:16:25 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E7%A8%8B%E5%BA%8F%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%86%E9%85%8D/</guid>
      <description></description>
    </item>
    <item>
      <title>芯片启动过程全解析</title>
      <link>http://localhost:8888/posts/%E8%8A%AF%E7%89%87%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E5%85%A8%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sat, 18 Dec 2021 22:32:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%8A%AF%E7%89%87%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E5%85%A8%E8%A7%A3%E6%9E%90/</guid>
      <description>内容总结自 B 站 Up【蛋饼嵌入式】我提着鞋带拎自己？嵌入式芯片启动过程全解析，彻底理解 bootloader
当你按下电源开关的那一瞬间，第一行代码如何在芯片上运行起来的呢？嵌入式软件代码需要一定的方式烧录到芯片中才能运行，除了物理刻蚀，无论是通讯端口的传输或者调试端口的烧录，都需要驱动程序的支持。所以说是程序烧录了程序，软件启动了软件。
这就像自己提着自己的鞋带，把自己拎起来。靴子（Boot）,鞋带（Strap），提鞋带（Loader）。这就是Boot Strap Loader的命名来源。通常称BootLoader，中文翻译为自举。
BootLoader是芯片最初运行的代码吗？当然不是，其实每一块芯片在出厂时都在其内部的ROM中，烧录了它最基础的软件。CPU 搬运并运行的第一条代码的默认位置，就在ROM的地址空间。所以一切的起始都在硬件上。
以 X86 架构的鼻祖 8086 芯片为例，按下开关的一瞬间，芯片 Reset 引脚接收到了电平跳变，在一连串电路的作用下，代码段寄存器CS恢复成0XFFFF，指令指针寄存器IP恢复成0X0000，他们组合成 20 位的地址正好等于 ROM 中存放第一条代码的位置。之后取出这里的指令在跳转到别处。
ARM 架构的芯片也是类似的过程，对于 32 位的芯片，通电后，PC指针寄存器复位至零地址，随后从中断向量表表头的 reset 向量处获取下一个跳转的地址。这时候的代码已经以二进制形式存储，处理器可以直接搬到自身缓存中运行。有了这部分代码，就能跳转到存放有更多更复杂的代码的地址。执行硬件自检，基本的初始化操作，提供基础的输入输出支持。之后可以将操作系统从外部的存储空间加载到内部。代码就这样接力式的流转起来。
所以我们把出厂就写在ROM里，负责启动后续用户软件的软件，称为Boot ROM或者ROM Code。现在不一定是用只读存储器（Read Only Memory），但是至少是一块掉电不易失的存储器，现在主要用EEPROM，NOR Flash。我们一般没有权限修改它，但是它也不完全是黑盒，大部分芯片都会有外部启动配置引脚，通常是以拨码快关的形式。对于 PC 机来说，Boot ROM就是我们常说的BIOS，它也有启动配置途径。而且提供了交互界面，用于配置部分功能和选择后续的引导设备。
除了芯片自带的Boot ROM，还需要再给自己实际的应用程序，写一个二次引导代码或者 N 次引导代码，用作操作系统，文件系统加载等等。我们所说的Bootloader时，其实大多数就是这样的二次引导代码。
这些事其实Boot ROM它也能做，但是Boot ROM实现的功能和配置方法不灵活，但是Bootloader是开发人员可以而完全控制的引导代码。
在设计Bootloader时，MCU的引导步骤就开始和嵌入式 Linux 或者 PC 有所不同。这一定程度与芯片架构所采用的的存储方案有关。
先来说MCU，与SOC相比MCU的主要特征是单核和或多核同构的微处理器，单核或多核同构，主频 &amp;lt; 1GHz，没有MMU内存管理单元，只能运行实时操作系统。常见MCU内核：
程序的主要运行介质为NOR Flash，因为和RAM一样有分离的地址线和数据线。并且可以以字节长度精确寻址，所以程序不需要拷贝到RAM中运行的。
以英飞凌家的 TC27x 系列 MCU 为例，上电后的默认取址位置是0x8FFF 8000，这就是他的Boot ROM在NorFlash中的地址。并且这块Boot Rom分为SSW，BSL，TF。
SSW 每次上电必须运行，他会根据写在program flash，PFO地址的前 32byte 中的配置字，来决定SSW执行完的跳转地址。我们可以选择一个合适的跳转地址，比如0x80000020，放上自己写的Bootloader。也可以选择不跳转，运行厂家提供的Bootloader（BSL）。
MCU下的Bootloader主要完成的事情有以下：
关闭看门狗，初始化中断和 trap 向量表，进行时钟和外设初始化，让芯片正常运行起来。 提供CAN,UART, ETH等用于通讯功能的驱动，能够接收外部数据传输请求。 提供FLASH的读写与擦除驱动，设计服务来对通讯端口接收到的更新代码进行校验、存储，以及跳转操作系统或后续应用程序代码。 如有必要，还会开发一些基础诊断服务，串口交互程序等等。 那么运行 Linux 的SOC和 PC 的这一过程有何不同呢。还是先看存储方案，运行嵌入式 Linux 的 SoC。一般将它的操作系统，文件系统和他的应用程序放在nand flash中。运行代码前，现将代码搬运到SRAM中，相比MCU多了一道步骤。</description>
    </item>
    <item>
      <title>定时器 Timer 基础</title>
      <link>http://localhost:8888/posts/%E5%AE%9A%E6%97%B6%E5%99%A8timer%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Wed, 15 Dec 2021 12:22:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%AE%9A%E6%97%B6%E5%99%A8timer%E5%9F%BA%E7%A1%80/</guid>
      <description>概念 定时器（Timer），又叫计时器，顾名思义，它的主要功能就是计时。因为 CPU 计时会占用大量资源，而定时器独立于 CPU，专门用来计时。单核 CPU 好比人的大脑，一心不可二用，它只能知道自己当前要干什么。人可以用闹钟来提醒自己某个时间需要做某件事，而 CPU 就需要定时器来完成这样的工作。
当定时器被开启后，里面的计数器就以计数器时钟的频率开始运行，内部的计数值不断增加。例如一个时钟为1MHz的定时器，被开启后每隔1us计数值就会加 1。但计数值不可能无限增加，最大值比如65535。将这个十进制数转为二进制数后应该是一个 16 位的二进制数1111 1111 1111 1111。所以我们需要有一个 16 位大小的存储空间来存储它。那这就是一个 16 位定时器。
功能 定时器可以让 SoC 在执行主程序的同时，可以 (通过定时器) 具有计时功能，到了一定时间 (计时结束) 后，定时器会产生中断提醒 CPU，CPU 会去处理中断并执行定时器中断的 ISR，从而去执行预先设定好的事件。打个比方，定时器就像一个秘书，CPU 就是老板。老板每天都有很多事要做，具体时间安排不想操心，就安排给秘书。秘书每天就是盯着表，到点就提醒老板要做某事。
原理 外设的工作频率是与它所挂载在的外设总线的时钟频率相同的。但工作频率不是时钟频率，工作频率到时钟频率需要进行一次分频。这个可调节的分频值使得定时器的计时更加灵活。这个分频值就是需要设置的第一个参数预分频系数。
$$ 计数器时钟频率 = 工作频率/(预分频系数+1) $$
$$ 定时频率 = 计时器时钟频率/(自动重载值+1) $$
假设定时器时钟频率为1MHz，那定时1ms该如何做？计数 1000 次即可。最大的计数值就是自动重载值，是我们需要设置的第二个参数。定时器被打开后，计数值就增加，一旦达到自动重载值就会出发定时器溢出中断，就实现了定时1ms。
计数模式 中心计数：计数器从 0 开始计数到自动装入的值 -1，产生一个计数器溢出事件，0 然后向下计数到 1 并且产生一个计数器溢出事件，然后再从 0 开始重新计数。
向上计数：计数器从 0 计数到自动加载值 (TIMx_ARR) ，然后重新从 0 开始计数并且产生一个计数器溢出事件。
向下计数：计数器从自动装入的值 (TIMx_ARR) 开始向下计数到 0，然后从自动装入的值重新开始，并产生一个计数器向下溢出事件。</description>
    </item>
    <item>
      <title>解决 Qt-QObject::connect: Cannot queue arguments of type‘QTextCursor’错误</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt-qobject-connect-cannot-queue-arguments-of-type-qtextcursor%E9%94%99%E8%AF%AF/</link>
      <pubDate>Sat, 04 Dec 2021 11:41:46 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt-qobject-connect-cannot-queue-arguments-of-type-qtextcursor%E9%94%99%E8%AF%AF/</guid>
      <description>保留现场 我在线程中直接调用了 QTextEdit 的 append 函数时，候就会出现下面的错误：
QObject::connect: Cannot queue arguments of type &amp;#39;QTextCursor&amp;#39; (Make sure &amp;#39;QTextCursor&amp;#39; is registered using qRegisterMetaType().) 探究原因 原因是我们不能通过线程来修改 UI，较为安全的修改用户界面的方式是向 UI 窗口发送信号 (signal)，较为简单的方式是使用 Qt threading 类。
解决方法 在窗口类中定义信号和槽，并声明和实现一个接口函数，这个接口函数由线程调用，在接口函数中 emit 一个信号，示例代码如下：
//mainwindow.h signals: void AppendText(const QString &amp;amp;text); private slots: void SlotAppendText(const QString &amp;amp;text); public: void Append(const QString &amp;amp;text); //mainwindow.cpp connect(this,SIGNAL(AppendText(QString)),this,SLOT(SlotAppendText(QString))); void ClassName::Append(const QString &amp;amp;text) { emit AppendText(&amp;#34;ok: string1&amp;#34;); } //thread.cpp void ThreadClassName::SlotAppendText(const QString &amp;amp;text) { mText.append(text); } </description>
    </item>
    <item>
      <title>解决 Linux 启动出现 fsck exited with status code 4</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E5%90%AF%E5%8A%A8%E5%87%BA%E7%8E%B0fsck-exited-with-status-code-4/</link>
      <pubDate>Sat, 04 Dec 2021 10:18:09 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E5%90%AF%E5%8A%A8%E5%87%BA%E7%8E%B0fsck-exited-with-status-code-4/</guid>
      <description>保留现场 探究原因 磁盘检测不能通过，可能是因为系统突然断电或其它未正常关闭系统导致。
解决方法 根据提示可以看到是dev/sda5这个扇区出现了异常，所以通过fsck命令修复文件系统。详细命令解释。
将sda5改为自己损坏的扇区即可，等待一段时间修复完成后，输入exit即可重启。
fsck -y /dev/sda5 </description>
    </item>
    <item>
      <title>Qt 跨窗口，控件类传递数据</title>
      <link>http://localhost:8888/posts/qt%E8%B7%A8%E7%AA%97%E5%8F%A3%E6%8E%A7%E4%BB%B6%E7%B1%BB%E4%BC%A0%E9%80%92%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Thu, 02 Dec 2021 10:35:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E8%B7%A8%E7%AA%97%E5%8F%A3%E6%8E%A7%E4%BB%B6%E7%B1%BB%E4%BC%A0%E9%80%92%E6%95%B0%E6%8D%AE/</guid>
      <description>问题简介 本文基于【Qt】窗体间传递数据（跨控件跨类），三种情况与处理方法
已知三个窗体，A 为 B C 的父控件，B 与 C 互为兄弟控件 那么参数传递分三种情况：
B 向 A（C 向 A）传递参数 B 向 C（C 向 B）传递参数 A 向 B（A 向 C）传递参数 三个空间关系模型参考如下，
B 向 A（C 向 A）传递参数 //B.h class B { signals: void toA([ParamList]); } //B.cpp B::B() { emit toA([ParamList]); } //A.h class A { private: B *b; private slots: void fromB([ParamList]); } //A.cpp A::A() { b = new B; connect(b, SIGNAL(toA([ParamList])), this, SLOT(fromB([ParamList]))); } void A::fromB([ParamList]) { //get[ParamList] } B 向 C（C 向 B）传递参数 //A.</description>
    </item>
    <item>
      <title>Clang-Format 格式化代码</title>
      <link>http://localhost:8888/posts/clang-format%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Wed, 01 Dec 2021 17:42:45 +0000</pubDate>
      <guid>http://localhost:8888/posts/clang-format%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</guid>
      <description>安装 Linux sudo apt-get install clang-format windows 每每到这时候就越能感受到用 Linux 作为开发环境的优势，Windows 安装就稍显复杂了。
你可以选择安装完整的 LLVM，在bin目录可以看到clang-format.exe。安装完后，将 bin 目录添加到环境变量中。
你也可以只下载clang-format.exe，从LLVM Snapshot Builds下载安装包。在下载页面的底部。同样你需要将单独下载的文件加入到环境变量中。
使用 入门使用 Linux 可以直接命令行，使用以 LLVM 代码风格格式化main.cpp, 结果直接写到main.cpp
clang g-format -i main.cpp -style=LLVM 进阶配置 如果每次编码都命令行执行一遍那也太麻烦了，而且每次修改也不止一个文件。最好的方式就是每次保存文件时自动格式化。比如 VSCode 已经内置了Clang-Format稍作配置即可实现，接下来介绍几种常见 IDE 如何配置Clang-Format。
VSCode VSCode 最常用，因为内置了Clang-Format也最容易配置。
安装C/C++插件，Ctrl+Shift+X打开应用商店，搜索C/C++找到下图插件，安装后会自动安装Clang-Format程序，无需单独下载。默认安装路径为： C:\Users\(你的用户名)\.vscode\extensions\ms-vscode.cpptools-1.7.1\LLVM\bin\clang-format.exe。 打开设置页面（左下角齿轮 - 设置），搜索format，勾选Format On Save，每次保存文件时自动格式化文档。下方的设置是决定每次格式化是整个文档，还是做过修改的内容。默认是file，对整个文档进行格式化。 仍在设置页面搜索Clang，配置如下。.clang-format文件最后详解。 效果图 QtCreator 安装Beautifier插件：帮助（Help）-关于插件（About Plugins）- Beautifier勾选，重启 QtCreator。 工具（Tool）- Beautifier，配置如图。该配置，保存文档时自动格式化，并选择Clang-Format作为格式化工具。 配置Clang-Format程序路径，如果开头已经apt install安装过，这里会自动补全。 Use predefined style可以选择内置的一些代码风格，如LLVM，Google等。 Use customized style使用自定义的一些代码风格。点击添加（Add）将配置文件粘贴进去即可，具体配置文件见最后。 别忘了点击OK保存。 Eclipse 安装cppstyle插件：Help - Eclipse Marketplace - 搜索cppstyle。</description>
    </item>
    <item>
      <title>《代码整洁之道》读书笔记</title>
      <link>http://localhost:8888/posts/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 29 Nov 2021 23:20:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
      <description>代码整洁之道 整洁代码 整洁之道 代码是我们最终用来表达需求的那种语言，代码永存；
时时保持代码整洁，稍后等于永不（Later equals never）；
整洁代码力求集中，每个函数、每个类和每个模块都全神贯注于一件事；
整洁代码简单直接，从不隐藏设计者的意图；
整洁代码应当有单元测试和验收测试。它使用有意义的命名，代码通过其字面表达含义；
消除重复代码，提高代码表达力。
有意义的命名 避免误导 &amp;ldquo;一组账号&amp;quot;别用accountList表示，List对程序员有特殊含义，可以用 accountGroup、bunchOfAccounts、甚至是accounts；
不使用区别较小的名称，ZYXControllerForEfficientHandlingOfStrings和 ZYXControllerForEfficientStorageOfStrings难以辨别；
不使用小写 l、大写 O 作变量名，看起来像常量 1、0。
做有意义的区分 不以数字系列命名(a1、a2、a3)，按照真实含义命名；
Product/ProductInfo/ProductData 意思无区别，只统一用一个；
别写冗余的名字，变量名别带variable、表名别带table。
使用读得出来的名称 genymdhms（生成日期，年、月、日、时、分、秒）肯定不如generation timestamp（生成时间戳）方便交流。 使用可搜索的名称 单字母名称和数字常量很难在上下文中找出。名称长短应与其作用域大小相对应，越是频繁出现的变量名称得越容易搜索 (越长)。 命名时避免使用编码 把类型和作用域编码进名称里增加了解码负担。意味着新人除了了解代码逻辑之外，还需要学习这种编码语言；
别使用匈牙利语标记法(格式：[Prefix]-BaseTag-Name 其中 BaseTag 是数据类型的缩写，Name 是变量名字)，纯属多余。例如，szCmdLine的前缀sz表示“以零结束的字符串”；
不必用m_前缀来表明成员变量；
接口和实现别在名称中编码。接口名IShapeFactory的前导&amp;quot;I&amp;quot;是废话。如果接口和实现必须选一个编码，宁可选实现，ShapeFactoryImp都比对接口名称编码来的好。
避免思维映射 不应当让读者在脑中把你的名称翻译为他们熟知的名称。例如，循环计数器自然有可能被命名为i或j或k，但千万别用字母l；
专业程序员了解，明确是王道，编写能方便他人理解的代码。
类名、方法名 类名应当是名词或名词短语，方法名应当是动词或动词短语。 命名不要耍宝幽默 言到意到，意到言到，不要在命名上展示幽默感。 每个概念用一个词 fetch、retrieve、get约定一个一直用即可。 尽管使用计算机科学术语 只有程序员才会读你的代码，不需要按照问题所在邻域取名称。 别用双关语 add方法一般语义是：根据两个值获得一个新的值。如果要把单个值加入到某个集合，用insert或append命名更好，这里用add就是双关语了。 添加有意义的语境 很少有名称能自我说明，需要用良好命名的类、函数、或者命名空间来放置名称，给读者提供语境，如果做不到的话，给名称添加前缀就是最后一招了。 函数 越短越好 短小，20 行封顶；
if/else/while语句的代码块应该只有一行，该行应该是一个函数调用语句；
函数的缩进层级不应该多于一层或两层。
一个函数只做一件事 如果函数只是做了该函数名下同一抽象层上的步骤，则函数只做了一件事；
要判断函数是否不止做了一件事，就是要看是否能再拆出一个函数；
每个函数一个抽象层级 向下规则：让代码拥有自顶向下的阅读顺序。每个函数后面都跟着位于下一抽象层级的函数，这样一来，在查看函数列表时，就能循抽象层级向下阅读了。 switch 语句 把 switch 埋在较低的抽象层级，一般可以放在抽象工厂底下，用于创建多态对象。 使用描述性的名称 函数越短小、功能越集中，就越便于取个好名字；</description>
    </item>
    <item>
      <title>Git-git pull 与 git pull --rebase 的区别</title>
      <link>http://localhost:8888/posts/git-git-pull%E4%B8%8Egit-pull-rebase%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Mon, 29 Nov 2021 16:09:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/git-git-pull%E4%B8%8Egit-pull-rebase%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>git pull == git fetch + git merge git pull --rebase == git fetch + git rebase 拆解来看这两个命令就是在拉取远端代码后，是合并还是进行变基操作。
假设当前有三个提交A,B,C，并且分支feature都与远程代码同步。
我们在feature上做了一些修改，并产生了E提交，远程也有用户进行了更新到了D提交。
此时我们需要git fetch获取最新的代码，然后git merge解决冲突后重新git add git commit，得到F提交。最后git push即可成功推送，得到如下的关系
而使用git rebase将会创建一个新的提交F，F的文件内容和上面F的一样，但我们将 E 提交废除，当它不存在（图中用虚线表示）。由于这种删除，避免了菱形的产生，保持提交曲线为直线。
在rebase的过程中，有时也会有冲突，这时 Git 会停止rebase并让用户去解决冲突，解决完冲突后，用git add添加修改的文件，然后不用执行git commit，直接执行git rebase --continue，这样 git 会继续 apply 余下的补丁。</description>
    </item>
    <item>
      <title>Git 同一文件被多人修改了文件名该如何处理</title>
      <link>http://localhost:8888/posts/git%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%E8%A2%AB%E5%A4%9A%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E6%96%87%E4%BB%B6%E5%90%8D%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</link>
      <pubDate>Sun, 28 Nov 2021 21:55:24 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%E8%A2%AB%E5%A4%9A%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E6%96%87%E4%BB%B6%E5%90%8D%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</guid>
      <description>用户一修改了文件名，并推送到了远端。用户二也修改了文件名，在进行推送时，就会被拒绝。
拉取最新代码后发现有相同的文件，只是文件名不同。index1.htm和index2.htm两个文件内容是完全相同的。
查看当前状态，可知有其他想把文件名修改为index2.htm。此时只需要根据提示，删除index.htm。协商后决定保留哪一个文件，比如我们决定保留index1.htm。那么删除index2.htm。
最后在commit一次，即可顺利推送。</description>
    </item>
    <item>
      <title>Git 他人同时修改了文件名和文件内容该如何处理</title>
      <link>http://localhost:8888/posts/git%E4%BB%96%E4%BA%BA%E5%90%8C%E6%97%B6%E4%BF%AE%E6%94%B9%E4%BA%86%E6%96%87%E4%BB%B6%E5%90%8D%E5%92%8C%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</link>
      <pubDate>Sat, 27 Nov 2021 23:07:37 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%BB%96%E4%BA%BA%E5%90%8C%E6%97%B6%E4%BF%AE%E6%94%B9%E4%BA%86%E6%96%87%E4%BB%B6%E5%90%8D%E5%92%8C%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</guid>
      <description>用户一修改了文件名，并提交远端。 用户二修改了文件内容，也进行了推送， 当然会被无情拒绝， 解决这个问题也十分简单，Git 可以智能的感知到只是文件名被修改，只需要一个git pull命令就可以解决。弹出弹窗可以直接保存退出，默认不变就行。</description>
    </item>
    <item>
      <title>Git 不同人修改了相同文件的相同区域</title>
      <link>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E7%9B%B8%E5%90%8C%E6%96%87%E4%BB%B6%E7%9A%84%E7%9B%B8%E5%90%8C%E5%8C%BA%E5%9F%9F/</link>
      <pubDate>Sat, 27 Nov 2021 22:13:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E7%9B%B8%E5%90%8C%E6%96%87%E4%BB%B6%E7%9A%84%E7%9B%B8%E5%90%8C%E5%8C%BA%E5%9F%9F/</guid>
      <description>不同人修改了文件的相同区域，如果向远端推送，肯定会被拒绝。这时候就需要解决冲突，
首先拉取远端最新的代码，会提示有冲突的文件， 打开冲突的文件，git 会对冲突区域进行标记，&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;到======区域表示远端的代码。======到&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;表示本地的代码。这时候就需要自己来判断需要哪些代码，也可以增删一些内容，修改完成后将这些标识符号删除，然后保存退出。 git status查看当前状态，提示还有未合并的路径，需要进行commit操作。 及时git push当前代码。</description>
    </item>
    <item>
      <title>Linux 文件删除仍然在 Trash 目录下占用空间，该如何删除 Trash 下的文件</title>
      <link>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E5%88%A0%E9%99%A4%E4%BB%8D%E7%84%B6%E5%9C%A8trash%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E8%AF%A5%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4trash%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 25 Nov 2021 10:31:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E5%88%A0%E9%99%A4%E4%BB%8D%E7%84%B6%E5%9C%A8trash%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E8%AF%A5%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4trash%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</guid>
      <description>保留现场 探究原因 查阅了一个网上的答案，大意就是，你删除了属于你的文件夹，但其中包含属于另一个用户的文件时，文件可能会卡住，就会在 Trash 目录里不会被彻底删除。
解决方法 sudo rm -rv /home/&amp;lt;your_username&amp;gt;/.local/share/Trash/expunged/* PS：发现一个好用的磁盘分析工具，Linux 内置应用Disk Usage Analyzer。按Win键后搜索框搜索即可打开。
图形化的方式快速找到占用空间较大的目录，文件。可以右击直接删除。</description>
    </item>
    <item>
      <title>Git 如何合并连续的多个 commit</title>
      <link>http://localhost:8888/posts/git%E5%A6%82%E4%BD%95%E5%90%88%E5%B9%B6%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%A4%9A%E4%B8%AAcommit/</link>
      <pubDate>Wed, 24 Nov 2021 23:18:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E5%A6%82%E4%BD%95%E5%90%88%E5%B9%B6%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%A4%9A%E4%B8%AAcommit/</guid>
      <description> 确定需要合并的commit 变基操作，以需要合并的commit下方的结点为基准。 交互式变基，squash表示合并到上方commit 编写合并commit的message，保留原先的不变 </description>
    </item>
    <item>
      <title>Git 不同人修改了同一文件的不同区域该如何处理</title>
      <link>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8D%E5%90%8C%E5%8C%BA%E5%9F%9F%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 23 Nov 2021 22:49:46 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E5%90%8C%E4%B8%80%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8D%E5%90%8C%E5%8C%BA%E5%9F%9F%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</guid>
      <description> git fetch git merge 或者 git pull </description>
    </item>
    <item>
      <title>Git 修改老旧 commit 的 message</title>
      <link>http://localhost:8888/posts/git%E4%BF%AE%E6%94%B9%E8%80%81%E6%97%A7commit%E7%9A%84message/</link>
      <pubDate>Mon, 22 Nov 2021 22:50:25 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%BF%AE%E6%94%B9%E8%80%81%E6%97%A7commit%E7%9A%84message/</guid>
      <description>以下操作仅限于维护自己的分支，不建议对团队共享的代码进行修改。
以最近三次提交为例，假设想要修改第二个提交的message。可以使用git rebase命令 git rebase -i 27d2f -i交互式变基 27d2f需要改变message的提交的父节点 弹出页面可以使用提供的命令进行操作，比如pick意思就是挑选需要的commit。本次任务需要修改message，从下方帮助文档里可以找到reword命令，可以保留commit，只修改message。
保存退出后，会弹出另外一个界面。
在这里就可以真正修改需要更新的message。保存退出即可。</description>
    </item>
    <item>
      <title>Git 修改最新 commit 的 message</title>
      <link>http://localhost:8888/posts/git%E4%BF%AE%E6%94%B9%E6%9C%80%E6%96%B0commit%E7%9A%84message/</link>
      <pubDate>Mon, 22 Nov 2021 22:44:45 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%BF%AE%E6%94%B9%E6%9C%80%E6%96%B0commit%E7%9A%84message/</guid>
      <description>commit提交后觉得描述信息不准确，想重新修改message内容，该如何操作？
git commit --amend 弹出页面就和git commit操作时的一样，将其改为新内容即可。</description>
    </item>
    <item>
      <title>解决 C 语言 undefined reference to pthread_join</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3c%E8%AF%AD%E8%A8%80undefined-reference-to-pthread-join/</link>
      <pubDate>Wed, 17 Nov 2021 19:30:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3c%E8%AF%AD%E8%A8%80undefined-reference-to-pthread-join/</guid>
      <description>保留现场 undefined reference to sleep同样的问题。 在使用 C 语言线程函数时，需要包含#include &amp;lt;pthread&amp;gt;，编译时就会报这种错误。
探究原因 pthread 库不是 Linux 系统默认的库，连接时需要使用静态库 libpthread.a，所以在使用pthread_create()创建线程，以及调用pthread_atfork()函数建立fork处理程序时，需要链接该库。
解决方法 gcc thread.c -o thread -lpthread 如果是Makefile配置的编译条件，在Makefile文件中加上如下：
CFLAGS += -lpthread </description>
    </item>
    <item>
      <title>解决 QT 点击按钮无响应</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt%E7%82%B9%E5%87%BB%E6%8C%89%E9%92%AE%E6%97%A0%E5%93%8D%E5%BA%94/</link>
      <pubDate>Tue, 16 Nov 2021 17:42:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt%E7%82%B9%E5%87%BB%E6%8C%89%E9%92%AE%E6%97%A0%E5%93%8D%E5%BA%94/</guid>
      <description>保留现场 在运行中的界面上点击按钮没有效果，像是按钮上层有其他遮盖层。
探究原因 widget的父控件上又添加了其他Widget，覆盖在了按钮上，因此无法点击。通过new得到的控件，默认显示在比它new的早的控件上面。
解决方法 // 将有按钮的那一层widget置于上层 widget-&amp;gt;raise(); </description>
    </item>
    <item>
      <title>解决 QT 在构造函数中写的控件不显示的问题</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt%E5%9C%A8%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E4%B8%AD%E5%86%99%E7%9A%84%E6%8E%A7%E4%BB%B6%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 16 Nov 2021 16:15:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qt%E5%9C%A8%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E4%B8%AD%E5%86%99%E7%9A%84%E6%8E%A7%E4%BB%B6%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>保留现场 在新窗口中的构造函数中添加控件运行后却没有显示
探究原因 新建的工程师 MainWindow 子类工程，没有设置父窗口。
没有将控件的父窗口设置成自己定义的 widget。
#include&amp;lt;QMainWindow&amp;gt; QMainWindow::QMainWindow(QMainWindow*parent) : QMainWindow(parent), ui(new Ui::QMainWindow) { ui-&amp;gt;setupUi(this); QPushButton* button_1 = new QPushButton(&amp;#34;add&amp;#34;); QPushButton* button_1 = new QPushButton(&amp;#34;del&amp;#34;); } 解决方法 方法 1：给按钮控件设置父窗口：QWidget，并且把按钮添加到父窗口中。
#include&amp;lt;QMainWindow&amp;gt; #include&amp;lt;QPushButton&amp;gt; #include&amp;lt;QHBoxLayout&amp;gt; QMainWindow::QMainWindow(QMainWindow*parent) : QMainWindow(parent), ui(new Ui::QMainWindow) { ui-&amp;gt;setupUi(this); QWidget* w = new QWidget(); this-&amp;gt;setCentralWidget(w); QHBoxLayout* hLayout = new QHBoxLayout(); QPushButton* button_1 = new QPushButton(&amp;#34;add&amp;#34;); QPushButton* button_1 = new QPushButton(&amp;#34;del&amp;#34;); hLayout-&amp;gt;addWidget(button_1); hLayout-&amp;gt;addWidget(button_2); w-&amp;gt;setLayout(hLayout); } 方法 2：手动指定父窗口
#include&amp;lt;QMainWindow&amp;gt; #include&amp;lt;QPushButton&amp;gt; #include&amp;lt;QHBoxLayout&amp;gt; QMainWindow::QMainWindow(QMainWindow*parent) : QMainWindow(parent), ui(new Ui::QMainWindow) { ui-&amp;gt;setupUi(this); QPushButton* button_1 = new QPushButton(&amp;#34;add&amp;#34;); QPushButton* button_1 = new QPushButton(&amp;#34;del&amp;#34;); button_1-&amp;gt;setParent(this); button_2-&amp;gt;setParent(this); button_2-&amp;gt;move(300,100); } </description>
    </item>
    <item>
      <title>QWidget 中 update 不执行 paintEvent</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qwidget%E4%B8%ADupdate%E4%B8%8D%E6%89%A7%E8%A1%8Cpaintevent/</link>
      <pubDate>Mon, 15 Nov 2021 18:04:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3qwidget%E4%B8%ADupdate%E4%B8%8D%E6%89%A7%E8%A1%8Cpaintevent/</guid>
      <description>保留现场 手动执行update()或者repaint()都不能执行paintEvent函数。
探究原因 如果是代码new出来的控件，检查是否正确显示，比如有没有加入到layout中。或者有没有设置父窗口（可能被其他空间遮挡）。
检查控件width或者height大小是否不为 0。如果为 0，也不会出出发paintEvent。
解决方法 参考 QT 在构造函数中写的控件不显示</description>
    </item>
    <item>
      <title>解决 C&#43;&#43;中 vector 声明错误 expected parameter declarator</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3c-%E4%B8%ADvector%E5%A3%B0%E6%98%8E%E9%94%99%E8%AF%AFexpected-parameter-declarator/</link>
      <pubDate>Sat, 13 Nov 2021 19:00:29 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3c-%E4%B8%ADvector%E5%A3%B0%E6%98%8E%E9%94%99%E8%AF%AFexpected-parameter-declarator/</guid>
      <description>保留现场 QVector&amp;lt;uint32_t&amp;gt; buttonPins(3); 声明了一个长度为 3 的vector数组，编译是会报这个错误。
探究原因 编译器可能无法区分这是一个成员函数声明还是一个成员变量声明，也就是产生歧义。
解决方法 方法 1：
QVector&amp;lt;uint32_t&amp;gt; buttonPins = QVector&amp;lt;uint32_t&amp;gt;(3);//明确这是一个成员变量 方法 2：默认构造函数里面进行成员变量的初始化
MainWindow::MainWindow(QWidget *parent) : QMainWindow(parent), ui(new Ui::MainWindow),buttonPins(3){} 方法 3：列表初始化
QVector&amp;lt;uint32_t&amp;gt; buttonPins{0, 0, 0}; </description>
    </item>
    <item>
      <title>解决 expected identifier before‘(’token</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3expected-identifier-before---token/</link>
      <pubDate>Fri, 12 Nov 2021 19:34:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3expected-identifier-before---token/</guid>
      <description>保留现场 比如在一个枚举类型中，会告诉你某行有这种错误。又或者，在一个宏定义语句中出现这种错误。
探究原因 一般来说，出现这种情况，是语句中有些定义的名字发生了冲突。
解决方法 定位错误位置，搜索是否有同名的函数，变量等等。改个名字。</description>
    </item>
    <item>
      <title>QEMU 源码分析-外设模拟（以 GPIO 为例）</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%A4%96%E8%AE%BE%E6%A8%A1%E6%8B%9F%E4%BB%A5gpio%E4%B8%BA%E4%BE%8B/</link>
      <pubDate>Thu, 11 Nov 2021 10:11:32 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%A4%96%E8%AE%BE%E6%A8%A1%E6%8B%9F%E4%BB%A5gpio%E4%B8%BA%E4%BE%8B/</guid>
      <description>QEMU 模拟外设的原理 QEMU 主要是实现了 CPU 核的模拟，可以读写某个地址。 QEMU 的模拟外设的原理很简单：硬件即内存。 要在 QEMU 上模拟某个外设，思路就是：
CPU 读某个地址时，QEMU 模拟外设的行为，把数据返回给 CPU CPU 写某个地址时，QEMU 获得数据，用来模拟外设的行为。 即：要模拟外设备，我们只需要针对外设的地址提供对应的读写函数即可。 以 GPIO 为例：
QEMU 为GPIO内存地址提供读写回调函数，
static void sifive_gpio_write(void *opaque, hwaddr offset, uint64_t value, unsigned int size) static uint64_t sifive_gpio_read(void *opaque, hwaddr offset, unsigned int size) 给外设地址提供读写函数 怎么描述某段地址：基地址、大小？如何给这段地址提供读写函数呢？这段地址设置好后，如何添加进system_memory去？有 2 种方法。
法 1：memory_region_init_io/memory_region_add_subregion 以SIFIVE_UART为例，
memory_region_init_io(&amp;amp;s-&amp;gt;mmio, NULL, &amp;amp;uart_ops, s, TYPE_SIFIVE_UART, 0x2000); memory_region_add_subregion(address_space, base, &amp;amp;s-&amp;gt;mmio); memory_region_init_io函数初始化iomem，读写函数，大小。 memory_region_add_subregion函数s-&amp;gt;iomem指定了基地址，并添加进system_memory中。 以后，客户机上的程序读写这块地址时，就会导致对应的读写函数被调用。
法 2：memory_region_init_io/sysbus_init_mmio/sysbus_mmio_map 以SIFIVE_GPIO为例，
memory_region_init_io(&amp;amp;s-&amp;gt;mmio, OBJECT(dev), &amp;amp;gpio_ops, s, TYPE_SIFIVE_GPIO, SIFIVE_GPIO_SIZE); sysbus_init_mmio(SYS_BUS_DEVICE(dev), &amp;amp;s-&amp;gt;mmio); memory_region_init_io函数初始化iomem，读写函数，大小。 sysbus_init_mmio将mmin传给设备；</description>
    </item>
    <item>
      <title>QEMU 源码分析 - 虚拟外设创建</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9F%E5%A4%96%E8%AE%BE%E5%88%9B%E5%BB%BA/</link>
      <pubDate>Tue, 09 Nov 2021 17:39:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9F%E5%A4%96%E8%AE%BE%E5%88%9B%E5%BB%BA/</guid>
      <description>QOM 简介 QOM(QEMU Object Model) 是 QEMU 的一个模块，用于描述虚拟机的结构，包括虚拟机的 CPU、内存、硬盘、网络、输入输出设备等。QEMU 为了方便整个系统的构建，实现了自己的一套的面向对象机制，也就是 QOM(QEMU Object Model)。它能够方便的表示各个设备（Device）与总线（Bus）之间的关系。
这个模型主要包含四个结构体：
Object: 是所有对象的 基类 Base Object ObjectClass: 是所有类对象的基类 TypeInfo：是用户用来定义一个 Type 的工具型的数据结构 TypeImpl：TypeInfo 抽象数据结构，TypeInfo 的属性与 TypeImpl 的属性对应 在 QEMU 里要初始化一个对象需要完成四步：
将 TypeInfo 注册 TypeImpl 实例化 Class（ObjectClass） 实例化 Object 添加 Property 如何描述硬件 一个板子上有很多硬件：芯片，LED、按键、LCD、触摸屏、网卡等等。芯片里面也有很多部件，比如 CPU、GPIO、SD 控制器、中断控制器等等。
这些硬件，或是部件，各有不同。怎么描述它们？
每一个都使用一个 TypeInfo 结构体来描述，TypeInfo 是用户用来定义一个 Type 的工具型的数据结构。它包含了很多成员变量，这些成员合在一起描述了一个设备类型。
// include/qom/object.h struct TypeInfo { const char *name; const char *parent; size_t instance_size; size_t instance_align; void (*instance_init)(Object *obj); void (*instance_post_init)(Object *obj); void (*instance_finalize)(Object *obj); bool abstract; size_t class_size;void (*class_init)(ObjectClass *klass, void *data); void (*class_base_init)(ObjectClass *klass, void *data); void *class_data;InterfaceInfo *interfaces; }; 这个结构体我们在刚刚也提到，他在图里是独立的，在注册的时候会将它的信息都传给 Typeimpl 结构体。</description>
    </item>
    <item>
      <title>解决一台电脑配置两个 GIT 账户</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AAgit%E8%B4%A6%E6%88%B7/</link>
      <pubDate>Sat, 30 Oct 2021 11:14:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AAgit%E8%B4%A6%E6%88%B7/</guid>
      <description>公司的也在用 git，但是账号和地址肯定都不同，需要配置两个不同的提交环境。
生成两个 Key 生成第一个 Key 如果电脑上已经在用 Git 了就无需重新生成 key，用当前的就可以。key 保存在~/.ssh文件夹内。
如果第一次使用，就使用以下命令重新生成：
➜ .ssh ssh-keygen -t rsa -C home_pc Generating public/private rsa key pair. Enter file in which to save the key (/home/dominic/.ssh/id_rsa): id_rsa_pc home_pc就是个备注名，假设我们这个 key 是平时捣腾 GitHub 玩，用来和 GitHub 同步用的，id_rsa_pc是生成的文件名，打开id_rsa_pc.pub可以看到生成的 key 最后就是备注名（如下）。
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABR/Fyj7Pz+e+/////////////////ZbdPGtHB86fLQYh/uR+TKcCERedrDKzGPdVt8= home_pc 配置 GitHub SSH 路径为：
Github-头像-settings-SSH and GPG keys-New SSH key 测试连通 ssh -T git@github.com 生成第二 Key 这个 key 就打算用来和公司代码同步用，所以备注名换成了work_ubuntu，文件名也换成了id_rsa_work。
➜ .ssh ssh-keygen -t rsa -C work_ubuntu Generating public/private rsa key pair.</description>
    </item>
    <item>
      <title>C 语言复杂声明</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%A4%8D%E6%9D%82%E5%A3%B0%E6%98%8E/</link>
      <pubDate>Fri, 22 Oct 2021 11:02:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%A4%8D%E6%9D%82%E5%A3%B0%E6%98%8E/</guid>
      <description>C 语言常常因为声明的语法问题而受到人们的批评，特别是涉及到函数指针的语法。C 语言的语法力图使声明和使用相一致。对于简单的情况，C 语言的做法是很有效的，但是，如果情况比较复杂，则容易让人混淆，原因在于，C 语言的声明不能从左至右阅读，而且使用了太多的圆括号。 在 C 中，声明的形式为（dcl 是 declaration 的简写）：
dcl: optional *&amp;#39;s direct-dcl（含有可选&amp;#34;*&amp;#34;的direct-dcl）direct-dcl name(dcl)direct-dcl()direct-dcl[optional size] 简而言之，声明符dc1(可以理解成间接声明) 就是前面可能带有多个*的direcr-dclo。direct-dcl可以是name、由一对圆括号括起来的dcl、后面跟有一对圆括号的direct-dcl、后面跟有用方括号括起来的表示可选长度的direc-dcl。
根据该规则进行逆向解析，就可以得到正确的声明。简化一下：TypeName Declarator;其中，Declarator就是声明中的那个name。当你遇到任何你不能理解的声明时，这个法则就是救命稻草。最简单的例子：
int aInt; 这里，int是TypeName，aInt是Declarator。
再说明一下结合紧密度。在声或定义变量时，可以使用一些修饰比如*，[]，()等。()（非函数声明中的()）具有最高的紧密度，其次才是函数和数组的()和[]。
没有*的声明称为直接声明（direct-dcl），而有*称为声明（dcl）。直接声明要比声明结合的紧。分解声明时，先读出结合紧的。在这里，我把direct-dcl称为更紧的结合，它比dcl结合得紧。
最后，需要你用英语来读出这个声明。对于[]，应该读成array of。
对于复杂的定义，可以将其分解。比如T (*p)()可以分解成T D1()，D1读作：function returning T。其中D1是*p。那么该声明应该读成：p is a poniter to。二者合在一起，就变成了 p is a pointer to function returning T，即：p是指向返回T类对象的函数的指针。
再看一个稍微复杂的示例：
T (*pfa[])(); 根据dcl和direct-dcl，可以分解成T1 D1（因为结合紧密度），T1也就是T ()，那么应该读作： D1 is function returning T。
D1又可以写成T2 D2，其中T2是T1 []，可以分解成T1 D2[]，读作：array of D2 function returning T。
D2是指针，读作：pointers to。那么整个 T (*pfa[])() 应该读作：pfa is an array of pointers to function returning T，即：pfa是个存放指向返回 T 类对象函数的指针的数组。</description>
    </item>
    <item>
      <title>C 语言共享内存实现 CyclicBuffer 循环缓冲区</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%AE%9E%E7%8E%B0cyclicbuffer%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA/</link>
      <pubDate>Thu, 21 Oct 2021 17:12:06 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%AE%9E%E7%8E%B0cyclicbuffer%E5%BE%AA%E7%8E%AF%E7%BC%93%E5%86%B2%E5%8C%BA/</guid>
      <description>完整代码详见GitHub CyclicBuffer。
什么是循环缓冲区 循环缓冲区通常应用在模块与模块之间的通信，可以减少程序挂起的时间，节省内存空间。
如图所示，蓝色箭头表示读取指针，红色表示写入指针。写入指针可以在缓冲区有剩余空间时不中断地写入数据，读取指针可以在循环缓冲区有数据时不停读取。
如何设计循环缓冲区 为了方便两个进程之间的通信，我们在共享内存中创建循环缓冲区。基本原理如图：
结构体定义 typedef struct CyclicBuffer { uint8_t buf[CYCBUFFSIZ]; //缓冲区 uint8_t read; //读指针 uint8_t write; //写指针 uint32_t valid_size; //已写入数据数 } CyCBuf; 写入数据 void cycbuff_write(CyCBuf *cycbuff, uint8_t ch) { while (cycbuff_isfull(cycbuff)) ; cycbuff-&amp;gt;buf[cycbuff-&amp;gt;write] = ch; cycbuff-&amp;gt;write++; cycbuff-&amp;gt;write %= CYCBUFFSIZ; cycbuff-&amp;gt;valid_size++; } 写入数据前，要检查缓冲区是否已满，如果已满就得挂起等待。直到缓冲区有空间再进行写入。
写入指针每次写完向后偏移一位，valid_size记录当前缓冲区中有效数据个数。
读取数据 uint8_t cycbuff_read(CyCBuf *cycbuff) { uint8_t ch; while (cycbuff_isempty(cycbuff)) ; ch = cycbuff-&amp;gt;buf[cycbuff-&amp;gt;read]; cycbuff-&amp;gt;read++; cycbuff-&amp;gt;read %= CYCBUFFSIZ; cycbuff-&amp;gt;valid_size--; return ch; } 读取数据前，要检查缓冲区是否为空，如果为空就要挂起等待。
判断空 bool cycbuff_isempty(CyCBuf *cycbuff) { if (cycbuff-&amp;gt;valid_size == 0) return true; return false; } 判断满 bool cycbuff_isfull(CyCBuf *cycbuff) { if (cycbuff-&amp;gt;valid_size == CYCBUFFSIZ) return true; return false; } 本次实验中，为了方便期间，用valid_size保存有效数据个数，没有用读写指针是否重合来判断，这就无需再考虑读写指针重合时，是空还是满。</description>
    </item>
    <item>
      <title>解决 gcc 编译后 fflush 失效</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc%E7%BC%96%E8%AF%91%E5%90%8Efflush%E5%A4%B1%E6%95%88/</link>
      <pubDate>Thu, 21 Oct 2021 09:56:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc%E7%BC%96%E8%AF%91%E5%90%8Efflush%E5%A4%B1%E6%95%88/</guid>
      <description>保留现场 使用scanf()获取输入时，因为涉及键盘缓冲区的问题，每次输入后想要把缓冲清空，但是在 gcc 编译后，使用fflush无法清空缓冲区。
探究原因 C 标准 (ISO/IEC 9899:1999 standard) 规定fflush(stdin)操作是未定义的&amp;lt;参看《ISO/IEC 9899:1999 standard》p270&amp;gt;;。也就是说不一定能实现刷新功能，但有的编译器可能不遵循标准，对fflush(stdin)操作不予警告，并且有时可能产生正确的结果，但最好不要这样使用。
解决方法 通过 while 循环把输入流中的余留数据“吃”掉：
int c; while ((c=getchar()) != ‘\n’ &amp;amp;&amp;amp; c != EOF); </description>
    </item>
    <item>
      <title>RISC-V 入门-RVOS 系统引导</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-rvos%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC/</link>
      <pubDate>Wed, 20 Oct 2021 23:13:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-rvos%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC/</guid>
      <description>操作系统定义与分类 操作系统（英语：Operating System，缩写：OS）是一组系统软件程序，狭义上就是内核如 Linux，广义上就是内核加一组软件组成的发行包，如 Ubuntu，Debian：
• 主管并控制计算机操作、运用和运行硬件、软件资源
• 提供公共服务来组织用户交互。
硬件的基本概念 Hart Platform 不能说是个板子，应该理解为芯片。早期的板子就是一块芯片加上各种外设，但是随着技术发展，板子越来越小，外设却并没有变少，是因为外设都被集成到了芯片中。当所有外设都被集成，那么芯片就是 platform。 SoC(System on Chip) 片上系统 QEMU 模拟 virt 这个平台，这个平台有八个 Hart。
地址映射 为了方便访问外设，现在主流的 platform 会对外设的内存地址做一个映射。映射到 platform 的真实物理地址。对真实物理地址进行操作时，就是对外设的地址进行操作。
物理地址从最低位到最高位都被分配给了各种外设。
引导过程介绍 通电后，会先到箭头所指的地址，这个地址就是对应的 ROM 外设首地址。ROM 相当于一个小硬盘，断电后不会丢失数据。这里面固化了一些指令。
主要就是跳转指令，运行到 kernel 段继续执行。
八核同时会执行这个过程。
以上是硬件的部分过程，软件该如何写？
为了简化学习流程和降低调试难度，目前只支持单核，其余七个核处于空转状态。
如何判断当前 Hart 是不是第一个？ 这些寄存器必须使用以下的指令读写：
以上指令就是将寄存器值进行一次交换，只不过这个过程是原子性的，不能被打断。
CSRRW经常会用在伪指令CSRW中，完整指令中，第一步向x0写入数据，就是空操作，第二步将rs写入csr。这个伪指令就是完成了一个写入csr的操作。
mhartid就是machine hart id。
学习以上几个指令，就可以完成判断 hart 是否为第一个的工作了，
csrr t0, mhartid #读寄存器值 mv tp, t0 # bnez t0, park # 跳转指令，不等于 0 就跳转到 park 标签 wfi休眠指令 如何初始化栈空间 如何跳转到 C 语言环境 # start.</description>
    </item>
    <item>
      <title>解决 Segmentation fault (core dumped)</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3segmentation-fault-core-dumped/</link>
      <pubDate>Wed, 20 Oct 2021 14:23:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3segmentation-fault-core-dumped/</guid>
      <description>相关概念 Core 在使用半导体作为内存的材料前，人类是利用线圈当作内存的材料（发明者为王安），线圈就叫作 core ，用线圈做的内存就叫作 core memory。如今，半导体工业澎勃发展，已经没有人用core memory 了，不过，在许多情况下，人们还是把记忆体叫作 core 。
Core dump 我们在开发（或使用）一个程序时，最怕的就是程序莫明其妙地宕掉。虽然系统没事，但我们下次仍可能遇到相同的问题。于是这时操作系统就会把程序宕掉时的内存内容 dump 出来（现在通常是写在一个叫 core 的 file 里面），让我们做为参考。这个动作就叫作 core dump。
如何获取 Core 文件 1、在一些 Linux 版本下，默认是不产生core文件的，首先可以查看一下系统core文件的大小限制：
$:~/segfault$ ulimit -c0 2、可以看到默认设置情况下，本机 Linux 环境下发生段错误时不会自动生成core文件，下面设置下core文件的大小限制（单位为 KB）：
$:~/segfault$ ulimit -c 1024$:~/segfault$ ulimit -c1024 3、重新运行程序，如果发生段错误，就会生成core文件。
出现段错误的可能原因 访问不存在的内存地址 #include&amp;lt;stdio.h&amp;gt; #include&amp;lt;stdlib.h&amp;gt; void main() { int *ptr = NULL; *ptr = 0; } 访问系统保护的内存地址 #include&amp;lt;stdio.h&amp;gt; #include&amp;lt;stdlib.h&amp;gt; void main() { int *ptr = (int *)0; *ptr = 100; } 访问只读的内存地址 #include&amp;lt;stdio.</description>
    </item>
    <item>
      <title>RISC-V 入门-RISC-V 汇编语言编程</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-risc-v%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Sat, 16 Oct 2021 23:26:42 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-risc-v%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B/</guid>
      <description>汇编语法介绍 一条典型的 RISC-V 汇编语句由三个部分组成[label:][operation][comment]。 后缀.s和.S区别：后者纯汇编。
label(标号) operation 可以有以下多种类型： instruction (指令) ：直接对应二进制机器指令的宇符串 pseudo-instruction (伪指令) ：为了提高编写代码的效率，可以用一条伪指令指示汇编器产生多条实际的指令 (instructions)。 directive (指示/伪操作) ：通过类似指令的形式(以&amp;quot;.&amp;ldquo;开头),通知汇编器如何控制代码的产生等，不对应具体的指令。 macro：采用.macro/.endm 自定义的宏 例子 .macro do_nothing # directive nop # pseudo-instruction nop # pseudo-instruction .endm # directive .text # directive .global _start # directive _start: # Label li x6, 5 # pseudo-instruction li x7, 4 # pseudo-instruction add x5, x6, x7 # instruction do_nothing # Calling macro stop: j stop # statement in one line .</description>
    </item>
    <item>
      <title>C 语言可变参数</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/</link>
      <pubDate>Tue, 12 Oct 2021 11:21:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/</guid>
      <description>学习过程中查看了printf()源码，遇到了这样的函数定义，
void printf(char *fmt, ...){ char buf[256]; va_list args; memset(buf, 0, sizeof(buf)); va_start(args, fmt); vsprint(buf, fmt, args); va_end(args); puts(buf); } 参数中的三个点号，就是 C 语言中可变参数的标识。这样的函数称为可变参数函数。这种函数需要固定数量的强制参数（mandatory argument），后面是数量可变的可选参数（optional argument）。
这种函数必须至少有一个强制参数。可选参数的类型可以变化。可选参数的数量由强制参数的值决定，或由用来定义可选参数列表的特殊值决定。
C 语言中最常用的可变参数函数例子是printf（）和 scanf（）。这两个函数都有一个强制参数，即格式化字符串。格式化字符串中的转换修饰符决定了可选参数的数量和类型。
可变参数函数要获取可选参数时，必须通过一个类型为 va_list 的对象，它包含了参数信息。这种类型的对象也称为参数指针（argument pointer），它包含了栈中至少一个参数的位置。可以使用这个参数指针从一个可选参数移动到下一个可选参数，由此，函数就可以获取所有的可选参数。va_list 类型被定义在头文件 stdarg.h 中。
当编写支持参数数量可变的函数时，必须用 va_list 类型定义参数指针，以获取可选参数。在下面的讨论中，va_list 对象被命名为 argptr。可以用 4个宏来处理该参数指针，这些宏都定义在头文件 stdarg.h 中：
宏 va_start 使用第一个可选参数的位置来初始化 argptr 参数指针。该宏的第二个参数必须是该函数最后一个有名称参数的名称。必须先调用该宏，才可以开始使用可选参数。
void va_start(va_list argptr, lastparam); 展开宏 va_arg 会得到当前 argptr 所引用的可选参数，也会将 argptr 移动到列表中的下一个参数。宏 va_arg 的第二个参数是刚刚被读入的参数的类型。
type va_arg(va_list argptr, type); 当不再需要使用参数指针时，必须调用宏 va_end。如果想使用宏 va_start 或者宏 va_copy 来重新初始化一个之前用过的参数指针，也必须先调用宏 va_end。va_end被定义为空。它只是为实现与 va_start 配对 (实现代码对称和&amp;quot;代码自注释&amp;quot;(根据代码就能知道功能，不需要额外注释) 功能)</description>
    </item>
    <item>
      <title>Linux 下将编译结果输出到文件</title>
      <link>http://localhost:8888/posts/linux%E4%B8%8B%E5%B0%86%E7%BC%96%E8%AF%91%E7%BB%93%E6%9E%9C%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 30 Sep 2021 15:18:32 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E4%B8%8B%E5%B0%86%E7%BC%96%E8%AF%91%E7%BB%93%E6%9E%9C%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/</guid>
      <description>在命令行编译项目时，经常遇到编译结果太长，覆盖了最先输出的结果，此时就需要将结果输出到文件再查看。命令如下：
make &amp;gt; make.log 2&amp;gt;&amp;amp;1 # make 编译命令 # make.log 输出文件名 # 2 文件描述符，标准错误 # &amp;gt; 重定向符，输出 # &amp;amp;1 文件描述符&amp;amp;，文件描述符1 标准输入 该命令功能即将make编译时输出，标准错误重定向为标准输入，写入到make.log文件中。符号的含义可以参考Linux 文件描述符</description>
    </item>
    <item>
      <title>Linux 文件描述符</title>
      <link>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</link>
      <pubDate>Thu, 30 Sep 2021 11:13:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</guid>
      <description>前言 Linux 中一切皆文件，比如 C++ 源文件、视频文件、Shell 脚本、可执行文件等，就连键盘、显示器、鼠标等硬件设备也都是文件。
一个 Linux 进程可以打开成百上千个文件，为了表示和区分已经打开的文件，Linux 会给每个文件分配一个编号（一个 ID），这个编号就是一个整数，被称为文件描述符（File Descriptor）。
文件描述符是什么？ 一个 Linux 进程启动后，会在内核空间中创建一个 PCB 控制块，PCB 内部有一个文件描述符表（File descriptor table），记录着当前进程所有可用的文件描述符，也即当前进程所有打开的文件。
除了文件描述符表，系统还需要维护另外两张表：
打开文件表（Open file table） i-node 表（i-node table） 文件描述符表每个进程都有一个，打开文件表和 i-node 表整个系统只有一个，它们三者之间的关系如下图所示。
对上图的说明：
在进程A 中，文件描述符 1 和20 都指向了同一个打开文件表项，标号为 23（指向了打开文件表中下标为 23 的数组元素），这可能是通过调用 dup()、dup2()、fcntl() 或者对同一个文件多次调用了 open() 函数形成的。 进程 A 的文件描述符 2和进程B 的文件描述符2 都指向了同一个文件，这可能是在调用 fork() 后出现的（即进程 A、B是父子进程关系），或者是不同的进程独自去调用open() 函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。 进程 A 的描述符0和进程B的描述符3分别指向不同的打开文件表项，但这些表项均指向 i-node 表的同一个条目（标号为 1976）；换言之，它们指向了同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了 open() 调用。同一个进程两次打开同一个文件，也会发生类似情况。 通过文件描述符，可以找到文件指针，从而进入打开文件表。该表存储了以下信息：
文件偏移量，也就是文件内部指针偏移量。调用read()或者write() 函数时，文件偏移量会自动更新，当然也可以使用 lseek() 直接修改。 状态标志，比如只读模式、读写模式、追加模式、覆盖模式等。 i-node 表指针。 然而，要想真正读写文件，还得通过打开文件表的 i-node 指针进入</description>
    </item>
    <item>
      <title>VScode 快速添加注释模板</title>
      <link>http://localhost:8888/posts/vscode%E5%BF%AB%E9%80%9F%E6%B7%BB%E5%8A%A0%E6%B3%A8%E9%87%8A%E6%A8%A1%E6%9D%BF/</link>
      <pubDate>Wed, 29 Sep 2021 17:03:13 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E5%BF%AB%E9%80%9F%E6%B7%BB%E5%8A%A0%E6%B3%A8%E9%87%8A%E6%A8%A1%E6%9D%BF/</guid>
      <description>需求 通常函数的注释一般都比较长，而且每个函数注释都格式一致，例如下面的函数注释模板。如果每次写注释都要复制一遍比较麻烦，复制完还要删除多余的字符。但是现有的编辑器一般都支持快捷输入。下面介绍在 VSCode 中如何快捷输入注释模板。
方法 Ctrl+Shift+P打开编辑器命令窗口 - 输入snippets-选择Preferences:Configure User Snippets-选择·c.json· 更改如下：
{ // Place your snippets for c here. Each snippet is defined under a snippet name and has a prefix, body and // description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are: // $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders.</description>
    </item>
    <item>
      <title>QtCreator 快速添加注释模板</title>
      <link>http://localhost:8888/posts/qtcreator%E5%BF%AB%E9%80%9F%E6%B7%BB%E5%8A%A0%E6%B3%A8%E9%87%8A%E6%A8%A1%E6%9D%BF/</link>
      <pubDate>Tue, 28 Sep 2021 19:26:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/qtcreator%E5%BF%AB%E9%80%9F%E6%B7%BB%E5%8A%A0%E6%B3%A8%E9%87%8A%E6%A8%A1%E6%9D%BF/</guid>
      <description>需求 通常函数的注释一般都比较长，而且每个函数注释都格式一致，例如下面的函数注释模板。如果每次写注释都要复制一遍比较麻烦，复制完还要删除多余的字符。但是现有的编辑器一般都支持快捷输入。下面介绍在 QtCreator 中如何快捷输入注释模板。
/* * Description: // 函数功能、性能等的描述 * Input Parameter: // 输入参数说明，包括每个参数的作 * Output Parameter: // 对输出参数的说明。 * Return: // 函数返回值的说明 */ 方法 QtCreator-菜单栏工具（Tool）- 选项（Options）- 文本编辑器（Text Editor）- 片段（Snippets） 组（Group）选择C++-添加（Add） 现在要为我们的触发（Trigger）起个名字，因为是函数注释，我起了个funcom，然后在下方空白框里填入注释模板。Apply 保存。如图 在需要添加注释模板的地方输入funcom即可提示快捷输入，回车即可添加注释模板。 我们可以看到片段里有很多熟悉的内容，比如if else，我们在写代码时输入if else自动补全花括号其实就是在这里设置的。同理，我们还可以设置一些其他需要的快捷输入内容。比如行注释，文件注释，经常使用的代码框架等等。</description>
    </item>
    <item>
      <title>Qt 修改 UI 文件不生效</title>
      <link>http://localhost:8888/posts/qt%E4%BF%AE%E6%94%B9ui%E6%96%87%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88/</link>
      <pubDate>Sun, 26 Sep 2021 09:19:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E4%BF%AE%E6%94%B9ui%E6%96%87%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88/</guid>
      <description>保留现场 修改了 UI 文件后，在代码中无法调用新增的内容。
探究原因 导致ui_*.h文件没有更新的原因是源代码中#include ui_*.h的位置和实际生成的位置不同，引用的是老的ui_*.h
解决方法 方法一：
项目设置文件.pro内增加 UI_DIR=./UI，同时删除掉源代码目录中ui_*.h，clear all,-&amp;gt;qmake-&amp;gt;rebuilt all 方法二：</description>
    </item>
    <item>
      <title>QtCreator 修改项目构建目录</title>
      <link>http://localhost:8888/posts/qtcreator%E4%BF%AE%E6%94%B9%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA%E7%9B%AE%E5%BD%95/</link>
      <pubDate>Sat, 25 Sep 2021 19:17:46 +0000</pubDate>
      <guid>http://localhost:8888/posts/qtcreator%E4%BF%AE%E6%94%B9%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA%E7%9B%AE%E5%BD%95/</guid>
      <description>保留现场 QtCreator 构建项目时，会在统计目录新建一个build-xxx-debug的目录，如果想要自己修改这个目录的位置，名称，该怎么办。
解决方法 仅修改工具（Tool）–&amp;gt;选项 (Options)–&amp;gt;构建和运行 (Build&amp;amp;Run) 中Default build directory：./%{CurrentBuild:Name}是不会生效的。
将工具–&amp;gt;选项–&amp;gt;构建和运行中Default build directory修改为./%{CurrentBuild:Name}（改为你想要的目标目录都行）；
把 QtCreator 关闭，把工程目录下后缀名为.pro.user的文件删掉；
用 QtCreator 打开工程，会提示你创建构建目录，此时提示的就是你修改后的Default build directory中填写的目录；
其中.pro.user文件记录了编译器、构建工具链、构建目录、版本…..等工程编译相关信息，想要更换项目的编译环境，得删除这个文件，由 QtCreator 自动重新创建。</description>
    </item>
    <item>
      <title>Git-把本地仓库同步到 GitHub</title>
      <link>http://localhost:8888/posts/git%E6%8A%8A%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E5%90%8C%E6%AD%A5%E5%88%B0github/</link>
      <pubDate>Thu, 23 Sep 2021 23:06:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E6%8A%8A%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E5%90%8C%E6%AD%A5%E5%88%B0github/</guid>
      <description>需求 因为现在大部分情况下是先从远程 Clone 下来代码，所以这一功能用的不多。但是如果自己想把本地已有的代码同步到远程，本文就可以解决这一的需求。
方法 GitHub 新建一个仓库，并复制 SSH 地址
git@github.com:git201901/git_learning.git git remote add 名称
pc:git-learning suling$ git remote add github git@github.com:git201901/git_learning.git 这里的github就是自定义的一个名称，用于替换后面的远程地址。方便后续git push github以及git fetch github。</description>
    </item>
    <item>
      <title>解决 Undefined reference to 问题</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3undefined-reference-to%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 17 Sep 2021 11:14:30 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3undefined-reference-to%E9%97%AE%E9%A2%98/</guid>
      <description>链接时缺失了相关目标文件 这是最典型最常见的情况。比如新添加了一个模块fun.h fun.c两个文件，其他文件中使用了这个模块里的函数，如果编译时忘记加上这两个文件，调用fun模块函数的地方，就会报undefined reference错误。
这个问题在编辑器中一般不容易发现，因为头文件包含是正确的，编辑器能够找到相关的函数及其实现，所以在编写代码时不会报错。
链接时缺少相关的库文件 这个原因和上一条类似，我们在调用静态库中的函数时，编译时如果没有将静态库一起编译，就会报同样的错误。
链接的库文件中又使用了另一个库文件 在使用第三方库时，一定要在编译中加入第三方库的路径。
多个库文件链接顺序问题 在链接命令中给出所依赖的库时，需要注意库之间的依赖顺序，依赖其他库的库一定要放到被依赖库的前面，这样才能真正避免 undefined reference 的错误，完成编译链接。
声明与实现不一致 这个原因也比较典型，注意排查声明与实现的参数是否一致，返回值是否一致。
在 c++代码中链接 c 语言的库 在C++代码中，调用了C语言库的函数，因此链接的时候找不到，解决方法是在相关文件添加一个extern &amp;quot;C&amp;quot;的声明即可。
总结 顾名思义，这个错误就是未定义你使用的内容导致的。所以要排查使用的内容是否能够被正确“找到”。使用的时候有没有声明，有没有定义，声明与定义是否一致，编译时能否正确链接等等。
相关参考 &amp;ldquo;undefined reference to&amp;rdquo; 问题汇总及解决方法</description>
    </item>
    <item>
      <title>C/C&#43;&#43;如何避免过多使用全局变量</title>
      <link>http://localhost:8888/posts/c-c-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E8%BF%87%E5%A4%9A%E4%BD%BF%E7%94%A8%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/</link>
      <pubDate>Fri, 17 Sep 2021 10:49:15 +0000</pubDate>
      <guid>http://localhost:8888/posts/c-c-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E8%BF%87%E5%A4%9A%E4%BD%BF%E7%94%A8%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/</guid>
      <description>‘
具体实例可以参考Marc Pony
指针传参 C 语言中，全局变量用结构体封装，设计函数时，将参数以结构体指针形式传入。
定义获取变量的方法/函数 定义一个函数以get/set全局变量，利用static变量，将全局变量作用域限定于该函数，将全局变量隐藏起来。
善用static 把全局变量定义在某一个 .c 文件中，并定义为 static 类型，然后定义一系列操作这个变量的函数，头文件里面只有操作函数，没有变量的声明</description>
    </item>
    <item>
      <title>C 语言 sizeof(结构体) 到底有多大</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80sizeof-%E7%BB%93%E6%9E%84%E4%BD%93-%E5%88%B0%E5%BA%95%E6%9C%89%E5%A4%9A%E5%A4%A7/</link>
      <pubDate>Wed, 15 Sep 2021 18:38:07 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80sizeof-%E7%BB%93%E6%9E%84%E4%BD%93-%E5%88%B0%E5%BA%95%E6%9C%89%E5%A4%9A%E5%A4%A7/</guid>
      <description>C 语言中各个数据类型的大小 类型 大小 范围 char 1 字节 -128 到 127 或 0 到 255 unsigned char 1 字节 0 到 255 signed char 1 字节 -128 到 127 int 2 或 4 字节 -32,768 到 32,767 或 -2,147,483,648 到 2,147,483,647 unsigned int 2 或 4 字节 0 到 65,535 或 0 到 4,294,967,295 short 2 字节 -32,768 到 32,767 unsigned short 2 字节 0 到 65,535 long 4 字节 -2,147,483,648 到 2,147,483,647 unsigned long 4 字节 0 到 4,294,967,295 结构体 (struct) 待分析，需要考虑字节对齐 联合 (union) 所有成员中最长的 枚举 (enum) 根据数据类型 单层结构体大小 如果结构体中的成员数据类型相同，这样的情况最简单，结构体大小=数据类型*数据个数。</description>
    </item>
    <item>
      <title>Qt 命令行带参数启动 Qt 程序</title>
      <link>http://localhost:8888/posts/qt%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B8%A6%E5%8F%82%E6%95%B0%E5%90%AF%E5%8A%A8qt%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Mon, 13 Sep 2021 12:03:44 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B8%A6%E5%8F%82%E6%95%B0%E5%90%AF%E5%8A%A8qt%E7%A8%8B%E5%BA%8F/</guid>
      <description>简介 我们经常用到命令行参数，比如最常见的 Linux 命令，显示所有文件ls -a,ls其实就是一个程序，-a就是该程序需要解析的一个参数。那么如何能让 Qt 程序也能解析命令行参数，从命令行启动呢？
Qt 从 5.2 版开始提供了两个类QCommandLineOption和QCommandLineParser来解析应用的命令行参数。
添加程序属性信息，帮助，版本 一个程序启动后，我们会在命令行看到程序的一些简要信息，以及可以使用-v命令显示其版本信息，这些通用的参数以及被 Qt 分装好，可以直接使用。
#include &amp;#34;mainwindow.h&amp;#34; #include &amp;lt;QApplication&amp;gt; #include &amp;lt;QCommandLineParser&amp;gt; int main(int argc, char *argv[]) { QApplication a(argc, argv); QCommandLineParser parser; // 定义解析实例 parser.setApplicationDescription(&amp;#34;TestCommandLine&amp;#34;); // 描述可执行程序的属性 parser.addHelpOption(); // 添加帮助命令 parser.addVersionOption(); // 添加版本选择命令 parser.process(a); // 把用户的命令行的放入解析实例 MainWindow w; w.show(); return a.exec(); } 运行结果：
➜ ./CommandLine -h Usage: ./CommandLine [options] TestCommandLine Options: -h, --help Displays help on commandline options. --help-all Displays help including Qt specific options.</description>
    </item>
    <item>
      <title>Git 不同人修改了不同的文件该如何处理</title>
      <link>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</link>
      <pubDate>Sun, 12 Sep 2021 23:19:28 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%B8%8D%E5%90%8C%E4%BA%BA%E4%BF%AE%E6%94%B9%E4%BA%86%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/</guid>
      <description>需求 同一个项目，不同的开发者修改了不同的文件，如何解决同步冲突。
模拟 用户一修改 第一个用户新建一个分支， 以上命令就是新建一个分支feature/add_git_commands 将其与远端分支origin/feature/add_git_commands相关联，并切换到该分支。
修改 readme 文件，并推送到远端。因为新建分支时已经做了与远端关联，所以可以直接git push。
用户二修改 第二个用户，首先拉取远端分支。
git branch -v查看本地分支，保持不变，但是git branch -av查看所有分支，可以发现多了两个远端分支。 新建本地分支，保持与远端分支名相同。
此时再对与 readme 不同的文件进行修改，提交，推送都会比较顺利。因为当前分支保持fast forward。
用户二继续做开发，但是没再往远端推送代码。在此期间，用户一对远端代码进行了更新。用户二想再次推送代码，将会报错，提示当前提交不再fast forward。
解决方法 git fetch远端分支 git merge合并远端分支 因为两个用户修改的不同文件，所以合并不会产生冲突。</description>
    </item>
    <item>
      <title>解决 TypeError [ERR_INVALID_ARG_TYPE]: The data argument must be of type string or an instance of Buffe</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3typeerror-err-invalid-arg-type-the-data-argument-must-be-of-type-string-or-an-instance-of-buffe/</link>
      <pubDate>Fri, 10 Sep 2021 15:59:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3typeerror-err-invalid-arg-type-the-data-argument-must-be-of-type-string-or-an-instance-of-buffe/</guid>
      <description>安装 GitBook 时出现这个错误，将node版本降级即可
MINGW64 ~/Desktop/dir1/dir11$ gitbook initwarn: no summary file in this bookinfo: create SUMMARY.mdTypeError [ERR_INVALID_ARG_TYPE]: The &amp;#34;data&amp;#34; argument must be of type stringor an instance of Buffer, TypedArray, or DataView. Received an instance ofPromise </description>
    </item>
    <item>
      <title>C 语言预处理</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E9%A2%84%E5%A4%84%E7%90%86/</link>
      <pubDate>Thu, 09 Sep 2021 14:10:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80%E9%A2%84%E5%A4%84%E7%90%86/</guid>
      <description>什么是预处理 C 语言通过预处理器提供了一些语言功能。从概念上讲，预处理器是编译过程中单独执行的第一个步骤。两个最常用的预处理器指令是：#include 指令 (用于在编译期间把指定文件的内容包含进当前文件中) 和 #define 指令 (用任意字符序列替代一个标记)。
为啥要进行预先处理呢？如果要深入的了解的话可以参考《程序员的自我修养：链接、装载与库》这本书。这里举一个非常常见的例子，假如我们编写跨平台的程序时，我们就需要考虑不同平台的系统库是不同的，如果只包含了一个平台下的库文件，换个平台编译就可能出错。这时候就需要在编译前进行预处理。
有重要的预处理器指令：
指令 描述 #define 定义宏 #include 包含一个源代码文件 #undef 取消已定义的宏 #ifdef 如果宏已经定义，则返回真 #ifndef 如果宏没有定义，则返回真 #if 如果给定条件为真，则编译下面代码 #else #if 的替代方案 #elif 如果前面的 #if 给定条件不为真，当前条件为真，则编译下面代码 #endif 结束一个 #if……#else 条件编译块 #error 当遇到标准错误时，输出错误消息 #pragma 使用标准化方法，向编译器发布特殊的命令到编译器中 条件编译 #if #if 整型常量表达式1 程序段1 #elif 整型常量表达式2 程序段2 #elif 整型常量表达式3 程序段3 #else 程序段4 #endif 它的意思是：如常“表达式 1”的值为真（非 0），就对“程序段 1”进行编译，否则就计算“表达式 2”，结果为真的话就对“程序段 2”进行编译，为假的话就继续往下匹配，直到遇到值为真的表达式，或者遇到 #else 。这一点和 if else 非常类似。
需要注意的是， #if 命令要求判断条件为整型常量表达式，也就是说，表达式中不能包含变量，而且结果必须是整数；而 if 后面的表达式没有限制，只要符合语法就行。这是 #if 和 if 的一个重要区别。</description>
    </item>
    <item>
      <title>解决 expected &#39;char * const*&#39; but argument is of type &#39;char **&#39;</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3expected-char-const-but-argument-is-of-type-char/</link>
      <pubDate>Wed, 08 Sep 2021 19:07:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3expected-char-const-but-argument-is-of-type-char/</guid>
      <description>在使用exec系列函数时，execle，execv，execvp三个函数，都可以使用char *arg[]传入启动参数。以下面的程序为例，
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; int main(void) { int ret; char *argv[] = {&amp;#34;ls&amp;#34;,&amp;#34;-l&amp;#34;,NULL}; ret = execvp(&amp;#34;ls&amp;#34;,argv); if(ret == -1) perror(&amp;#34;execl error&amp;#34;); return 0; } 编译时就会出现一下，警告，
expected &amp;#39;char * const*&amp;#39; but argument is of type &amp;#39;const char **&amp;#39; 因为项目中不允许警告产生，所以编译选项是-Werror，所有警告都会被升级成错误。编译时就会产生如下提示，
ccl : all warnings being treated as errors 如果是平时练习，改一下编译选项，把这个警告忽略就行，但是现在只能解决。
出现这个问题就是因为定义数组时char *argv[]类型是char **。但是execvp()函数签名是execvp(const char *file, char *const argv[]);第二个参数的类型是char * const *。
本以为直接将变量定义更改成char * const argv[]就行了，但是它等价于const char **，所以仍然不能和函数签名匹配。
实在没办法只能改成如下：
#include &amp;lt;stdio.</description>
    </item>
    <item>
      <title>VSCode 中调试带 Makefile 文件的项目</title>
      <link>http://localhost:8888/posts/vscode%E4%B8%AD%E8%B0%83%E8%AF%95%E5%B8%A6makefile%E6%96%87%E4%BB%B6%E7%9A%84%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Mon, 06 Sep 2021 15:41:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E4%B8%AD%E8%B0%83%E8%AF%95%E5%B8%A6makefile%E6%96%87%E4%BB%B6%E7%9A%84%E9%A1%B9%E7%9B%AE/</guid>
      <description>在调试 QEMU 时，自己需要修改源文件，但是每次修改都需要在命令行重新make编译一遍，比较麻烦，想到之前刚刚配置过tasks.json文件，可以把命令行任务配置到文件里，make命令不也一样可以加入吗？修改tasks.json文件如下：
{ &amp;#34;version&amp;#34;: &amp;#34;2.0.0&amp;#34;, &amp;#34;tasks&amp;#34;: [ { //任务的名字方便执行 &amp;#34;label&amp;#34;: &amp;#34;make qemu&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;command&amp;#34;: &amp;#34;make&amp;#34;, &amp;#34;args&amp;#34;:[ //8 线程编译 &amp;#34;-j8&amp;#34;, ], &amp;#34;options&amp;#34;: { //切换到 build 文件夹下 &amp;#34;cwd&amp;#34;: &amp;#34;${workspaceFolder}/build&amp;#34; }, }, { // 启动 qemu 供调试器连接 &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;Run Qemu Server(RISCV)&amp;#34;, //在执行这个任务前，先执行 make qemu 任务、 //这样就可以在执行调试时，自动先编译一遍 &amp;#34;dependsOn&amp;#34;: &amp;#34;make qemu&amp;#34;, &amp;#34;command&amp;#34;: &amp;#34;qemu-system-riscv64&amp;#34;, &amp;#34;args&amp;#34;: [ &amp;#34;-g&amp;#34;, &amp;#34;${workspaceFolder}/debug/${fileBasenameNoExtension}&amp;#34; ], }, ] } </description>
    </item>
    <item>
      <title>解决 gcc-multilib : 依赖：gcc-4.8-multilib (&gt;= 4.8.2-5~) 但是它将不会被安装</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc-multilib-%E4%BE%9D%E8%B5%96-gcc-4-8-multilib-4-8-2-5-%E4%BD%86%E6%98%AF%E5%AE%83%E5%B0%86%E4%B8%8D%E4%BC%9A%E8%A2%AB%E5%AE%89%E8%A3%85/</link>
      <pubDate>Fri, 03 Sep 2021 10:44:44 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc-multilib-%E4%BE%9D%E8%B5%96-gcc-4-8-multilib-4-8-2-5-%E4%BD%86%E6%98%AF%E5%AE%83%E5%B0%86%E4%B8%8D%E4%BC%9A%E8%A2%AB%E5%AE%89%E8%A3%85/</guid>
      <description>问题 这是一类问题，不仅限于安装 gcc，这类问题的根本原因在于，Ubuntu 已安装的软件包版本高，而所安装软件的依赖包版本低，这样在安装高版软件时，已有的软件包依赖你要安装的软件包，你把软件包升级了，可能就会破坏这个依赖关系，所以apt-get不让你安装。
这时就要请到大杀器-aptitude，它与 apt-get一样，是 Debian 及其衍生系统中功能极其强大的包管理工具。与 apt-get 不同的是，aptitude在处理依赖问题上更佳一些。举例来说，aptitude在删除一个包时，会同时删除本身所依赖的包。这样，系统中不会残留无用的包，整个系统更为干净。
方法 $sudo apt-get install aptitude //安装aptitude包管理器$sudo aptitude install gcc-multilib //用新的包管理器安装你要安装的软件 安装gcc-multilib时会把所有依赖包一并安装，此时会让你同意，选择n就行。
接下来就会解决已经安装的包之间的依赖关系，他会降级或升级一些软件包来匹配当前安装的软件版本，此时选择y。
完成以上操作，再次正常安装需要的软件包即可成功安装。
如果无法正常安装，重复以上操作，每次都选择n。</description>
    </item>
    <item>
      <title>解决 fatal error: bits/libc-header-start.h：no such file</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3fatal-error-bits-libc-header-start-hno-such-file/</link>
      <pubDate>Fri, 03 Sep 2021 09:26:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3fatal-error-bits-libc-header-start-hno-such-file/</guid>
      <description>保留现场 想要分别编译 32 位和 64 位的程序时，gcc 出现了错误，
In file included from func_call.c:1:/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: 没有那个文件或目录27 | #include &amp;lt;bits/libc-header-start.h&amp;gt;| ^~~~~~~~~~~~~~~~~~~~~~~~~~compilation terminated. 问题解决 问题原因猜测是默认 gcc 只提供当前机器的版本，解决如下
apt install gcc-multilib </description>
    </item>
    <item>
      <title>QEMU 源码分析-虚拟 CPU 创建</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9Fcpu%E5%88%9B%E5%BB%BA/</link>
      <pubDate>Wed, 01 Sep 2021 18:22:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9Fcpu%E5%88%9B%E5%BB%BA/</guid>
      <description>流程图 先开个头吧，把创建流程稍微捋一下，找到创建虚拟 CPU 的模块。至于中间的流程还没有详细分析，万事开头难，先上手再说吧。
qemu_add_opts解析 qemu 的命令行 qemu_init函数中下面这一长串内容，就是在解析命令行的参数。
qemu add opts (&amp;amp;qemu drive opts); qemu add drive opts(&amp;amp;qemu Legacy drive opts); qemu add drive opts (&amp;amp;qemu common drive opts); qemu add drive opts (&amp;amp;qemu drive opts); qemu add drive opts (sbdry runtime opts); qemu add opts (qemu chardev opts); qemu add opts (&amp;amp;qemu device opts); qemu add opts (&amp;amp;qemu netdev opts); qemu add opts (&amp;amp;qemu nic opts); qemu add opts (sqemu net opts qemu add opts (&amp;amp;qemu rtc opts) qemu add opts (&amp;amp;qemu global_opts); qemu add opts (&amp;amp;qemu mon opts); qemu add opts (sqemu trace opts); .</description>
    </item>
    <item>
      <title>Qt 文件系统</title>
      <link>http://localhost:8888/posts/qt%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Tue, 31 Aug 2021 20:00:06 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid>
      <description>Qt 通过QIODevice提供了对 I/O 设备的抽象，这些设备具有读写字节块的能力。下面是 I/O 设备的类图：
图中所涉及的类及其用途简要说明如下：
QIODevice：所有I/O设备类的父类，提供了字节块读写的通用操作以及基本接口； QFlie：访问本地文件或者嵌入资源； QTemporaryFile：创建和访问本地文件系统的临时文件； QBuffer：读写QByteArray； QProcess：运行外部程序，处理进程间通讯； QAbstractSocket：所有套接字类的父类； QTcpSocket：TCP协议网络数据传输； QUdpSocket：传输 UDP 报文； QSslSocket：使用 SSL/TLS 传输数据； QFileDevice：Qt5 新增加的类，提供了有关文件操作的通用实现。
QFile 及其相关类 我们通常会将文件路径作为参数传给QFile的构造函数。不过也可以在创建好对象最后，使用setFileName()来修改。QFile需要使用/作为文件分隔符，不过，它会自动将其转换成操作系统所需要的形式。例如C:/windows这样的路径在 Windows 平台下同样是可以的。
QFile主要提供了有关文件的各种操作，比如打开文件、关闭文件、刷新文件等。我们可以使用QDataStream或QTextStream类来读写文件，也可以使用QIODevice类提供的read()、readLine()、readAll()以及write()这样的函数。值得注意的是，有关文件本身的信息，比如文件名、文件所在目录的名字等，则是通过QFileInfo获取，而不是自己分析文件路径字符串。
在这段代码中，我们首先使用QFile创建了一个文件对象。这个文件名字是 test.txt。只要将这个文件放在同执行路径一致的目录下即可。可以使用QDir::currentPath()来获得应用程序执行时的当前路径。只要将这个文件放在与当前路径一致的目录下即可。然后，我们使用open()函数打开这个文件，打开形式是只读方式，文本格式。这个类似于fopen()的 r 这样的参数。open()函数返回一个 bool 类型，如果打开失败，我们在控制台输出一段提示然后程序退出。否则，我们利用 while 循环，将每一行读到的内容输出。
#include &amp;lt;QWidget&amp;gt; #include &amp;lt;QApplication&amp;gt; #include &amp;lt;QDebug&amp;gt; #include &amp;lt;QFile&amp;gt; #include &amp;lt;QFileInfo&amp;gt; #include &amp;lt;QMainWindow&amp;gt; int main(int argc, char *argv[]) { QApplication app(argc, argv); QFile file(&amp;#34;test.txt&amp;#34;); if (!file.open(QIODevice::ReadOnly | QIODevice::Text)) { qDebug() &amp;lt;&amp;lt; &amp;#34;Open file failed.&amp;#34;; return -1; } else { while (!</description>
    </item>
    <item>
      <title>Linux 操作系统-虚拟化</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%99%9A%E6%8B%9F%E5%8C%96/</link>
      <pubDate>Tue, 31 Aug 2021 09:44:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%99%9A%E6%8B%9F%E5%8C%96/</guid>
      <description>虚拟化 虚拟机 QEMU 工作原理 单纯使用 qemu，采用的是完全虚拟化的模式。qemu 向 Guest OS 模拟 CPU，也模拟其他的硬件，GuestOS 认为自己和硬件直接打交道，其实是同 qemu 模拟出来的硬件打交道，qemu 会将这些指令转译给真正的硬件。由于所有的指令都要从 qemu 里面过一手，因而性能就会比较差。
完全虚拟化是非常慢的，所以要使用硬件辅助虚拟化技术 Intel-VT，AMD-V，所以需要 CPU 硬件开启这个标志位，一般在 BIOS 里面设置。当确认开始了标志位之后，通过 KVM，GuestOS 的 CPU 指令不用经过 Qemu 转译，直接运行，大大提高了速度。所以，KVM 在内核里面需要有一个模块，来设置当前 CPU 是 Guest OS 在用，还是 Host OS 在用。
可以通过如下命令查看内核模块中是否有 KVM
lsmod | grep kvm KVM 内核模块通过 /dev/kvm 暴露接口，用户态程序可以通过 ioctl来访问这个接口。Qemu 将 KVM 整合进来，将有关 CPU 指令的部分交由内核模块来做，就是 qemu-kvm (qemu-system-XXX)。
qemu 和 kvm 整合之后，CPU 的性能问题解决了。另外 Qemu 还会模拟其他的硬件，如网络和硬盘。同样，全虚拟化的方式也会影响这些设备的性能。
于是，qemu 采取半虚拟化的方式，让 Guest OS 加载特殊的驱动来做这件事情。
例如，网络需要加载 virtio_net，存储需要加载 virtio_blk，Guest 需要安装这些半虚拟化驱动，GuestOS 知道自己是虚拟机，所以数据会直接发送给半虚拟化设备，经过特殊处理（例如排队、缓存、批量处理等性能优化方式），最终发送给真正的硬件。这在一定程度上提高了性能。</description>
    </item>
    <item>
      <title>Linux 操作系统-进程管理</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 30 Aug 2021 09:41:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>进程 源码 //process.c #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; extern int create_process (char* program, char** arg_list); int create_process (char* program, char** arg_list) { pid_t child_pid; child_pid = fork (); if (child_pid != 0) { return child_pid; } else { execvp (program, arg_list); abort (); } } 在这里，我们创建的子程序运行了一个最最简单的命令 ls。
//createprocess.c #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; extern int create_process (char* program, char** arg_list); int main () { char* arg_list[] = { &amp;#34;ls&amp;#34;, &amp;#34;-l&amp;#34;, &amp;#34;/etc/yum.</description>
    </item>
    <item>
      <title>CSAPPLAB-Bomb Lab</title>
      <link>http://localhost:8888/posts/csapp-lab-bomb-lab/</link>
      <pubDate>Sun, 29 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/csapp-lab-bomb-lab/</guid>
      <description>Tips 缩写注释 CSAPP：Computer Systems A Programmer’s Perspective（深入理解计算机操作系统）。CSAPP（C：P166，O：P278）表示书本的中文版第 166 页，英文原版第 278 页。
寄存器信息 了解寄存器的基本用途，看到一个汇编代码，可以大概了解这个寄存器是在栈中使用的，还是保存参数的，是调用者保存，还是被调用者保存。 GDB 调试过程用到的 GDB 命令可以先参考GDB 调试入门这篇文章。文中所用例子也是摘自与 BombLab 的源码，更容易理解如何使用。还有一定比较重要的是，如何使用 gdb 带参数调试。为了不用每次运行bomb程序都需要重新输入答案，bomb程序可以读取文本信息，在文本文件中写入答案即可免去手动输入。
phase_1 拆弹专家已上线，开干！！！！！！！！！！！！！
(gdb) b phase_1(gdb) b explode_bomb(gdb) disas phase_1Dump of assembler code for function phase_1:&amp;#39;0x0000000000400ee0 &amp;lt;+0&amp;gt;: sub $0x8,%rsp0x0000000000400ee4 &amp;lt;+4&amp;gt;: mov $0x402400,%esi0x0000000000400ee9 &amp;lt;+9&amp;gt;: callq 0x401338 &amp;lt;strings_not_equal&amp;gt;0x0000000000400eee &amp;lt;+14&amp;gt;: test %eax,%eax0x0000000000400ef0 &amp;lt;+16&amp;gt;: je 0x400ef7 &amp;lt;phase_1+23&amp;gt;0x0000000000400ef2 &amp;lt;+18&amp;gt;: callq 0x40143a &amp;lt;explode_bomb&amp;gt;0x0000000000400ef7 &amp;lt;+23&amp;gt;: add $0x8,%rsp0x0000000000400efb &amp;lt;+27&amp;gt;: retq End of assembler dump.</description>
    </item>
    <item>
      <title>GDB 调试入门</title>
      <link>http://localhost:8888/posts/gdb%E8%B0%83%E8%AF%95%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 29 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/gdb%E8%B0%83%E8%AF%95%E5%85%A5%E9%97%A8/</guid>
      <description>file 加载程序 (gdb) file bomb Reading symbols from bomb... set args 带参数调试 有时候程序不是直接可以运行的，需要加上一些必要的参数。带上参数运行很容易，只要在程序名后加上相应参数即可，但是如何带上参数进行调试呢？这就需要set args命令。
比如在BombLab实验中，我们不可能一次解决所有phase，但是每次重新调试，已经解决的phase还要重新输入一次答案，这就很麻烦，好在这个实验的作者也考虑到了，他支持读取文本。我们可以把答案预先写入一个文本文件中，程序读取已经保存的答案即可跳过相应的phase。
假设我们把答案写入了solutions.txt文件中，首先，我们加载程序，然后通过set args solutions.txt设置运行参数。
(gdb) file bomb Reading symbols from bomb... (gdb) set args solutions.txt (gdb) r Starting program: /home/dominic/learning-linux/bomb/bomb solutions.txt Welcome to my fiendish little bomb. You have 6 phases with which to blow yourself up. Have a nice day! Phase 1 defused. How about the next one? That&amp;#39;s number 2. Keep going! list 查看源码 查看 10 行源码 每条命令显示 10 行代码</description>
    </item>
    <item>
      <title>oh-my-zsh 让你的终端更加顺手（眼）</title>
      <link>http://localhost:8888/posts/oh-my-zsh%E8%AE%A9%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E6%9B%B4%E5%8A%A0%E9%A1%BA%E6%89%8B%E7%9C%BC/</link>
      <pubDate>Sun, 29 Aug 2021 09:56:21 +0000</pubDate>
      <guid>http://localhost:8888/posts/oh-my-zsh%E8%AE%A9%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E6%9B%B4%E5%8A%A0%E9%A1%BA%E6%89%8B%E7%9C%BC/</guid>
      <description>效果 主题：evan
主题：dallas
主题：robbyrussell
如果原先其他电脑安装过 把.oh-my-zsh整个文件夹，.zshrc，.zsh_history复制到/home/user/目录；
安装zsh
sudo apt install zsh 切换shell
chsh -s /bin/zsh source ~/.zshrc 即可使用。所有配置都会和原先一样。
如果是新安装 官方方法，curl和wget二选一即可
curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh 应该也有人和我一样，可能会遇到连接 GitHub 失败的问题，要不就是 SSL 验证失败，要不就是连接无响应。可以更换下面的方法。
# 先下载 git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh ## 再替换 cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 重启终端即可成功。
如果无法访问 GitHub，其实oh-my-zsh并不需要安装，完整的工程就是oh-my-zsh本体，只要想办法把整个工程下载下来，并重命名为oh-my-zsh即可。所以找找 gitee 有没有相关工程。这也是为什么从旧电脑里直接复制.oh-my-zsh就能用的原因。
问题 oh-my-zsh.sh parse error near `&amp;laquo;&amp;lt;&#39; 一般是在更新oh-my-zsh时出现，因为更新相当于就是从远程拉取了内容，可能本地的oh-my-zsh.sh脚本自己做了修改与远程冲突了。只要退回上个版本，重新拉取就可以了。
cd $ZSH git reset --hard HEAD^ git pull --rebase 如果本地修改了一些内容需要保留，可以打开oh-my-zsh.sh看看冲突在哪，自己做个备份，保存一下。</description>
    </item>
    <item>
      <title>Qt 绘制系统</title>
      <link>http://localhost:8888/posts/qt%E7%BB%98%E5%88%B6%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Fri, 27 Aug 2021 14:39:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E7%BB%98%E5%88%B6%E7%B3%BB%E7%BB%9F/</guid>
      <description>本篇文章所涉及代码可在此处查看。
绘制系统简介 Qt 的绘图系统允许使用相同的 API 在屏幕和其它打印设备上进行绘制。整个绘图系统基于QPainter,QPainterDevice和QPaintEngine三个类。
QPainter用来执行绘制的操作；QPaintDevice是一个二维空间的抽象，这个二维空间允许QPainter在其上面进行绘制，也就是QPainter工作的空间；QPaintEngine提供了画笔（QPainter）在不同的设备上进行绘制的统一的接口。QPaintEngine类应用于QPainter和QPaintDevice之间，通常对开发人员是透明的。
三个类的关系：QPainter-&amp;gt;QPaintEngine-&amp;gt;QPaintDevice。通过这个关系我们也可以知道，QPainter通过QPaintEngine翻译指令在QPaintDevice上绘制。
通过一个实例来了解一下绘制系统的，
//main.h #include &amp;lt;QPainter&amp;gt; #include &amp;lt;QWidget&amp;gt; #include &amp;lt;QPaintEvent&amp;gt; #include &amp;lt;QApplication&amp;gt; #include &amp;lt;QMainWindow&amp;gt; class PaintedWidget : public QWidget { Q_OBJECT public: PaintedWidget(QWidget *parent = 0); protected: void paintEvent(QPaintEvent *); }; //main.cpp #include &amp;#34;paintwidget.h&amp;#34; PaintedWidget::PaintedWidget(QWidget *parent) : QWidget(parent) { resize(800, 600); setWindowTitle(tr(&amp;#34;Paint Demo&amp;#34;)); } void PaintedWidget::paintEvent(QPaintEvent *) { QPainter painter(this); painter.drawLine(20, 20, 700, 20); painter.setPen(Qt::red); painter.drawRect(10, 10, 100, 400); painter.setPen(QPen(Qt::green, 5)); painter.setBrush(Qt::blue); painter.drawEllipse(0, 0, 300, 40); // painter.</description>
    </item>
    <item>
      <title>RISC-V 入门 - 计算机基础</title>
      <link>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Thu, 26 Aug 2021 13:42:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/risc-v%E5%85%A5%E9%97%A8-%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</guid>
      <description>计算机基础 计算机硬件基础 两大硬件架构
冯诺依曼架构
一根总线，开销小，控制逻辑实现简单
执行效率低
哈佛架构
与上一架构相反 程序的存储与执行 .c文件经过编译链接，生成.out文件。加载到内存中，到控制单元运行。进行取值，译码，执行。
晶振发出脉冲。 语言的设计与进化 上图是冯诺依曼架构，特点就是指令与数据放在一起。黄色部分表示指令，绿色部分表示数据。我们来看看指令是如何执行的。 ProgramCounter指到右图内存的第一条指令，程序开始执行。将第一条 指令读入指令寄存器。然后将指令解码，根据之前的规定，我们可以知道这条指令是将0100(二进制即 5)位置的数据，00(load)到00(Register 0)中。下面的指令一次类推，每次取指，Program Counter移动一次。 </description>
    </item>
    <item>
      <title>VSCode 单步调试 QEMU</title>
      <link>http://localhost:8888/posts/vscode%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95qemu/</link>
      <pubDate>Tue, 24 Aug 2021 19:24:08 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95qemu/</guid>
      <description>了解了如何在VSCode 中调试程序，接下来我们在 VSCode 中搭建调试 QEMU 的环境。
配置 首先我们需要下载和编译 QEMU 源码
./configure --enable-debug --target-list=riscv32-softmmu,riscv32-linux-user --enable-kvm 一定要加上--enable-debug，编译出的程序才带有调试信息，不用设置安装路径，编译时会自动在 qemu 文件夹下自动创建一个build文件夹，编译后的程序也在build文件夹下。
用 VSCode 打开qemu-6.X.X文件夹，Ctrl+Shift+D打开调试配置。如果参考过VSCode 中调试程序这篇文章，接下来就很容易。我们只需要将launch.jason文件中的program属性改为${workspaceFolder}/build/qemu-system-riscv32即可。
调试 打开qemu-6.X.X/softmmu/main.c文件，在main函数入口处打上断点，即可开始调试。
现在只需要点击屏幕上的图标，就可以快速的进行单步调试。
如果需要进行命令行操作，在屏幕下方打开DEBUG CONSOLE，输入-exec+正常命令行下的命令即可在命令行中进行更多的调试。如查看断点信息-exec info breakpoints</description>
    </item>
    <item>
      <title>Qt 模仿登录界面-页面反转效果</title>
      <link>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E9%A1%B5%E9%9D%A2%E5%8F%8D%E8%BD%AC%E6%95%88%E6%9E%9C/</link>
      <pubDate>Tue, 24 Aug 2021 13:55:37 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E9%A1%B5%E9%9D%A2%E5%8F%8D%E8%BD%AC%E6%95%88%E6%9E%9C/</guid>
      <description>设置一个旋转效果，将登录界面旋转翻个面，设置一些网络参数。
效果 网络参数设置界面布局 网络参数设置界面 //loginnetsetwindow.cpp //初始化标题 void LoginNetSetWindow::initMyTitle() { m_titleBar-&amp;gt;move(0, 0); m_titleBar-&amp;gt;raise(); m_titleBar-&amp;gt;setBackgroundColor(0, 0, 0, true); m_titleBar-&amp;gt;setButtonType(MIN_BUTTON); m_titleBar-&amp;gt;setTitleWidth(this-&amp;gt;width()); m_titleBar-&amp;gt;setMoveParentWindowFlag(false); } void LoginNetSetWindow::initWindow() { QLabel* pBack = new QLabel(this); QMovie *movie = new QMovie(); movie-&amp;gt;setFileName(&amp;#34;:/Resources/NetSetWindow/headBack.gif&amp;#34;); pBack-&amp;gt;setMovie(movie); movie-&amp;gt;start(); pBack-&amp;gt;move(0, 0); connect(ui.pButtonOk, SIGNAL(clicked()), this, SIGNAL(rotateWindow())); connect(ui.pButtonCancel, SIGNAL(clicked()), this, SIGNAL(rotateWindow())); ui.comboBoxNetType-&amp;gt;addItem(QStringLiteral(&amp;#34;不使用代理&amp;#34;)); ui.comboBoxServerType-&amp;gt;addItem(QStringLiteral(&amp;#34;不使用高级选项&amp;#34;)); } void LoginNetSetWindow::paintEvent(QPaintEvent *event) { // 绘制背景图; QPainter painter(this); QPainterPath pathBack; pathBack.setFillRule(Qt::WindingFill); pathBack.addRoundedRect(QRect(0, 0, this-&amp;gt;width(), this-&amp;gt;height()), 3, 3); painter.setRenderHint(QPainter::Antialiasing, true); painter.fillPath(pathBack, QBrush(QColor(235, 242, 249))); QPainterPath pathBottom; pathBottom.</description>
    </item>
    <item>
      <title>Linux 操作系统-系统初始化</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
      <pubDate>Tue, 24 Aug 2021 09:45:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
      <description>系统初始化 x86 架构概述 CPU（Central Processing Unit）：中央处理器，计算机所有设备都围绕它展开工作。
运算单元：只管算，例如做加法、做位移等等。但是，它不知道应该算哪些数据，运算结果应该放在哪里。 数据单元：运算单元计算的数据如果每次都要经过总线，到内存里面现拿，这样就太慢了，所以就有了数据单元。数据单元包括 CPU 内部的缓存和寄存器组，空间很小，但是速度飞快，可以暂时存放数据和运算结果。 控制单元：有了放数据的地方，也有了算的地方，还需要有个指挥到底做什么运算的地方，这就是控制单元。控制单元是一个统一的指挥中心，它可以获得下一条指令，然后执行这条指令。这个指令会指导运算单元取出数据单元中的某几个数据，计算出个结果，然后放在数据单元的某个地方。 内存（Memory）：CPU 本身不能保存大量数据，许多复杂的计算需要将中间结果保存下来就必须用到内存。
总线（Bus）：CPU 和其他设备连接，就靠总线，其实就是主板上密密麻麻的集成电路，这些东西组成了 CPU 和其他设备的高速通道。
地址总线：传输地址数据（我想拿内存中哪个位置的数据） 数据总线：传输真正的数据 总线就像 CPU 和内存之间的高速公路，总线多少位就类似高速公路多少个车道，但两种总线的位数意义不同。
地址总线的位数决定了访问地址范围有多广，数据总线位数决定了一次能拿多少数据进来。那么 CPU 中总线的位数有没有标准呢？如果没有标准，那操作系统作为软件就很难办了，因为软件层没办法实现通用的运算逻辑。早期每家公司的 CPU 架构都不同，后来历史将 x86 平台推到了开放，统一，兼容的位置。
8086 架构图 数据单元： 8086 处理器内部共有 8 个 16 位的通用寄存器，分别是 数据寄存器（AX、BX、CX、DX）、指针寄存器（SP、BP）、变址寄存器（SI、DI）。其中 AX、BX、CX、DX 可以分成两个 8 位的寄存器来使用，分别是 AH、AL、BH、BL、CH、CL、DH、DL，其中 H 就是 High（高位），L 就是 Low（低位）的意思。
控制单元： IP 寄存器（Instruction Pointer Register）就是指令指针寄存器，它指向代码段中下一条指令的位置。CPU 会根据它来不断地将指令从内存的代码段中，加载到 CPU 的指令队列中，然后交给运算单元去执行。
如果需要切换进程呢？每个进程都分代码段和数据段，为了指向不同进程的地址空间，有四个 16 位的段寄存器，分别是 CS、DS、SS、ES。
其中，CS 就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置；DS 是数据段的寄存器（Data Segment Register），通过它可以找到数据在内存中的位置。SS 是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取只能从一端进行，秉承后进先出的原则。ES是扩展段寄存器（Extra Segment Register）顾名思义。</description>
    </item>
    <item>
      <title>VSCode 调试 RISC-V 程序</title>
      <link>http://localhost:8888/posts/vscode%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Mon, 23 Aug 2021 15:51:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F/</guid>
      <description>前提 本文主要涉及 VSCode 的相关配置，编译及调试工具需要提前安装好。
已经安装好riscv-toolchain，包括riscv64-unknown-elf-gcc，riscv64-unknown-elf-gdb 已经安装好qemu，包括riscv32-softmmu,riscv32-linux-user,riscv64-softmmu,riscv64-linux-user 已经安装好g++,gdb 调试流程简介 对于我这样的新手，要调试一个项目源码最怕的就是开始，也就是怎么能把项目跑起来。
我们以一个简单的test项目，看看在 VSCode 里怎么跑起来。
拿到源码后，将其以文件夹形式，加入到 VSCode 中，文件 - 打开文件夹 - 选择 test 项目文件夹。项目就会在 VSCode 中打开，但是此时我们还无法编译运行，我们需要在 VSCode 上 构建出一个 C 语言的编译与调试环境。
首先得安装一个插件C/C++，打开插件中心Ctrl+Shit+X，搜索，安装。
然后输入F5，会弹出对话框，选择C++(GDB)，继续选择g++。VSCode 会自动创建.vscode文件夹，已经两个文件launch.json和tasks.json。 launch.json用来配置调试环境，tasks.json主要用来配置编译环境，当然也可以配置其他任务。task.json里配置的每个任务其实就相当于多开一个控制台。
配置tasks.json 因为我们先要编译源码，生成.out或者.exe文件，才能调试，所以先进行编译任务配置。
自动生成的文件是个配置模板，我们可以根据自己的实际情况进行配置，也有一部分可以保持默认。
// tasks.json{// https://code.visualstudio.com/docs/editor/tasks&amp;#34;version&amp;#34;: &amp;#34;2.0.0&amp;#34;,&amp;#34;tasks&amp;#34;: [{// 任务的名字，注意是大小写区分的//会在launch中调用这个名字&amp;#34;label&amp;#34;: &amp;#34;C/C++: g++ build active file&amp;#34;, // 任务执行的是shell&amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, // 命令是g++&amp;#34;command&amp;#34;: &amp;#34;g++&amp;#34;, //g++ 后面带的参数&amp;#34;args&amp;#34;: [&amp;#34;&amp;#39;-Wall&amp;#39;&amp;#34;,&amp;#34;-g&amp;#34;, // 生成调试信息，否则无法进入断点&amp;#34;&amp;#39;-std=c++17&amp;#39;&amp;#34;, //使用c++17标准编译&amp;#34;&amp;#39;${file}&amp;#39;&amp;#34;, //当前文件名&amp;#34;-o&amp;#34;, //对象名，不进行编译优化&amp;#34;&amp;#39;${fileBasenameNoExtension}.</description>
    </item>
    <item>
      <title>进程间通信（IPC）之信号量（Semaphore）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8Fsemaphore/</link>
      <pubDate>Thu, 19 Aug 2021 15:36:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8Fsemaphore/</guid>
      <description>简介 为了防止出现因多个程序同时访问一个共享资源而引发的一系列问题，我们需要一种方法，它可以通过生成并使用令牌来授权，在任一时刻只能有一个执行线程访问代码的临界区域。临界区域是指执行数据更新的代码需要独占式地执行。而信号量就可以提供这样的一种访问机制，让一个临界区同一时间只有一个线程在访问它，也就是说信号量是用来调协进程对共享资源的访问的。
信号量是一个特殊的变量，程序对其访问都是原子操作，且只允许对它进行等待（即P) 和发送（即V) 信息操作。最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二进制信号量。而可以取多个正整数的信号量被称为通用信号量。这里主要讨论二进制信号量。
由于信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv),他们的行为是这样的：
P(sv)：如果sv的值大于零，就给它减 1；如果它的值为零，就挂起该进程的执行
V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加 1.
举个例子，就是两个进程共享信号量sv，一旦其中一个进程执行了P(sv)操作，它将得到信号量，并可以进入临界区，使sv减 1。而第二个进程将被阻止进入临界区，因为当它试图执行P(sv)时，sv为 0，它会被挂起以等待第一个进程离开临界区域并执行V(sv)释放信号量，这时第二个进程就可以恢复执行。
本文代码同步在这里。
相关函数 Linux 提供了一组精心设计的信号量接口来对信号进行操作，它们不只是针对二进制信号量，下面将会对这些函数进行介绍，但请注意，这些函数都是用来对成组的信号量值进行操作的。它们声明在头文件 sys/sem.h 中。
semget() 它的作用是创建一个新信号量或取得一个已有信号量，原型为：
int semget(key_t key, int num_sems, int sem_flags); key是整数值（唯一非零），不相关的进程可以通过它访问一个信号量，它代表程序可能要使用的某个资源，程序对所有信号量的访问都是间接的，程序先通过调用semget()函数并提供一个键，再由系统生成一个相应的信号标识符（semget()函数的返回值），只有semget()函数才直接使用信号量键，所有其他的信号量函数使用由semget()函数返回的信号量标识符。如果多个程序使用相同的key值，key将负责协调工作。
num_sems指定需要的信号量数目，它的值几乎总是 1。
sem_flags是一组标志，当想要当信号量不存在时创建一个新的信号量，可以和值IPC_CREAT做按位或操作。设置了IPC_CREAT标志后，即使给出的键是一个已有信号量的键，也不会产生错误。而IPC_CREAT | IPC_EXCL则可以创建一个新的，唯一的信号量，如果信号量已存在，返回一个错误。
semget()函数成功返回一个相应信号标识符（非零），失败返回-1.
semop() 它的作用是改变信号量的值，原型为：
int semop(int sem_id, struct sembuf *sem_opa, size_t num_sem_ops); sem_id是由semget()返回的信号量标识符，sembuf结构的定义如下：
struct sembuf{ short sem_num; // 除非使用一组信号量，否则它为0 short sem_op; // 信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即 P（等待）操作， // 一个是+1，即V（发送信号）操作。 short sem_flg; // 通常为 SEM_UNDO，使操作系统跟踪信号， // 并在进程没有释放该信号量而终止时，操作系统释放信号量 }; num_sem_ops：操作sops中的操作个数，通常取值为 1</description>
    </item>
    <item>
      <title>进程间通信（IPC）之消息队列（MessageQueue）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97messagequeue/</link>
      <pubDate>Thu, 19 Aug 2021 10:53:09 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97messagequeue/</guid>
      <description>简介 消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。
每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。我们可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。
本文代码同步在这里。
相关函数 msgget() 该函数用来创建和访问一个消息队列。它的原型为：
int msgget(key_t, key, int msgflg); key：与其他的 IPC 机制一样，程序必须提供一个键来命名某个特定的消息队列。 msgflg是一个权限标志，表示消息队列的访问权限，它与文件的访问权限一样。msgflg可以与IPC_CREAT做或操作，表示当 key 所命名的消息队列不存在时创建一个消息队列，如果 key 所命名的消息队列存在时，IPC_CREAT标志会被忽略，而只返回一个标识符。 它返回一个以key命名的消息队列的标识符（非零整数），失败时返回-1.
msgsnd() 该函数用来把消息添加到消息队列中。它的原型为：
int msgsend(int msgid, const void *msg_ptr, size_t msg_sz, int msgflg); msgid是由msgget函数返回的消息队列标识符。
msg_ptr是一个指向准备发送消息的指针，但是消息的数据结构却有一定的要求，指针msg_ptr所指向的消息结构一定要是以一个长整型成员变量开始的结构体，接收函数将用这个成员来确定消息的类型。所以消息结构要定义成这样：
struct my_message { long int message_type; /* The data you wish to transfer */ }; msg_sz 是msg_ptr指向的消息的长度
msgflg 用于控制当前消息队列满或队列消息到达系统范围的限制时将要发生的事情
如果调用成功，消息数据的副本将被放到消息队列中，并返回0，失败时返回-1.
msgrcv() 该函数用来从一个消息队列获取消息，它的原型为
int msgrcv(int msgid, void *msg_ptr, size_t msg_st, long int msgtype, int msgflg); 前三个参数参照前面的解释 msgtype 可以实现一种简单的接收优先级。如果msgtype为0，就获取队列中的第一个消息。如果它的值大于零，将获取具有相同消息类型的第一个信息。如果它小于零，就获取类型等于或小于msgtype的绝对值的第一个消息。 msgflg 用于控制当队列中没有相应类型的消息可以接收时将发生的事情。 调用成功时，该函数返回放到接收缓存区中的字节数，消息被复制到由msg_ptr指向的用户分配的缓存区中，然后删除消息队列中的对应消息。失败时返回-1。 msgctl() 该函数用来控制消息队列，它与共享内存的shmctl函数相似，它的原型为：</description>
    </item>
    <item>
      <title>Linux(Ubuntu) 环境下安装 VSCode</title>
      <link>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85vscode/</link>
      <pubDate>Thu, 19 Aug 2021 09:38:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85vscode/</guid>
      <description>本来不想写这一篇的，安装 VSCode 时随便搜一下就 OK 了，但是因为 APT 源中没有 VSCode，所以需要找下载网址，几次的安装经历下来，找下载网址也经历了一番折腾。今天又要安装一遍，就顺手记录一下吧。以后翻自己记录总比翻全网记录方便。
官方文档 其实最完备安装教程在官方文档里。本文也算是对官方文档的一个翻译版吧。
基于 Debian 和 Ubuntu 的发行版 如果下载了.deb 安装包，那么只需要一个命令就可以完成安装了。
sudo apt install ./&amp;lt;file&amp;gt;.deb 无奈的是，我需要在开发机安装，无法下载安装包，但是我又不想用ftp传来传去，要是apt能完成，绝不单独下载安装包。
可以使用以下脚本手动安装存储库和密钥
wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &amp;gt; packages.microsoft.gpg sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/ sudo sh -c &amp;#39;echo &amp;#34;deb [arch=amd64,arm64,armhf signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main&amp;#34; &amp;gt; /etc/apt/sources.list.d/vscode.list&amp;#39; rm -f packages.microsoft.gpg 更新与安装
sudo apt install apt-transport-httpssudo apt updatesudo apt install code # or code-insiders </description>
    </item>
    <item>
      <title>Linux 操作系统-内存管理</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Thu, 19 Aug 2021 09:37:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>内存管理概述 计算机所谓的“计算”指的是：
进程和线程对于 CPU 的使用 对内存的管理 独享内存空间的原理 每个进程都独享一段内存空间，并且真实物理内存地址对进程不可见，操作系统会给进程分配一个虚拟地址，每个进程看到的内存地址都是从 0 开始。操作系统会将不同进程的虚拟地址和不同内存的物理地址做映射。当程序访问虚拟地址时，由内核的数据结构进行转换，转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址。
规划虚拟地址空间 通过以上的原理，我们可以看出，操作系统的内存管理，主要分为三个方面。
物理内存的管理； 虚拟地址的管理； 虚拟地址和物理地址如何映射； 进程获取了一段独立的虚拟内存空间后，可以不用管其他进程，“任意”使用这片内存，但是也有一点规则。这篇内存需要存放内核态和用户态的内容。高地址存放内核态的内容，低地址存放用户态的内容。具体分界线 64 位与 32 位不同，暂不深究。
我们从最低位开始排起，先是Text Segment、Data Segment 和 BSS Segment。Text Segment 是存放二进制可执行代码的位置，Data Segment 存放静态常量，BSS Segment 存放未初始化的静态变量。是不是觉得这几个名字很熟悉？没错，咱们前面讲 ELF 格式的时候提到过，在二进制执行文件里面，就有这三个部分。这里就是把二进制执行文件的三个部分加载到内存里面。
接下来是堆（Heap）段。堆是往高地址增长的，是用来动态分配内存的区域，malloc 就是在这里面分配的。 接下来的区域是Memory Mapping Segment。这块地址可以用来把文件映射进内存用的，如果二进制的执行文件依赖于某个动态链接库，就是在这个区域里面将 so 文件映射到了内存中。 再下面就是栈（Stack）地址段。主线程的函数调用的函数栈就是用这里的。
普通进程不能访问内核空间，如果需要进行更高权限的工作，就需要系统调用进入内核。每一段进程的内存空间存放的内容各不相同，但是进入内核后看到的都是同一个内核空间，同一个进程列表。
内核的代码访问内核的数据结构，大部分的情况下都是使用虚拟地址的，虽然内核代码权限很大，但是能够使用的虚拟地址范围也只能在内核空间，也即内核代码访问内核数据结构。
接下来，我们需要知道，如何将其映射成为物理地址呢？
咱们前面讲 x86 CPU 的时候，讲过分段机制，咱们规划虚拟空间的时候，也是将空间分成多个段进行保存。我们来看看分段机制的原理。
分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。段选择子就保存在咱们前面讲过的段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。虚拟地址中的段内偏移量应该位于 0 和段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
例如，我们将上面的虚拟空间分成以下 4 个段，用 0～3 来编号。每个段在段表中有一个项，在物理空间中，段的排列如下图的右边所示。如果要访问段 2 中偏移量 600 的虚拟地址，我们可以计算出物理地址为，段 2 基地址 2000 + 偏移量 600 = 2600。
在 Linux 里面，段表全称段描述符表（segment descriptors），放在全局描述符表 GDT（Global Descriptor Table）里面，会有下面的宏来初始化段描述符表里面的表项。</description>
    </item>
    <item>
      <title>Qt 模仿登录界面-交互响应</title>
      <link>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E4%BA%A4%E4%BA%92%E5%93%8D%E5%BA%94/</link>
      <pubDate>Wed, 18 Aug 2021 13:07:01 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E4%BA%A4%E4%BA%92%E5%93%8D%E5%BA%94/</guid>
      <description>效果预览 设置窗口拖动 因为这个项目中没有将登录界面直接继承MainWindow，而是继承的Dialog类，所以它是不能直接移动的，需要我们自己添加相应的方法。这里实现了三种方法，点击，拖动，释放。
//mytitlebar.cpp // 以下通过 mousePressEvent、mouseMoveEvent、mouseReleaseEvent 三个事件实现了鼠标拖动标题栏移动窗口的效果; void MyTitleBar::mousePressEvent(QMouseEvent *event) { if (m_buttonType == MIN_MAX_BUTTON) { // 在窗口最大化时禁止拖动窗口; if (m_pButtonMax-&amp;gt;isVisible()) { m_isPressed = true; m_startMovePos = event-&amp;gt;globalPos(); } } else { m_isPressed = true; m_startMovePos = event-&amp;gt;globalPos(); } return QWidget::mousePressEvent(event); } void MyTitleBar::mouseMoveEvent(QMouseEvent *event) { if (m_isPressed &amp;amp;&amp;amp; m_isMoveParentWindow) { QPoint movePoint = event-&amp;gt;globalPos() - m_startMovePos; QPoint widgetPos = this-&amp;gt;parentWidget()-&amp;gt;pos() + movePoint; m_startMovePos = event-&amp;gt;globalPos(); this-&amp;gt;parentWidget()-&amp;gt;move(widgetPos.x(), widgetPos.y()); } return QWidget::mouseMoveEvent(event); } void MyTitleBar::mouseReleaseEvent(QMouseEvent *event) { m_isPressed = false; return QWidget::mouseReleaseEvent(event); } globalPos()获取全局的坐标 event-&amp;gt;globalPos()是获取全局的坐标，全局是相对于整个屏幕而言的。还有一个函数pos()获取的是局部坐标，相对于一个widget窗口而言。</description>
    </item>
    <item>
      <title>Qt 模仿登录界面-窗口布局及样式</title>
      <link>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E7%AA%97%E5%8F%A3%E5%B8%83%E5%B1%80%E5%8F%8A%E6%A0%B7%E5%BC%8F/</link>
      <pubDate>Tue, 17 Aug 2021 11:30:06 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E7%AA%97%E5%8F%A3%E5%B8%83%E5%B1%80%E5%8F%8A%E6%A0%B7%E5%BC%8F/</guid>
      <description>框架类图 效果预览 完整项目及资源文件请在Github查看。
页面布局 初始化标题栏 // 初始化标题栏; void LoginWindow::initMyTitle() { // 因为这里有控件层叠了，所以要注意控件 raise() 方法的调用顺序; m_titleBar-&amp;gt;move(0, 0); m_titleBar-&amp;gt;raise(); m_titleBar-&amp;gt;setBackgroundColor(100, 0, 0, true); m_titleBar-&amp;gt;setButtonType(MIN_BUTTON); m_titleBar-&amp;gt;setTitleWidth(this-&amp;gt;width()); // 这里需要设置成 false，不允许通过标题栏拖动来移动窗口位置，否则会造成窗口位置错误; m_titleBar-&amp;gt;setMoveParentWindowFlag(false); ui-&amp;gt;pButtonArrow-&amp;gt;raise(); } raise()将控件置于顶层 程序在打开后一般都在所有窗体的顶层，打开其他程序后之前的程序就会被放到下一层，在这里，当设置完my_titleBar后对其他控件操作就会把my_titleBar控件覆盖。所有要用raise()方法将其置于顶层。
初始化窗口 // 初始化窗口; void LoginWindow::initWindow() { //背景 GIG 图; QLabel* pBack = new QLabel(this); QMovie *movie = new QMovie(); movie-&amp;gt;setFileName(&amp;#34;:/Resources/LoginWindow/back.gif&amp;#34;); pBack-&amp;gt;setMovie(movie); movie-&amp;gt;start(); pBack-&amp;gt;move(0, 0); //文本框内提示 ui-&amp;gt;accountComboBox-&amp;gt;setEditable(true); QLineEdit* lineEdit = ui-&amp;gt;accountComboBox-&amp;gt;lineEdit(); lineEdit-&amp;gt;setPlaceholderText(QStringLiteral(&amp;#34;QQ 号码/手机/邮箱&amp;#34;)); QRegExp regExp(&amp;#34;[A-Za-z0-9_]{6,30}&amp;#34;); //正则表达式限制用户名输入不能输入汉字 lineEdit-&amp;gt;setValidator(new QRegExpValidator(regExp,this)); ui-&amp;gt;passwordEdit-&amp;gt;setPlaceholderText(QStringLiteral(&amp;#34;密码&amp;#34;)); //密码框中的小键盘按钮; m_keyboardButton = new QPushButton(); m_keyboardButton-&amp;gt;setObjectName(&amp;#34;pButtonKeyboard&amp;#34;); m_keyboardButton-&amp;gt;setFixedSize(QSize(16, 16)); m_keyboardButton-&amp;gt;setCursor(QCursor(Qt::PointingHandCursor));//鼠标放上去变成手形 QHBoxLayout* passwordEditLayout = new QHBoxLayout(); passwordEditLayout-&amp;gt;addStretch(); passwordEditLayout-&amp;gt;addWidget(m_keyboardButton); passwordEditLayout-&amp;gt;setSpacing(0); passwordEditLayout-&amp;gt;setContentsMargins(0, 0, 8, 0); ui-&amp;gt;passwordEdit-&amp;gt;setLayout(passwordEditLayout); //设置密码达到最长时最后一个字符离小键盘图标的距离（12） ui-&amp;gt;passwordEdit-&amp;gt;setTextMargins(0, 0, m_keyboardButton-&amp;gt;width() + 12, 0); //设置头像以及状态图标 ui-&amp;gt;userHead-&amp;gt;setPixmap(QPixmap(&amp;#34;:/Resources/LoginWindow/HeadImage.</description>
    </item>
    <item>
      <title>Linux 操作系统-进程间通信</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</link>
      <pubDate>Sat, 14 Aug 2021 09:46:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</guid>
      <description>Linux 环境下，进程地址空间相互独立，每个进程各自有不同的用户地址空间。任何一个进程的全局变量在另一个进程中都看不到，所以进程和进程之间不能相互访问，要交换数据必须通过内核，在内核中开辟一块缓冲区，进程 1 把数据从用户空间拷到内核缓冲区，进程 2 再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）。
进程间通信概述 管道 在学 Linux 命令时就有管道在这个概念，比如下面这个命令
ps -ef | -grep root | xargs kill -9 将上一个命令的输出作为下一个命令的输入，数据只能向一个方向流动；双方需要互相通信时，需要建立起两个管道。
管道有两种类型：匿名管道和命名管道。上面提到的命令中|表示的管道即匿名管道 pipe。用完即销毁，自动创建，自动销毁。
使用mkfifo显示创建的是命名管道 fifo，
mkfifo hello hello即是管道名称，类型为p，就是pipe，接下来就可以在管道里写入东西，
# echo &amp;#34;hello world&amp;#34; &amp;gt; hello 光写入还不行，只有有另一个进程读取了内容才完成一次信息交换，才完成一次通信，
# cat &amp;lt; hello hello world 这种方式通信效率低，无法频繁通信。
消息队列 类似于日常沟通使用的邮件，有一定格式，有个收件列表，列表上的用户都可以反复在原邮件基础上回复，达到频繁交流的目的。这种模型就是消息队列模型。
共享内存 共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。
每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存空间映射到不同的物理内存中去。这个进程访问 A 地址和另一个进程访问 A 地址，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。
但是，咱们是不是可以变通一下，拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去。
使用shmget函数创建一个共享内存，
//key_t key: 唯一定位一个共享内存对象 //size_t size: 共享内存大小 //int flag: 如果是 IPC_CREAT 表示创建新的共享内存空间 int shmget(key_t key, size_t size, int flag); 创建完毕之后，我们可以通过 ipcs 命令查看这个共享内存。</description>
    </item>
    <item>
      <title>每天学命令-rename 批量重命名</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-rename%E6%89%B9%E9%87%8F%E9%87%8D%E5%91%BD%E5%90%8D/</link>
      <pubDate>Fri, 13 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-rename%E6%89%B9%E9%87%8F%E9%87%8D%E5%91%BD%E5%90%8D/</guid>
      <description>Commands rename [options] &amp;#34;s/oldname/newname/&amp;#34; file 格式就很容易看出来怎么用的，就是/不能丢。
-v 将重命名的内容都打印到标准输出，v 可以看成 verbose-n 测试会重命名的内容，将结果都打印，但是并不真正执行重命名的过程-f force 会覆盖本地已经存在的文件-h -m -V 分别为帮助，帮助，版本-e 比较复杂，可以通过该选项，写一些脚本来做一些复杂的事情 Examples 替换文件名中的特定字段 rename &amp;#34;s/AA/aa/&amp;#34; * # 把文件名中的AA替换成aa 修改文件后缀 rename &amp;#34;s/.html/.php/&amp;#34; * # 把.html 后缀的改成 .php后缀rename &amp;#34;s/.png/.jpg/&amp;#34; * # 将 png 改为 jpg 添加后缀 rename &amp;#34;s/$/.txt/&amp;#34; * # 把所有的文件名都以txt结尾 $正则表达式中表示结尾。
保留部分文件名 假如需要在批量修改的时候保留部分文件名，可以使用引用\1 ，比如有下面格式的文件，只想保留日期部分。
Screenshot from 2019-01-02 15-56-49.jpgrename -n &amp;#34;s/Screenshot from ([0-9\\- ]+).jpg/\1.jpg/&amp;#34; * 将() 匹配的内容取出来放到替换部分。</description>
    </item>
    <item>
      <title>每天学命令-apt 安装卸载软件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-apt%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E8%BD%AF%E4%BB%B6/</link>
      <pubDate>Thu, 12 Aug 2021 18:42:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-apt%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E8%BD%AF%E4%BB%B6/</guid>
      <description>这个命令应该是我们平时用的最多的命令之一了，应该早就拿出来讲一下的。但是平时用的太多，总感觉自己都会用了，但是仔细看了所有命令，还是有一些比较实用但是没记住的命令。
apt的全称是Advanced Packaging Tool是 Linux 系统下的一款安装包管理工具。APT 可以自动下载、配置和安装二进制或源代码格式软件包，简化了 Unix 系统上管理软件的过程。
APT 主要由以下几个命令组成：
apt-getapt-cacheapt-file Commands 搜索软件包 apt search python3 安装软件包 apt install python3 更新源 sudo apt install update 更新软件 执行完 update 命令后，就可以使用 apt upgrade 来升级软件包了。执行命令后系统会提示有几个软件需要升级。在得到你的同意后，系统即开始自动下载安装软件包。
sudo apt install upgrade 卸载软件 apt remove python3 # 移除软件包，但是保留配置文件apt purge python3 #移除软件包并移除配置apt autoremove # 移除孤立的并不被依赖的软件包 列出软件清单 apt list </description>
    </item>
    <item>
      <title>Qt 添加资源文件（QtCreator）</title>
      <link>http://localhost:8888/posts/qt%E6%B7%BB%E5%8A%A0%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6qtcreator/</link>
      <pubDate>Thu, 12 Aug 2021 10:23:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%B7%BB%E5%8A%A0%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6qtcreator/</guid>
      <description>QtCreator➜新建文件或项目➜Qt➜Qt Resource File
点击Choose，设置资源文件名和路径。资源文件是一系列文件的集合，比如我要建立一个图片的资源文件，我可以设置img为资源文件名，将来所有图片类资源，都放到这个资源文件里，加入还有音频类的文件，我可以新建一个audio的资源文件，以后所有音频类的文件都放到这个资源文件下。
而不是我想要添加的文件名。
右侧编辑器下方有个Add Prefix(添加前缀)，我们首先要添加文件前缀，前缀就是存放文件的文件夹名，然后添加需要的文件。添加完以后看效果就知道啥意思了。
这么做带来的一个问题是，如果以后我们要更改文件名，比如将 xbl.png 改成 xiabanle.png，那么，所有使用了这个名字的路径都需要修改。所以，更好的办法是，我们给这个文件去一个“别名”，以后就以这个别名来引用这个文件。具体做法是，选中这个文件，添加别名信息：
这样，我们可以直接使用:/images/avatar用到这个资源，无需关心图片的真实文件名。</description>
    </item>
    <item>
      <title>每天学命令-kill 这个进程</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-kill%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/</link>
      <pubDate>Wed, 11 Aug 2021 15:22:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-kill%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/</guid>
      <description>对于在前台运行的程序，我们可以用Ctrl+C来终止运行，但是在后台的程序就必须用kill命令来终止了。
Command -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称-a 当处理当前进程时，不限制命令名和进程号的对应关系-p 指定 kill 命令只打印相关进程的进程号，而不发送任何信号-s 指定发送信号-u 指定用户 Examples 查看所有信号 ➜ kill -lHUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS 常用信号
HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \）TERM 15 终止KILL 9 强制终止CONT 18 继续（与 STOP 相反， fg/bg 命令）STOP 19 暂停（同 Ctrl + Z） 用 ps 查找进程，然后用 kill 杀掉 ps -ef | grep &amp;#39;program&amp;#39;kill PID 无条件彻底杀死进程 kill –9 PID 杀死指定用户所有进程 kill -9 $(ps -ef | grep username)kill -u username </description>
    </item>
    <item>
      <title>进程间通信（IPC）之信号（Signal）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7signal/</link>
      <pubDate>Wed, 11 Aug 2021 10:59:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7signal/</guid>
      <description>关于进程间通信的概述可以查看Linux 操作系统 - 进程间通信，代码同步在这里。
本文通过实例介绍通过共享内存实现进程间通信。
简介 信号就像实际生产过程中的应急预案，发生了某个异常就会启动特定的应急预案，为了响应各类异常情况，所以就定义了很多个信号，信号的名称是在头文件signal.h中定义的，信号都以SIG开头，常用的信号并不多，常用的信号如下：
SIGALRM #时钟定时信号, 计算的是实际的时间或时钟时间SIGHUP #终端的挂断或进程死亡SIGINT #来自键盘的中断信号SIGKILL #用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。SIGPIPE #管道破裂SIGTERM #程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理SIGUSR1,SIGUSR2 #留给用户使用 实例 #include &amp;lt;signal.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; void signalHandler(int sig) { printf(&amp;#34;\nOps! - I got signal %d\n&amp;#34;, sig); // 恢复终端中断信号 SIGINT 的默认行为 (void)signal(SIGINT, SIG_DFL); } int main() { // 改变终端中断信号 SIGINT 的默认行为，使之执行 ouch 函数 // 而不是终止程序的执行 (void)signal(SIGINT, signalHandler); while (1) { printf(&amp;#34;Hello World!\n&amp;#34;); sleep(1); } return 0; } 我们可以用signal()函数处理指定的信号，主要通过忽略和恢复其默认行为来工作。signal() 函数的原型如下：</description>
    </item>
    <item>
      <title>进程间通信（IPC）之共享内存 (SharedMemory)</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98sharedmemory/</link>
      <pubDate>Tue, 10 Aug 2021 17:41:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98sharedmemory/</guid>
      <description>关于进程间通信的概述可以查看Linux 操作系统 - 进程间通信，代码同步在这里。
本文通过实例介绍通过共享内存实现进程间通信。
shmget(得到一个共享内存标识符或创建一个共享内存对象) 我们可以通过shmget函数创建或打开共享内存，通过函数签名
//key_t key: 唯一定位一个共享内存对象 //size_t size: 共享内存大小 //int flag: 如果是 IPC_CREAT 表示创建新的共享内存空间 int shmget(key_t key, size_t size, int flag); 第一个参数是共享内存的唯一标识，是需要我们指定的。那么如何指定key呢？如何保证唯一性呢？我们可以指定一个文件，ftok会根据这个文件的 inode，生成一个近乎唯一的 key。只要在这个消息队列的生命周期内，这个文件不要被删除就可以了。只要不删除，无论什么时刻，再调用 ftok，也会得到同样的key。 第二个参数是申请的空间大小，我们就申请 1024B。 第三个参数是权限标识，IPC_CREAT表示创建共享内存，0644表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。 shmat(把共享内存区对象映射到调用进程的地址空间) 第一次创建完共享内存时，它还不能被任何进程访问，shmat()函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。它的签名如下：
void *shmat(int shm_id, const void *shm_addr, int shmflg); 第一个参数就是上文产生的唯一标识。 第二个参数，shm_addr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址。 第三个参数，shm_flg是一组标志位，通常为 0。 调用成功时返回一个指向共享内存第一个字节的指针，如果调用失败返回-1. (void *) - 1把-1转换为指针0xFFFFFFFF，有时也会用到(void*)0，表示一个空指针。
shmdt(断开共享内存连接) 与 shmat 函数相反，是用来断开与共享内存附加点的地址，禁止本进程访问此片共享内存
函数签名如下：
int shmdt(const void *shmaddr) 参数一shmaddr为连接共享内存的起始地址。 需要注意的是，本函数调用并不删除所指定的共享内存区，而只是将先前用 shmat 函数连接（attach）好的共享内存脱离（detach）目前的进程。删除共享内存就需要下面的这个函数。
shmctl(共享内存管理) 完成对共享内存的控制，包括改变状态，删除共享内存等。
函数签名如下：
int shmctl(int shmid, int cmd, struct shmid_ds *buf) shmid共享内存唯一标识符 cmd执行的操作，包括如下 IPC_STAT：得到共享内存的状态，把共享内存的shmid_ds结构复制到buf中 IPC_SET：改变共享内存的状态，把buf所指的shmid_ds结构中的uid、gid、mode复制到共享内存的shmid_ds结构内 IPC_RMID：删除这片共享内存 buf共享内存管理结构体。具体说明参见共享内存内核结构定义部分 //server.</description>
    </item>
    <item>
      <title>每天学命令-ar 多文件归档为一个文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ar%E5%A4%9A%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/</link>
      <pubDate>Tue, 10 Aug 2021 11:33:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ar%E5%A4%9A%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/</guid>
      <description>现在我们有solution.c,solution.h两个文件，他们实现了某一个功能，自成一个模块。在其他项目中也可复用。我们就可以把它做成库文件。ar命令就可以将锁哥文件整合成一个库文件，也可以从一个库中单独提取出某一个文件。
Commands -d 删除备存文件中的成员文件。-m 变更成员文件在备存文件中的次序。-p 显示备存文件中的成员文件内容。-q 将文件附加在备存文件末端。-r 将文件插入备存文件中。-t 显示备存文件中所包含的文件。-x 自备存文件中取出成员文件。 Examples 打包文件 将solution.c solution.h两个文件打包成solution.bak，并显示详细信息
➜ ar rv solution.bak solution.c solution.har: 正在创建 solution.baka - solution.ca - solution.h 显示打包文件内容 ➜ ar t solution.bak solution.csolution.h </description>
    </item>
    <item>
      <title>每日学命令-ps 显示进程状态</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E5%91%BD%E4%BB%A4-ps%E6%98%BE%E7%A4%BA%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81/</link>
      <pubDate>Mon, 09 Aug 2021 19:37:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E5%91%BD%E4%BB%A4-ps%E6%98%BE%E7%A4%BA%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81/</guid>
      <description>ps命令显示的信息类似于 Windows 的任务管理器。也是参数超级多的一个命令，所以就不列参数了，需要查看时直接搜索，这里列举一下实例。
使用实例 显示当前执行的所有程序
➜ ~ ps -a PID TTY TIME CMD 879 tty2 00:03:43 Xorg 990 tty2 00:00:00 gnome-session-b 2653 pts/0 00:00:00 zsh 12365 pts/0 00:00:00 ps 显示所有程序
➜ ~ ps -A PID TTY TIME CMD 1 ? 00:00:01 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:00 rcu_gp 4 ? 00:00:00 rcu_par_gp 6 ? 00:00:00 kworker/0:0H-kblockd 9 ? 00:00:00 mm_percpu_wq 10 ? 00:00:00 ksoftirqd/0 11 ? 00:00:02 rcu_sched 12 ?</description>
    </item>
    <item>
      <title>解决 OpenSSL SSL_connect: Connection was reset in connection to github.com:443</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3openssl-ssl-connect-connection-was-reset-in-connection-to-github-com-443/</link>
      <pubDate>Mon, 09 Aug 2021 18:20:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3openssl-ssl-connect-connection-was-reset-in-connection-to-github-com-443/</guid>
      <description>在向 GitHub 推送博客时，推送失败报了这个错。也不知道是改了什么设置突然报错。SSL 的错之前遇到一次，就是刚开始配置 Git 时用的https协议，每次push都需要重新输入一次密码。改成ssl协议就 OK 了。当时把 Linux 环境的 Git 改了，但是现在的 Windows 下没改，猜测可能和这也有关，于是就把 URL 改了一下，结果还真好了。 在本地仓库的.git文件里找到config文件，打开后将url改为ssl协议，git@github.com:XXX格式的。
将 Hexo 的配置也改了，找到仓库下的_config.yml
deploy:type: gitrepository: 改成ssl协议地址branch: master </description>
    </item>
    <item>
      <title>Qt 事件</title>
      <link>http://localhost:8888/posts/qt%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Mon, 09 Aug 2021 09:55:07 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E4%BA%8B%E4%BB%B6/</guid>
      <description>本篇文章所涉及代码可在此处查看
事件以及与信号的区别 事件（event）是由系统或者 Qt 本身在不同的时刻发出的。当用户按下鼠标、敲下键盘，或者是窗口需要重新绘制的时候，都会发出一个相应的事件。一些事件在对用户操作做出响应时发出，如键盘事件等；另一些事件则是由系统自动发出，如计时器事件。
事件和信号槽的区别
信号是由具体对象发出，然后马上交给connect函数连接的槽进行处理，如果处理过程中产生了新的信号，将会继续执行新的信号，一直这样递归进行下去。而事件使用一个事件队列对发出的所有事件进行维护，当新的事件产生时会被加到事件队列的尾部。 在运行过程中发现，刚启动时并不会显示任何内容，只有在点击一次后，平面才会显示信息。这是因为QWidget中有一个mouseTracking属性，该属性用于设置是否追踪鼠标。只有鼠标被追踪时，mouseMoveEvent()才会发出。如果mouseTracking是 false（默认即是），组件在至少一次鼠标点击之后，才能够被追踪，也就是能够发出mouseMoveEvent()事件。如果mouseTracking为 true，则mouseMoveEvent()直接可以被发出。知道了这一点，我们就可以在main()函数中直接设置下：
EventLabel *label = new EventLabel;label-&amp;gt;setWindowTitle(&amp;#34;MouseEvent Demo&amp;#34;);label-&amp;gt;resize(300, 200);label-&amp;gt;setMouseTracking(true);label-&amp;gt;show(); 显示效果 事件的接受与忽略 //custombutton.h #include &amp;lt;QDebug&amp;gt; #include &amp;lt;QMouseEvent&amp;gt; #include &amp;lt;QApplication&amp;gt; #include &amp;lt;QPushButton&amp;gt; class CustomButton : public QPushButton { Q_OBJECT private: void onButtonClicked(); public: CustomButton(QWidget *parent = 0); }; //custombutton.cpp #include &amp;#34;custombutton.h&amp;#34; CustomButton::CustomButton(QWidget *parent) : QPushButton(parent) { connect(this, &amp;amp;CustomButton::clicked, this, &amp;amp;CustomButton::onButtonClicked); } void CustomButton::onButtonClicked() { qDebug() &amp;lt;&amp;lt; &amp;#34;You clicked this!&amp;#34;; } //main02.</description>
    </item>
    <item>
      <title>每天学命令-scp 远程拷贝文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-scp%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D%E6%96%87%E4%BB%B6/</link>
      <pubDate>Fri, 06 Aug 2021 20:05:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-scp%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D%E6%96%87%E4%BB%B6/</guid>
      <description>看到同事要安装自己编译一天的库，本想传授一下“踩坑经验”，结果他用scp命令直接从已经安装好的电脑里复制了一份。心里一万只 XXX 在奔腾。
早知道先学学这个命令了。
可选参数 参数 功能 -1 强制 scp 命令使用协议 ssh1 -2 强制 scp 命令使用协议 ssh2 -4 强制 scp 命令使用协议 ssh2 -6 强制 scp 命令只使用 IPv6 寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩 -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条 -r 递归复制整个目录 -v 详细方式显示输出 -P 注意是大写的 P, port 是指定数据传输用到的端口号 使用实例 复制文件
scp local_file rmot_usr@rmot_ip:rmot_folderscp /opt/soft/ root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz </description>
    </item>
    <item>
      <title>每天学命令-grep 文本搜索</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-grep%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Thu, 05 Aug 2021 19:27:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-grep%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2/</guid>
      <description>grep全称global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来。这名字就怪吓人，如果熟练掌握正则表达式，配上这命令 Linux 里可以横着走了。
这个命令参数实在太多，加上正则表达式估计一张纸不够。那就直接上实例吧。
使用实例 在当前目录中，查找后缀带有cpp字样的文中包含test字符串的文件，并打印所在行
grep test *cppgrep --colorauto test *cpp # 用颜色标记 通过&amp;quot;-v&amp;quot;参数可以打印出不符合条件行的内容。
grep -v test *cpp 系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行)。-n 或 --line-number 可以显示符合样式的那一行之前，标示出该行的列数编号。
grep -n &amp;#39;2019-10-24 00:01:11&amp;#39; *.log grep 静默输出，不会输出任何信息，如果命令运行成功返回 0，失败则返回非 0 值。一般用于条件测试。
grep -q &amp;#34;test&amp;#34; filename 在多级目录中对文本进行递归搜索
grep &amp;#34;text&amp;#34; . -r -n 配合管道，查找指定的进程信息
ps -ef | grep svn 查找指定的进程个数，-c计数
ps -ef | grep svn -c 常用正则表达式通配符
通配符 功能 c* 将匹配 0 个（即空白）或多个字符 c（c 为任一字符） .</description>
    </item>
    <item>
      <title>Qt 对话框</title>
      <link>http://localhost:8888/posts/qt%E5%AF%B9%E8%AF%9D%E6%A1%86/</link>
      <pubDate>Thu, 05 Aug 2021 10:11:33 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E5%AF%B9%E8%AF%9D%E6%A1%86/</guid>
      <description>本篇文章所涉及代码，可在此处查看
Qt 中使用 QDialog 类实现对话框。就像主窗口一样，我们通常会设计一个类继承 QDialog。QDialog（及其子类，以及所有 Qt::Dialog 类型的类）的对于其 parent 指针都有额外的解释：
如果 parent 为 NULL，则该对话框会作为一个顶层窗口，否则则作为其父组件的子对话框（此时，其默认出现的位置是 parent 的中心）。
顶层窗口与非顶层窗口的区别在于，顶层窗口在任务栏会有自己的位置，而非顶层窗口则会共享其父组件的位置。
对话框分为模态对话框和非模态对话框。所谓模态对话框，就是会阻塞同一应用程序中其它窗口的输入。模态对话框很常见，比如“打开文件”功能。你可以尝试一下记事本的打开文件，当打开文件对话框出现时，我们是不能对除此对话框之外的窗口部分进行操作的。
与此相反的是非模态对话框，例如查找对话框，我们可以在显示着查找对话框的同时，继续对记事本的内容进行编辑。
Qt 支持模态对话框和非模态对话框。其中，Qt 有两种级别的模态对话框：应用程序级别的模态和窗口级别的模态，默认是应用程序级别的模态。应用程序级别的模态是指，当该种模态的对话框出现时，用户必须首先对对话框进行交互，直到关闭对话框，然后才能访问程序中其他的窗口。窗口级别的模态是指，该模态仅仅阻塞与对话框关联的窗口，但是依然允许用户与程序中其它窗口交互。
消息对话框 QMessageBox 文件对话框 QFileDialog &amp;lsquo;QTextEdit&amp;rsquo; Does not name a type 需要包含头文件
#include &amp;lt;QTextEdit&amp;gt; Qt 需要包含的头文件实在太多了。
可能添加了头文件仍然报同样的错，没有搜索到相关的解答。
我的做法是：
确保在.pro文件中加入QT += widgets和CONFIG += c++11 将包含库文件语句都放到头文件.h中 </description>
    </item>
    <item>
      <title>Git 中添加 gitignore 并更新远程仓库</title>
      <link>http://localhost:8888/posts/git%E4%B8%AD%E6%B7%BB%E5%8A%A0gitignore%E5%B9%B6%E6%9B%B4%E6%96%B0%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/</link>
      <pubDate>Wed, 04 Aug 2021 14:09:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E4%B8%AD%E6%B7%BB%E5%8A%A0gitignore%E5%B9%B6%E6%9B%B4%E6%96%B0%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/</guid>
      <description>gitignore 的作用 在使用Git版本控制时，必须要用.gitignore这个文件来告诉Git那些文件或目录不需要添加到版本控制中。通俗点说，就是不需要git push到远程仓库。
在平时开发过程中，开发目录下会有各种格式的文件，比如 C 语言除了.c源码，还会有.o目标文件，没有后缀的可执行程序等等，假如你要进行深度学习类的开发，如图像识别，需要训练大量数据，如果这些训练数据也到跟踪管理，那push一次就可以下班回家了。
但是我们怎么让Git知道哪些文件需要跟踪，哪些文件不需要呢，这时候.gitignore文件就起作用了。
常用规则 简单介绍一下常用的规则，虽然后面有现成的模板，但是我们还是了解一下常用规则，能看得懂.gitignore里写了啥。也方便自己编写一些规则适应自己的工作。
/test/ # 过滤整个test文件夹*.o # 过滤所有.o文件/test/hello.o # 过滤test文件夹下hello.o这个文件!src/ # 不过滤src这个文件夹!*.c # 不过滤.c文件 通过 gitignore 文件更新远程仓库 上面说到我们在不同环境下需要制定不同的规则，但是每次都要重新写一遍，又或者不知道制定什么样的规则，还是挺麻烦的。
首先推荐一个.gitignore模板仓库，在平时工作学习中遇到的各种语言环境下的模板都能找到。这是广大开发人员总结的一些规则。
最近在学习Qt，在所有模板中搜索关键字，找到了Qt.gitignore这个模板打开并复制，在自己本地仓库里新建一个.gitignore文件，将复制的内容粘贴进去。
现在就要解决如何更新远程仓库的内容，因为我在使用.gitignore文件之前已经向远程push过了，现在需要删除不需要的文件。
git rm -r --cached . rm就是Linux下常用的删除命令，-r表示递归删除，--cached表示需要在本地端（工作区）保留文件，.表示所有文件。
git add . # 重新添加所有文件到暂存区，然后提交，推送git commit -m &amp;#34;update&amp;#34;git push </description>
    </item>
    <item>
      <title>Qt 添加资源文件</title>
      <link>http://localhost:8888/posts/qt%E6%B7%BB%E5%8A%A0%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6/</link>
      <pubDate>Wed, 04 Aug 2021 11:34:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%B7%BB%E5%8A%A0%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6/</guid>
      <description> 本文是学习【Qt 学习之路】的学习笔记，源码非原创。Github同步本文更改的代码。
在建立 Qt 学习代码仓时，推送到远程的代码比较乱，所以用gitignore文件屏蔽了一些。相关方法在这里。
资源文件 Qt 资源系统是一个跨平台的资源机制，用于将程序运行时所需要的资源以二进制的形式存储于可执行文件内部。如果你的程序需要加载特定的资源（图标、文本翻译等），那么，将其放置在资源文件中，就再也不需要担心这些文件的丢失。也就是说，如果你将资源以资源文件形式存储，它是会编译到可执行文件内部。
使用 QtCreator 的相关方法，讲得也很清楚了，就不赘述了。
不使用 QtCreator 添加资源文件 在使用命令行编译运行时，并不能像在 QtCreator 中一样，可以自动的生成一个.qrc文件，这就需要我们自己去编写。从原文的讲解中我们也知道，它就是一个XML描述文件，里面定义了文件位置等信息。如原文中的.qrc文件：
&amp;lt;RCC&amp;gt;&amp;lt;qresource prefix=&amp;#34;/images&amp;#34;&amp;gt;&amp;lt;file alias=&amp;#34;doc-open&amp;#34;&amp;gt;document-open.png&amp;lt;/file&amp;gt;&amp;lt;/qresource&amp;gt;&amp;lt;/RCC&amp;gt; 其中
&amp;lt;RCC&amp;gt;&amp;lt;qresource&amp;gt;&amp;lt;/qresource&amp;gt;&amp;lt;/RCC&amp;gt; 是固定的标记，再往中间加东西。如果学过html语言就很容易理解。其中prefix=&amp;quot;/images&amp;quot;就是自动加上前缀/images，因为图片在images目录下，每次都加这个路径太麻烦，太长。
alias=&amp;quot;doc-open&amp;quot;意思是将document-open.png这个文件起个别名，原来的太长了。下次再用document-open.png就只需要用doc-open就行了。
我们知道了这些，就可以编写一个自己的.qrc文件了。我也自己下载了一个打开文件的图标open.png，文件比较少，就和代码放在同一个目录下了。我们将其命名为ico.qrc，这个文件中以后都存放有关图标的资源，我们开始编写：
&amp;lt;RCC&amp;gt;&amp;lt;qresource&amp;gt;&amp;lt;file&amp;gt;open.png&amp;lt;/file&amp;gt;&amp;lt;/qresource&amp;gt;&amp;lt;/RCC&amp;gt; 因为添加资源后需要更新.pro文件才能正常编译，所以需要在.pro中加入RESOURCES 信息，就在.pro文件最后一行加入：
RESOURCES += ico.qrc 然后输入命令
qmake MainWindow.promake clean #因为之前可能make过，先清理一遍make./MainWindow 如果一切顺利，将会得到下面的窗口： Reference https://www.devbean.net/2012/08/qt-study-road-2-action/ </description>
    </item>
    <item>
      <title>每天学命令-cat 可以查看文件的小猫咪</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-cat%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%B0%8F%E7%8C%AB%E5%92%AA/</link>
      <pubDate>Wed, 04 Aug 2021 09:57:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-cat%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%B0%8F%E7%8C%AB%E5%92%AA/</guid>
      <description>cat 可以将文件的内容方便地输出到屏幕上。但是它的全称concatenate意为“连接”，连接文件也是它的重要功能之一，很多人可能都不常用。只记得输出文件内容了。
可选参数 -n 或 --number #由 1 开始对所有输出的行数编号。-b 或 --number-nonblank #和 -n 相似，只不过对于空白行不编号。-s 或 --squeeze-blank #当遇到有连续两行以上的空白行，就代换为一行的空白行。-v 或 --show-nonprinting #使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。-E 或 --show-ends # 在每行结束处显示 $。-T 或 --show-tabs: #将 TAB 字符显示为 ^I。-A, --show-all #等价于 -vET。-e #等价于&amp;#34;-vE&amp;#34;选项；-t #等价于&amp;#34;-vT&amp;#34;选项； 使用实例 将文件内容输出到屏幕
➜ ~ cat test.txt This is firt line!This is second line!This is third line!This is fourth line!</description>
    </item>
    <item>
      <title>解决/usr/bin/env:python:No such file or directory</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3-usr-bin-env-python-no-such-file-or-directory/</link>
      <pubDate>Tue, 03 Aug 2021 15:58:44 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3-usr-bin-env-python-no-such-file-or-directory/</guid>
      <description>在执行的程序源码开头有这么一句!#/usr/bin/env python，!#这玩意叫shebang也叫hashbang。他用来指定脚本的解释器，也就是说这个程序指定python解释器。
再看这个错误提示，罪魁祸首就是这句命令，就是说在环境变量找不到python，通俗点说，假如我要能直接用python来跑这个程序，我在命令行直接输入python应该是可以进入python环境的，但是此时肯定不能。我们可以试试
dominic@hanhan:~$ pythonCommond not found xxxxxxxxxxx 解决方案一 系统里没有python还跑个锤子，先装上再说
apt-get install python3 这时候可能就解决问题了
解决方案二 有的人可能python早就装了，但是仍然有这个问题，但是我们在命令输入python仍然没法用，但是输入python3就可以
那python3可以，我直接将python改成python3不就完了。没错！
打开文件将!#/usr/bin/env python改成!#/usr/bin/env python3
解决方案三 如果了解软链接，那我们就可以不用去改源码了，源码最好还是保持原样。
既然找不到python这玩意，那我们给他建一个不就完了。
他要python就是用来解释程序的，我们本地装的python3就是他需要的东西
先找找我们的python3在哪
dominic@hanhan:~$ whereis python3python3: /usr/bin/python3.8 /usr/bin/python3.8-config /usr/bin/python3 一般在/usr/bin目录下，然后我们在这个目录下给他创建一个软链接“快捷方式”，具体咋用的啥意思，可以参考这篇文章。
sudo ln -s /usr/bin/python3 /usr/bin/python 这样程序再找python时就会链接到python3，然后用python3去当解释器。
解决方案四 可能在root目录下使用过repo，将其删除</description>
    </item>
    <item>
      <title>每天学命令-ln 软硬链接</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ln%E8%BD%AF%E7%A1%AC%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Tue, 03 Aug 2021 11:57:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ln%E8%BD%AF%E7%A1%AC%E9%93%BE%E6%8E%A5/</guid>
      <description>Linux ln（英文全拼：link files）命令是一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。这有点像 Windows 环境下的快捷方式。介绍命令前了解一下软链接，硬链接具体是什么。
硬链接 Hard Link 在 Linux 系统中，每个文件对应一个 inode，文件的内容在存储在 inode 指向的 data block 中。要读取该文件的内容，需要通过文件所在的目录中记录的文件名找到文件的 inode 号，然后通过 inode 找到存储文件内容的 data block。当然多个文件名可以指向同一个inode。
使用ll命令显示文件的详细信息，-i参数显示其结点信息，其中最前面的一串数字就是inode信息。我们以/opt/test.txt文件为例，查看其结点信息。
dominic@hanhan:/opt$ ll -i test.txt 2498138 -rw-r--r-- 1 root root 4 8月 3 12:16 test.txt 使用 ln 命令在/opt/temp目录下创建一个 test.txt 文件的硬链接，然后观察其文件属性：
dominic@hanhan:/opt/temp$ sudo ln ../test.txt .dominic@hanhan:/opt/temp$ ll -i ../test.txt test.txt 2498138 -rw-r--r-- 2 root root 4 8月 3 12:16 ../test.txt2498138 -rw-r--r-- 2 root root 4 8月 3 12:16 test.</description>
    </item>
    <item>
      <title>每天学命令-ed 行编辑器</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ed%E8%A1%8C%E7%BC%96%E8%BE%91%E5%99%A8/</link>
      <pubDate>Mon, 02 Aug 2021 09:57:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ed%E8%A1%8C%E7%BC%96%E8%BE%91%E5%99%A8/</guid>
      <description>ed命令是文本编辑器，用于文本编辑。
ed是 Linux 中功能最简单的文本编辑程序，一次仅能编辑一行而非全屏幕方式的操作。很多命令和vim相似，平时开发中并不常用，但是在编辑大文本时还是会用到。
学学无妨毕竟这是 Unix 系统三大要件（编辑器，汇编器和 shell）之一。
ed编辑器有两种模式：命令模式和输入模式。命令模式下输入a,i,c,d可以进入对应的编辑模式，接下来可以输入任何想要输入的内容，输入完毕或者要切换命令时，可以输入.退出输入模式。
Commands a #添加到行i #添加到行首c #改变行d #删除行 Line Address . #buffer 中 当前行$ #最后一行n #第 n 行，行的范围是 [0,$]- or ^ #前一行-n or ^n #前 n 行+ or +n #后一行及后n行, or % #全部行，等同于 1,$; #当前行到最后一行 .,$/re/ #下一个包含正则 re 的行?re? #上一个包含正则 re 的行 使用实例 dominic@hanhan:~$ ed # 进入编辑模式This is a test text!</description>
    </item>
    <item>
      <title>每天学命令-wc 统计文件有多少字多少行</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-wc%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E6%9C%89%E5%A4%9A%E5%B0%91%E5%AD%97%E5%A4%9A%E5%B0%91%E8%A1%8C/</link>
      <pubDate>Fri, 30 Jul 2021 17:26:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-wc%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E6%9C%89%E5%A4%9A%E5%B0%91%E5%AD%97%E5%A4%9A%E5%B0%91%E8%A1%8C/</guid>
      <description>想知道自己代码写了多少行，可以一个wc命令搞定。
可选参数 -l：仅列出行； -w：仅列出多少字 (英文单字)； -m：多少字符 使用实例 统计hello.c文件夹下文件总共多少行
$ wc -l hello.c 14 hello.c 统计文件夹下文件的个数
ls -l | grep &amp;#34;^-&amp;#34; | wc -l 统计当前目录下文件的个数（包括子目录）
ls -lR| grep &amp;#34;^-&amp;#34; | wc -l 查看目录下文件夹 (目录) 的个数（包括子目录）
ls -lR | grep &amp;#34;^d&amp;#34; | wc -l 过滤ls的输出信息，只保留一般文件，只保留目录是grep &amp;quot;^d&amp;quot;。 </description>
    </item>
    <item>
      <title>更换 Ubuntu 软件更新源</title>
      <link>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2ubuntu%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</link>
      <pubDate>Fri, 30 Jul 2021 11:14:41 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2ubuntu%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</guid>
      <description>Ubuntu 默认是国外的源，软件下载和更新都比较慢。两种方法将下载源换成国内的源。
用&amp;quot;软件和更新&amp;quot;工具 从 Ubuntu 菜单中找到软件和更新这个应用并打开。
找到下载自，选择其他 - 国内-aliyun，然后勾选前四个选项。关闭时会弹出对话框，点击更新。然后就能愉快的下载软件了。
修改sourcelist 备份原文件 这也算是系统文件的一部分，还是保险一点，出错了再改回来。
sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup 打开并修改 sudo vi /etc/apt/sources.list vim用的不习惯的估计会和我一样找全选内容怎么操作。教给你了 在命令模式下，就是按一下esc键，然后输入ggvG。具体什么含义看VIM 笔记吧，选择后直接delete删除，再把阿里云源粘贴进去。保存退出。
#阿里云 deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.</description>
    </item>
    <item>
      <title>每天学命令-find 查找文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-find%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 29 Jul 2021 11:05:43 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-find%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/</guid>
      <description>命令格式 find [path] [expression] 在path下查找expression表示的文件
常用命令 一般常见就是自己不知道写的某个文件或者文件夹放哪里了，又或者只记住部分文件名。以下几个命令就能帮到你。
按文件名查找 find -name filename(查找结果显示路径)或者 find filename(查找结果不显示路径)find hello.cpp #当前目录下精确查找hello.cpp文件find hello #当前目录下精确查找hello文件find hello* #当前目录下模糊查找以hello为前缀的文件 按类型查找 这就是为查找文件夹用的。
find -type [fdlcb] name [fdlcb]都是类型，d就是目录，文件夹类型。
find / -type d -name &amp;#34;helloworld&amp;#34; #查找名为helloworld的文件夹 按文件名查找 以下就详细介绍一些参数
find -name &amp;#34;hello.cpp&amp;#34; # 搜索文件名，大小写敏感find -iname &amp;#34;hello.cpp&amp;#34; #大小写不敏感 按文件大小查找 find [path] -size 50Mfind / -size 10M # 查找系统中大小等于10M的文件find / -size +50M # 查找系统中大小大于50M的文件find / -size -30M # 查找系统中大小小于30M的文件 按时间来查找文件 Linux 会存储下面的时间：</description>
    </item>
    <item>
      <title>git clone 快速下载子模块</title>
      <link>http://localhost:8888/posts/git-clone%E5%BF%AB%E9%80%9F%E4%B8%8B%E8%BD%BD%E5%AD%90%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Wed, 28 Jul 2021 15:28:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/git-clone%E5%BF%AB%E9%80%9F%E4%B8%8B%E8%BD%BD%E5%AD%90%E6%A8%A1%E5%9D%97/</guid>
      <description>在git clone时候，如果遇到项目里有子模块通常会在下载时加上--recursive参数，一起下载。但是子模块较多，体积较大时大概率都会下载失败。
好在可以通过一些小技巧，下载国内镜像，进行加速。但是下载项目时，只是主体是国内的镜像，子模块仍然下载很慢。首先解决获取国内镜像的问题。有三个方法：
在码云 Gitee 上搜索下载
在码云上搜索同样的项目，然后用码云git 的地址下载。
加上.cnpmjs.org后缀
在地址后面加上后缀，如git clone https://github.com.cnpmjs.org/riscv/riscv-binutils-gdb.git。
使用油猴脚本获取镜像地址
如果你有油猴插件可以去greasyfork搜索安装GitHub镜像访问，加速下载这个脚本，刷新GitHub仓库界面就会多出几个镜像地址，一般下载都会快好几倍。
再来解决子模块下载速度慢的问题，下载项目时，先不加--recursive参数，只下载项目的本题。
下载完后找到.gitmodules文件，这是一个隐藏文件，需要显示隐藏文件，Linux 下使用快捷键Ctrl+H。用vim打开后可以得到：
这个文件里写入了子模块的下载信息，url就是下载地址。我们把所有子模块中的 URL 地址同样加上.cnpmjs.org后缀。或者使用上述三种方式得到的镜像地址。
然后利用git submodule sync更新子项目对应的url
最后再git submodule update --init --recursive，即可快速下载所有子项目。</description>
    </item>
    <item>
      <title>在 QEMU 上运行 64 位和 32 位 RISC-V-Linux</title>
      <link>http://localhost:8888/posts/qemu%E4%B8%8A%E8%BF%90%E8%A1%8C64%E4%BD%8D%E5%92%8C32%E4%BD%8Drisc-v-linux/</link>
      <pubDate>Wed, 28 Jul 2021 13:47:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E4%B8%8A%E8%BF%90%E8%A1%8C64%E4%BD%8D%E5%92%8C32%E4%BD%8Drisc-v-linux/</guid>
      <description>制作交叉工具链 riscv-gnu-toolchain 下载源码 这个仓库是我遇到的最难下载的一个仓库了，公司网慢和虚拟机性能差都脱不了干系。估计下载了五小时都不止，刚开始还指望一个命令所有子模块都下载完的，结果愣是等了半天中断了。试了两次后放弃了。如果各位看官能一次完成，那您是福大。
国内的码云平台有个Gitee 极速下载项目，上面有 GitHub 的一些常用开源项目的镜像，可供加速下载。
# riscv-gnu-toolchainhttps://gitee.com/mirrors/riscv-gnu-toolchain.git 下载时问题出现了，如果下载子模块仍然会卡住，如果不加--recursive就只能下载主体内容，子模块都没有。（以下内容为第一安装时的方法，后续又找到了git clone 快速下载子模块的方法）
开始下载时不加--recursive参数，只下载riscv-gnu-toolchain的主体内容，然后进入到riscv-gnu-toolchain文件夹下，手动下载子模块的内容。
当下完riscv-binutils继续下载riscv-gdb时发现这两个项目是同一个项目，只是不同的分支。但是码云上并没有区分，但是我也没找到在码云上的对应分支。只能用油猴脚本了。
如果你有油猴插件可以去greasyfork搜索安装GitHub 镜像访问，加速下载这个脚本，刷新 GitHub 仓库界面就会多出几个镜像地址，一般下载都会快好几倍。如果不用油猴插件的可以用我复制好的链接。
# riscv-binutilsgit clone https://gitee.com/mirrors/riscv-binutils-gdb.git# riscv-gccgit clone https://gitee.com/mirrors/riscv-gcc.git# riscv-dejagnugit clone https://gitee.com/mirrors/riscv-dejagnu.git# riscv-glibcgit clone https://gitee.com/mirrors/riscv-glibc.git# riscv-newlibgit clone https://gitee.com/mirrors/riscv-newlib.git# riscv-gdbgit clone --depth=1 https://hub.fastgit.org/riscv/riscv-binutils-gdb.git 编译 riscv-gnu-toolchain 提前安装如下软件：
sudo apt-get install autoconf automake autotools-dev curl python3 libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev 不听老人言，吃亏在眼前呀，本以为这是可选项，很多库都安装了，就没有操作这一步，结果就是编译半天结果还错了。如果报make 错误 127，那就老老实实把前置的这些库都装上。</description>
    </item>
    <item>
      <title>每天学命令-df/du查看磁盘剩余空间</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-df-du%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Wed, 28 Jul 2021 10:13:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-df-du%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4/</guid>
      <description>df全称disk filesystem ，以磁盘分区为单位查看文件系统，可以查看磁盘文件占用空间，磁盘剩余空间等信息。
命令格式 df [] [] 可选参数 -a 全部文件系统列表-h 方便阅读方式显示-H 等于“-h”，但是计算式，1K=1000，而不是 1K=1024-i 显示 inode 信息-k 区块为 1024 字节-l 只显示本地文件系统-m 区块为 1048576 字节--no-sync 忽略 sync 命令-P 输出格式为 POSIX--sync 在取得磁盘信息前，先执行 sync 命令-T 文件系统类型 使用实例 df -T显示包含文件系统，类型，可用大小，已用大小，挂载点等信息。
dominic@hanhan:~$ df -T文件系统 类型 1K-块 已用 可用 已用% 挂载点udev devtmpfs 1985056 0 1985056 0% /devtmpfs tmpfs 403036 1304 401732 1% /run/dev/sda5 ext4 50824704 20826256 27386992 44% /tmpfs tmpfs 2015172 0 2015172 0% /dev/shmtmpfs tmpfs 5120 4 5116 1% /run/locktmpfs tmpfs 2015172 0 2015172 0% /sys/fs/cgroup/dev/loop0 squashfs 56832 56832 0 100% /snap/core18/1988/dev/loop1 squashfs 56832 56832 0 100% /snap/core18/2074 du全称disk usage可以查看文件，文件夹占用情况。</description>
    </item>
    <item>
      <title>Linux(Ubuntu) 环境下安装 Qt</title>
      <link>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85qt/</link>
      <pubDate>Tue, 27 Jul 2021 16:34:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85qt/</guid>
      <description>真蠢，之前费那么大劲，只要一句命令就完事了
下载安装 sudo apt install qtcreator 但是在用命令行构建 project 时可能会报错
qmake -projectcould not find a Qt installation of &amp;#39;&amp;#39; 这时候需要
sudo apt-get install qt5-default 好了可以愉快玩耍了。
瞎折腾
下载 Qt 从 Qt5.15.0 起，对于开源用户，Qt 官方不再提供独立安装文件，且不再有 bug 修复版本（比如 Qt5.15.1），如果从官网下载，需要自己编译。虽然想试试编译，但是虚拟机刚开始开的空间太小了，还是另寻他法吧。以后有机会再来编译试试新功能。若读者有兴趣可以从官网下载源码并编译。或者参考官方的编译教程，从 GitHub 上下载。
国内有一些镜像站，提供 qt 镜像下载： 清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/archive/qt/ 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/ 北京理工大学：https://mirrors.cnnic.cn/qt/
以清华大学的镜像为例，找到archive/qt/5.14/5.14.0/qt-opensource-linux-x64-5.14.0.run，点击即可开始下载。
qt 5.15 已经不提供安装包，想要最新版本，只能下 5.14，但是 5.14.2 下载没资源，下不动，如果遇到下不动的情况换一个版本吧
安装 Qt 下载的.run文件双击是无法安装的，因为它还没有可执行的权限，需要我们赋给它执行权限，打开终端进入安装包的目录。
chmod +x filename.run chmod命令是控制用户对文件的权限修改的命令，x是可执行权限的参数。 执行以上命令后就可以直接双击安装了。
网上一些教程可以跳过登录，我没找到跳过按钮，需要注册一个账号才能继续安装。 安装目录一般选择在/opt目录下 安装的附加组件最好都选择，以免后期使用再安装麻烦。Qt Creator 肯定要装的。 安装依赖库 apt-get install g++apt-get install libgl1-mesa-devapt-get install libqt4-devapt-get install build-essential # Build Essential，它是一个元软件包，可让您在Ubuntu中安装和使用c ++工具。sudo apt install qt5-default # 如果要将Qt 5用作默认的Qt Creator版本需要安装，否则会报 qmake: could not find a Qt installation of &amp;#39;&amp;#39;的错误 使用 Qt Creator 创建第一个程序 使用 Qt Creator 创建 首先我们先创建一个不带窗口的 HelloWorld 程序，测试安装是否成功，打开 Qt Creator-文件 - 新建文件或项目，选择 Non-Qt Project-Plain C++ Application。 接下来就设置项目名等，一直下一步。完成后就可以在编辑器看到如下 点击左下角运行按钮就可以得到如下： 再创建一个带窗口的 HelloWorld，在选择模板时选择 Application-Qt Widgets Application。一路点下一步就可以完成创建，运行后就可得到一个灰白的 HelloWorld 窗口。</description>
    </item>
    <item>
      <title>QEMU 文档</title>
      <link>http://localhost:8888/posts/qemu%E6%96%87%E6%A1%A3/</link>
      <pubDate>Tue, 27 Jul 2021 11:12:01 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%96%87%E6%A1%A3/</guid>
      <description>调用文档 qemu-system-x86_64 [options] [disk_image]disk_image是 IDE 硬盘 0 的原始硬盘映像。某些目标不需要磁盘映像。
标准参数 Standard options -h 功能 显示帮助信息并退出
子参数
调用实例
qemu-system-riscv32 -h -version 功能 显示 qemu 版本信息并退出
子参数
调用实例
qemu-system-riscv32 -version -machine [type=]name[,prop=value[,...]] 功能 通过名称选择模拟器。使用 -machine help 可以查看可用的模拟器。 对于支持跨版本实时迁移兼容性的架构，每个版本都会引入一个新的版本化模拟器类型。例如，2.8.0 版本为 x86_64/i686 架构引入了“pc-i440fx-2.8”和“pc-q35-2.8”。
子参数 为了允许用户从 QEMU 2.8.0 版实时迁移到 QEMU 2.9.0 版，2.9.0 版也必须支持“pc-i440fx-2.8”和“pc-q35-2.8”机器。为了允许用户在升级时实时迁移 VMs 跳过多个中间版本，QEMU 的新版本将支持多个以前版本的机器类型。 支持的机器属性有：
accel=accels1[:accels2[:...]] This is used to enable an accelerator. Depending on the target architecture, kvm, xen, hax, hvf, nvmm, whpx or tcg can be available.</description>
    </item>
    <item>
      <title>Git 踩坑记录</title>
      <link>http://localhost:8888/posts/git%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 23 Jul 2021 11:55:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/git%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</guid>
      <description>创建仓库时没有加入 gitignore 文件，上传了不需要的文件，后添加了 gitignore 文件如何同步远程与本地的文件（自动删除不需要的文件） # 注意有个点“.” 取消版本控制 git rm -r --cached . 重新添加 git add -A 重新提交 git commit -m &amp;#34;update .gitignore&amp;#34; Git rm 和 rm &amp;ndash;cached 区别 rm ：当需要删除暂存区或分支上的文件，同时工作区不需要这个文件
rm --cached：当需要删除暂存区或分支上的文件，同时工作区需要这个文件，但是不需要被版本控制。就是本地需要保留，但是远程不保留
推送空文件夹到远程仓库 在需要推送的空文件下创建&amp;quot;.gitkeep&amp;quot;文件 在&amp;quot;.gitignore&amp;quot;文件中编写规则 !.gitkeep
克隆指定分支代码 git clone -b master https://github.com/Dunky-Z/Dunky-Z.github.io.git master就是分支名</description>
    </item>
    <item>
      <title>QEMU 初识</title>
      <link>http://localhost:8888/posts/qemu%E5%88%9D%E8%AF%86/</link>
      <pubDate>Fri, 23 Jul 2021 11:54:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%88%9D%E8%AF%86/</guid>
      <description>简介 QEMU 是一款开源的模拟器及虚拟机监管器 (Virtual Machine Monitor, VMM)。QEMU 主要提供两种功能给用户使用。一是作为用户态模拟器，利用动态代码翻译机制来执行不同于主机架构的代码。二是作为虚拟机监管器，模拟全系统，利用其他 VMM(Xen, KVM, etc) 来使用硬件提供的虚拟化支持，创建接近于主机性能的虚拟机。
安装 使用包管理安装 sudo apt-get install qemu 使用源码安装 wget wget https://download.qemu.org/qemu-6.1.0-rc3.tar.xztar xvJf qemu-6.1.0-rc3.tar.xzcd qemu-6.1.0-rc3 安装相关库 apt-get install libglib2.0-devapt-get install ninja-buildapt install g++apt install libpixman-1-devapt install libsdl2-dev -y 配置 通过./configure --help 的查看编译时的选项，--target-list选项为可选的模拟器，默认全选。 --target-list 中的 xxx-soft 和 xxx-linux-user 分别指系统模拟器和应用程序模拟器，生成的二进制文件名字为qemu-system-xxx和 qemu-xxx 本文使用如下配置：
./configure --prefix=XXX --enable-debug --target-list=riscv32-softmmu,riscv32-linux-user,riscv64-linux-user,riscv64-softmmu --enable-kvm# --prefix 选项设置qemu的安装位置绝对路径，之后若要卸载删除qemu只要删除该文件夹即可，--enable-kvm开启kvm# config完，可以在指定的qemu安装文件夹下面找到config-host.mak文件，# 该文件记录着qemu配置的选项，可以和自己设置的进行对比，确保配置和自己已知 接着进行编译
make -j8 直接make会很慢，第一次编译时默认安装说有模拟器，编译了三四个小时。加上-j8可以进行多线程编译</description>
    </item>
    <item>
      <title>什么是驱动，驱动的作用又是什么？</title>
      <link>http://localhost:8888/posts/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A9%B1%E5%8A%A8%E9%A9%B1%E5%8A%A8%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88/</link>
      <pubDate>Wed, 21 Jul 2021 15:02:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A9%B1%E5%8A%A8%E9%A9%B1%E5%8A%A8%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88/</guid>
      <description>任何一个计算机系统的运行都是系统中软硬件协作的结果，没有硬件的软件是空中楼阁，而没有软件的硬件则只是一堆废铁。&amp;ndash;天朗 - 星空
硬件是底层基础，所有软件代码的运行平台，相对固定不易改变，而软件是具体的应用，它灵活多变，可以应对用户的不同需求。
为尽可能快速地完成设计，应用软件工程师不想也不必关心硬件，而硬件工程师也难有足够的闲暇和能力来顾忌软件。譬如，应用软件工程师在调用套接字发送和接收数据包的时候，不必关心网卡上的寄存器、存储空间、I/O 端口、片选以及其他任何硬件层面的操作调度；在使用printf()函数输出信息的时候，他不用知道底层究竟是怎样把相应的信息输出到屏幕或者串口的具体硬件过程，需要的只是出现相应的显示效果。
也就是说，应用软件工程师需要看到一个没有硬件的纯粹的软件世界，硬件必须被透明地呈现给他们。谁来实现硬件对应用软件工程师的隐形？这个艰巨的任务就落在了驱动工程师的头上。
对设备驱动最通俗的解释就是“驱使硬件设备行动” 。设备驱动与底层硬件直接打交道，按照硬件设备的具体工作方式读写设备寄存器，完成设备的轮询、中断处理、DMA 通信，进行物理内存向虚拟内存的映射，最终使通信设备能够收发数据，使显示设备能够显示文字和画面，使存储设备能够记录文件和数据。</description>
    </item>
    <item>
      <title>Hexo 搭建 GitHub 博客如何添加 README 文件</title>
      <link>http://localhost:8888/posts/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0readme%E6%96%87%E4%BB%B6/</link>
      <pubDate>Wed, 21 Jul 2021 12:14:46 +0000</pubDate>
      <guid>http://localhost:8888/posts/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0readme%E6%96%87%E4%BB%B6/</guid>
      <description>刚开始搭建的时候并没有为仓库添加 Readme 文件，但是后期添加也不能直接在仓库里直接添加，因为每次部署都会被自动删除。 添加方法：
在博客根目录的source文件夹下新建README.md文件 在根目录的_config.yml文件中搜索skip_render，并做如下更改 skip_render: README.md 因为在每次hexo g时候，README 文件都会被自动渲染为 HTML 文件，所以在配置文件中告诉渲染器跳过这个文件不要渲染它。</description>
    </item>
    <item>
      <title>QEMU 学习记录</title>
      <link>http://localhost:8888/posts/qemu%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 20 Jul 2021 16:51:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>QEMU 学习记录 什么是 KVM？ 基于内核的虚拟机 Kernel-based Virtual Machine（KVM）是一种内建于 Linux 中的开源虚拟化技术。具体而言，KVM 可帮助用户将 Linux 转变为虚拟机监控程序，使主机计算机能够运行多个隔离的虚拟环境，即虚拟客户机或虚拟机（VM）。
什么是 QEMU？ Qemu 是一个完整的可以单独运行的软件，它可以用来模拟不同架构的机器，非常灵活和可移植。它主要通过一个特殊的&amp;rsquo;重编译器&amp;rsquo;将为特定处理器编写二进制代码转换为另一种。
KVM 与 QEMU 的关系 KVM 是 Linux 的一个模块。可以用modprobe去加载 KVM 模块。加载了模块后，才能进一步通过其他工具创建虚拟机。但仅有 KVM 模块是 远远不够的，因为用户无法直接控制内核模块去作事情：还必须有一个用户空间的工具才行。这个用户空间的工具，开发者选择了已经成型的开源虚拟化软件 QEMU。KVM 使用了 QEMU 的一部分，并稍加改造，就成了可控制 KVM 的用户空间工具了。所以你会看到，官方提供的 KVM 下载有两 大部分三个文件，分别是 KVM 模块、QEMU 工具以及二者的合集。也就是说，你可以只升级 KVM 模块，也可以只升级 QEMU 工具。
QEMU 用户模式与系统模式 QEMU 属于应用层的仿真程序，它支持两种操作模式：用户模式模拟和系统模式模拟。
用户模式仿真 利用动态代码翻译机制，可以在当前 CPU 上执行被编译为支持其他 CPU 的程序，如可以在 x86 机器上执行一个 ARM 二进制可执行程序。（执行主机 CPU 指令的动态翻译并相应地转换 Linux 系统调用）。 系统模式仿真 利用其它 VMM(Xen, KVM) 来使用硬件提供的虚拟化支持，创建接近于主机性能的全功能虚拟机，包括处理器和配套的外围设备（磁盘，以太网等）。 用户模式 支持的 CPU：x86 (32 and 64 bit), PowerPC (32 and 64 bit), ARM, MIPS (32 bit only), Sparc (32 and 64 bit), Alpha, ColdFire(m68k), CRISv32 和 MicroBlaze 下列操作系统支持 QEMU 的用户模式模拟：</description>
    </item>
    <item>
      <title>ZH-Unix 是什么，为什么重要？</title>
      <link>http://localhost:8888/posts/zh-unix%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</link>
      <pubDate>Tue, 20 Jul 2021 15:44:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-unix%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</guid>
      <description>Unix 是什么，为什么重要？ Author：CHRIS HOFFMAN 译：What Is Unix, and Why Does It Matter?
大多数操作系统都可以分为两大类。除了微软基于 Windows NT 的操作系统之外，几乎所有其他系统的祖宗都是 Unix。
Linux、Mac OS X、Android、iOS、Chrome OS、PlayStation 4 上使用的 Orbis 操作系统，无论路由器上运行的是什么固件——所有这些操作系统通常都被称为“类 Unix”操作系统。
Unix 的设计延续至今 19 世纪中后期 Unix 在贝尔实验室中被开发出来。最初版的 Unix 有许多重要的设计特性至今仍然在使用。
“Unix 哲学”之一就是，创建小型、模块化的程序，一个程序只做一件事并把它做好。如果你经常使用 Linux 终端，那么你应该对此很熟悉——系统提供了许多实用程序，这些程序可以通过管道和其他功能以不同方式组合以执行更复杂的任务。甚至图形程序也可能在后台调用更简单的实用程序来完成复杂的工作。这也使得创建 shell 脚本变得容易，将简单的工具串在一起来完成复杂的事情。
Unix 有一个程序之间通信用的单一文件系统。这就是为什么在 Linux 上“一切都是文件” ——包括硬件设备和提供系统信息或其他数据的特殊文件。这也是为什么只有 Windows 有驱动器号（C、D、E 盘）的原因，它是从 DOS 继承的——在其他操作系统上，系统上的每个文件都是单个目录层次结构的一部分。
追寻 Unix 的后代 Unix 及其后代的历史错综复杂，简化起见，我们大致将 Unix 的后代分为两类。
一类 Unix 后代是在学术界发展起来的。第一个是 BSD（BerkeleySoftwareDistribution），一个开源、类 Unix 操作系统。BSD 通过 FreeBSD、NetBSD 和 OpenBSD 延续至今。NeXTStep 也是基于最初的 BSD 开发的，Apple 的 Mac OS X 是基于 NeXTStep 开发出来的，而 iOS 则基于 Mac OS X。还有一些操作系统，包括 PlayStation 4 上使用的 Orbis OS，都是从 BSD 操作系统衍生而来的。</description>
    </item>
    <item>
      <title>Hexo 实时更新预览</title>
      <link>http://localhost:8888/posts/hexo%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0%E9%A2%84%E8%A7%88/</link>
      <pubDate>Tue, 20 Jul 2021 14:32:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/hexo%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0%E9%A2%84%E8%A7%88/</guid>
      <description>在项目目录下安装 hexo-browsersync 插件
npm install hexo-browsersync --save hexo s启动服务后，每次保存 Markdown 文件都会实时更新页面。</description>
    </item>
    <item>
      <title>Hexo 和 GitHub 搭建博客以及更换电脑同步博客</title>
      <link>http://localhost:8888/posts/hexo%E5%92%8Cgithub%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E4%BB%A5%E5%8F%8A%E6%9B%B4%E6%8D%A2%E7%94%B5%E8%84%91%E5%90%8C%E6%AD%A5%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Tue, 20 Jul 2021 12:04:37 +0000</pubDate>
      <guid>http://localhost:8888/posts/hexo%E5%92%8Cgithub%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E4%BB%A5%E5%8F%8A%E6%9B%B4%E6%8D%A2%E7%94%B5%E8%84%91%E5%90%8C%E6%AD%A5%E5%8D%9A%E5%AE%A2/</guid>
      <description>只要有source文件夹下所有源文件就可以重新部署，按照正常的搭建 Hexo 环境开始搭建，搭建好以后将source文件夹替换即可，需要应用主题就下载主题然后替换。
注意：
主题更换需要更改_config_yml文件 _config_yml文件中的部署配置，branch:master就是每次hexo d操作推送的分支。而在命令行每次git push推送的分支是设置的默认分支hexo deploy:type: gitrepository: https://github.com/Dunky-Z/Dunky-Z.github.io.gitbranch: master 利用 Hexo 在多台电脑上提交和更新 GitHub pages 博客 </description>
    </item>
    <item>
      <title>HelloWorld</title>
      <link>http://localhost:8888/posts/helloworld/</link>
      <pubDate>Sun, 23 Aug 2020 09:09:13 +0000</pubDate>
      <guid>http://localhost:8888/posts/helloworld/</guid>
      <description>这是博客的第一篇文章</description>
    </item>
    <item>
      <title>QEMU Decodetree详解</title>
      <link>http://localhost:8888/posts/qemu-decodetree%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu-decodetree%E8%AF%A6%E8%A7%A3/</guid>
      <description>QEMU 在 decode 指令的时候，需要调用各平台所定义的 instruction decoders 来解析指令。如在 ARM 平台下，就定义了：disas_arm_insn()、disas_thumb_insn() 及 disas_thumb2_insn() 等来分别负责 ARM 32-bits 指令、ARM Thumb 指令及 ARM Thumb2 指令的解析。
而 Decodetree 则是由 Bastian Koppelmann 于 2017 年在 移植 RISC-V QEMU 的时候所提出来的机制 (详见：讨论邮件1、讨论邮件2)。提出该机制主要是因为过往的 instruction decoders (如：ARM) 都是采用一堆 switch-case 来做判断。不仅难阅读，也难以维护。
因此 Bastian Koppelmann 就提出了 Decodetree 的机制，开发者只需要通过 Decodetree 的语法定义各个指令的格式，便可交由 Decodetree 来动态生成对应包含 switch-case 的 instruction decoder .c 文档。
Decodetree 特别适合像 RISC-V 这种具有固定指令格式的 ISA。
因为各字段都在固定的位置，(如 RISC-V 的 opcode 都是固定在 bits[6..0] 的位置)。 Decodetree 其实是由 Python script (.</description>
    </item>
  </channel>
</rss>
