<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>计算机组成原理-存储与 IO 系统 | 夜云泊</title>
<meta name=keywords content="计算机组成原理,DMA,页表,虚拟内存,缓存,Cache,总线"><meta name=description content="存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆"><meta name=author content="Nic"><link rel=canonical href=https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/><link crossorigin=anonymous href=/assets/css/stylesheet.ac74316738ec9be850f385073ae1b0b3c442da15f0a57cb0b89434683d014d90.css integrity="sha256-rHQxZzjsm+hQ84UHOuGws8RC2hXwpXywuJQ0aD0BTZA=" rel="preload stylesheet" as=style><link rel=icon href=https://lifeislife.cn/assets/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lifeislife.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lifeislife.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://lifeislife.cn/apple-touch-icon.png><link rel=mask-icon href=https://lifeislife.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Noto+Sans+SC:wght@100..900&display=swap" rel=stylesheet><script async src="https://www.googletagmanager.com/gtag/js?id=G-PS8L2EEEPR"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PS8L2EEEPR")}</script><meta property="og:title" content="计算机组成原理-存储与 IO 系统"><meta property="og:description" content="存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆"><meta property="og:type" content="article"><meta property="og:url" content="https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-08T10:48:23+00:00"><meta property="article:modified_time" content="2022-05-08T10:48:23+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="计算机组成原理-存储与 IO 系统"><meta name=twitter:description content="存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lifeislife.cn/posts/"},{"@type":"ListItem","position":2,"name":"计算机组成原理-存储与 IO 系统","item":"https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"计算机组成原理-存储与 IO 系统","name":"计算机组成原理-存储与 IO 系统","description":"存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆","keywords":["计算机组成原理","DMA","页表","虚拟内存","缓存","Cache","总线"],"articleBody":"存储器 存储器的层次结构 SRAM（Static Random-Access Memory，静态随机存取存储器） CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆。它用的是 SRAM 芯片。\nSRAM 的“静态”的意思是，只要处于通电状态，里面的数据就保持存在，一旦断电，数据就会丢失。SRAM 里 1bit 数据需要 6-8 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间，能够存的数据有限。因为其电路简单，访问速度非常快。\n在 CPU 里，通常会有 L1、L2、L3 这样三层高速缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，通常分成指令缓存和数据缓存，分开存放 CPU 使用的指令和数据。\nL2 的 Cache 同样是每个 CPU 核心都有的，不过它往往不在 CPU 核心的内部。所以，L2 Cache 的访问速度会比 L1 稍微慢一些。而 L3Cache，则通常是多个 CPU 核心共用的，尺寸会更大一些，访问速度自然也就更慢一些。\n你可以把 CPU 中的 L1Cache 理解为我们的短期记忆，把 L2/L3Cache 理解成长期记忆，把内存当成我们拥有的书架或者书桌。当我们自己记忆中没有资料的时候，可以从书桌或者书架上拿书来翻阅。这个过程中就相当于，数据从内存中加载到 CPU 的寄存器和 Cache 中，然后通过“大脑”，也就是 CPU，进行处理和运算。\nDRAM（Dynamic Random Access Memory，动态随机存取存储器） 内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM 的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。\nDRAM 被称为“动态”存储器，是因为 DRAM 需要靠不断地“刷新”，才能保持数据被存储起来。DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多，也就是存储的“密度”更大。但是，因为数据是存储在电容里的，电容会不断漏电，所以需要定时刷新充电，才能保持数据不丢失。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。\n从 Cache、内存，到 SSD 和 HDD 硬盘，一台现代计算机中，就用上了所有这些存储器设备。其中，容量越小的设备速度越快，而且，CPU 并不是直接和每一种存储器设备打交道，而是每一种存储器设备，只和它相邻的存储设备打交道。比如，CPUCache 是从内存里加载而来的，或者需要写回内存，并不会直接写回数据到硬盘，也不会直接从硬盘加载数据到 CPUCache 中，而是先加载到内存，再从内存加载到 Cache 中。\n这样，各个存储器只和相邻的一层存储器打交道，并且随着一层层向下，存储器的容量逐层增大，访问速度逐层变慢，而单位存储成本也逐层下降，也就构成了我们日常所说的存储器层次结构。\n缓存 CPU cache 高速缓存 缓存不是 CPU 的专属功能，可以把它当成一种策略，任何时候想要增加数据传输性能，都可以通过加一层缓存试试。\n存储器层次结构的中心思想是，对于每个$k$，位于$k$层的更快更小的存储设备作为位于$k+1$层的更大更慢的存储设备的缓存。下图展示了存储器层次结构中缓存的一般性概念。\n数据总是以块block为单位，在层与层之间来回复制。\n说回高速缓存，按照摩尔定律，CPU 的访问速度每 18 个月便会翻一翻，相当于每年增长 60%。内存的访问速度虽然不断增长，却远没有那么快，每年只增长 7% 左右。这样就导致 CPU 性能和内存访问的差距不断拉大。为了弥补两者之间差异，现代 CPU 引入了高速缓存。\nCPU 的读（load）实质上就是从缓存中读取数据到寄存器（register）里，在多级缓存的架构中，如果缓存中找不到数据（Cache miss），就会层层读取二级缓存三级缓存，一旦所有的缓存里都找不到对应的数据，就要去内存里寻址了。寻址到的数据首先放到寄存器里，其副本会驻留到 CPU 的缓存中。\nCPU 的写（store）也是针对缓存作写入。并不会直接和内存打交道，而是通过某种机制实现数据从缓存到内存的写回（write back）。\n缓存到底如何与 CPU 和主存数据交换的？CPU 如何从缓存中读写数据的？缓存中没有读的数据，或者缓存写满了怎么办？我们先从 CPU 如何读取数据说起。\n缓存读取 CPU 发起一个读取请求后，返回的结果会有如下几种情况：\n缓存命中 (cache hit) 要读取的数据刚好在缓存中，叫做缓存命中。 缓存不命中 (cache miss) 发送缓存不命中，缓存就得执行一直放置策略(placement policy)，比如 LRU。来决定从主存中取出的数据放到哪里。 强制性不命中(compulsory miss)/冷不命中(cold miss)：缓存中没有要读取的数据，需要从主存读取数据，并将数据放入缓存。 冲突不命中(conflict miss)：缓存中有要读的数据，在采取放置策略时，从主存中取数据放到缓存时发生了冲突，这叫做冲突不命中。 高速缓存存储器组织结构 整个 Cache 被划分为 1 个或多个组 (Set)，$S$ 表示组的个数。每个组包含 1 个或多个缓存行(Cache line)，$E$ 表示一个组中缓存行的行数。每个缓存行由三部分组成：有效位(valid)，标记位（tag），数据块（cache block）。\n有效位：该位等于 1，表示这个行数据有效。 标记位：唯一的标识了存储在高速缓存中的块，标识目标数据是否存在当前的缓存行中。 数据块：一部分内存数据的副本。 Cache 的结构可以由元组$(S,E,B,m)$表示。不包括有效位和标记位。Cache 的大小为 $C=S \\times E \\times B$.\n接下来看看 Cache 是如何工作的，当 CPU 执行数据加载指令，从内存地址 A 读取数据时，根据存储器层次原理，如果 Cache 中保存着目标数据的副本，那么就立即将数据返回给 CPU。那么 Cache 如何知道自己保存了目标数据的副本呢？\n假设目标地址的数据长度为$m$位，这个地址被参数 $S$ 和 $B$ 分成了三个字段：\n首先通过长度为$s$的组索引，确定目标数据保存在哪一个组 (Set) 中，其次通过长度为$t$的标记，确定在哪一行，需要注意的是此时有效位必须等于 1，最后根据长度为$b$的块偏移，来确定目标数据在数据块中的确切位置。\nQ：既然读取 Cache 第一步是组选择，为什么不用高位作为组索引，而使用中间的为作为组索引？ A：如果使用了高位作索引，那么一些连续的内存块就会映射到相同的高速缓存块。如图前四个块映射到第一个缓存组，第二个四个块映射到第二个组，依次类推。如果一个程序有良好的空间局部性，顺序扫描一个数组的元素，那么在任何时候，缓存中都只保存在一个块大小的数组内容。这样对缓存的使用率很低。相比而言，如果使用中间的位作为组索引，那么相邻的块总是映射到不同的组，图中的情况能够存放整个大小的数组片。 直接映射高速缓存 Direct Mapped Cache 根据每个组的缓存行数 $E$ 的不同，Cache 被分为不同的类。每个组只有一行$E=1$的高速缓存被称为直接映射高速缓存(direct-mapped cache)。\n当一条加载指令指示 CPU 从主存地址 A 中读取一个字 w 时，会将该主存地址 A 发送到高速缓存中，则高速缓存会根据组选择，行匹配和字抽取三步来判断地址 A 是否命中。\n组选择(set selection)：根据组索引值来确定属于哪一个组，如图中索引长度为 5 位，可以检索 32 个组 ($2^5=32$)。当$s=0$时，此时组选择的结果为set 0，当$s=1$时，此时组选择的结果为set 1。\n行匹配 (line match)：首先看缓存行的有效位，此时有效位为 1，表示当前数据有效。然后对比缓存行的标记0110与地址中的标记0110是否相等，如果相等，则表示目标数据在当前的缓存行中（缓存命中）。如果不一致或者有效位为 0，则表示目标数据不在当前的缓存行中（缓存不命中）。如果命中，就可以进行下一步字抽取。\n字抽取 (word extraction)：根据偏移量$b$确定目标数据的确切位置，通俗来说就是从数据块的什么位置开始抽取位置。如当偏移块等于100时，表示目标数据起始地址位于字节 4 处。\n下面通过一个例子来解释清除这个过程。假设我们有一个直接映射高速缓存，描述为$(S,E,B,m) = (4,1,2,4)$。换句话说，高速缓存有 4 个组，每个组 1 行，每个数据块 2 个字节，地址长度为 4 位。\n从图中可以看出，8 个内存块，但只有 4 个高速缓存组，所以会有多个块映射到同一个高速缓存组中。例如，块 0 和块 4 都会被映射到组 0。\n下面我们来模拟当 CPU 执行一系列读的时候，高速缓存的执行情况，我们假设每次 CPU 读 1 个字节的字。\n读地址 0(0000) 的字： 读地址 1(0001) 的字： 读地址 13(1101) 的字： 读地址 8(1000) 的字： 读地址 0(0000) 的字： 组相联高速缓存 Set Associative Cache 由于直接映射高速缓存的组中只有一行，所以容易发生冲突不命中。组相联高速缓存 (Set associative cache) 运行有多行缓存行。但是缓存行最大不能超过 $C/B$。\n如图一个组中包含了两行缓存行，这种我们称为 2 路相联高速缓存。\n组选择：与直接映射高速缓存的组选择过程一样。\n行匹配：因为一个组有多行，所以需要遍历所有行，找到一个有效位为 1，并且标记为与地址中的标记位相匹配的一行。如果找到了，表示缓存命中。\n字抽取：根据偏移量$b$确定目标数据的确切位置，通俗来说就是从数据块的什么位置开始抽取位置。如当偏移块等于100时，表示目标数据起始地址位于字节 4 处。\n如果不命中，那么就需要从主存中取出需要的数据块，但是将数据块放在哪一行缓存行呢？如果存在空行 ($valid=0$)，那就放到空行里。如果没有空行，就得选择一个非空行来替换，同时希望 CPU 不会很快引用这个被替换的行。这里介绍几个替换策略。\n最简单的方式就是随机选择一行来替换，其他复杂的方式就是利用局部性原理，使得接下来 CPU 引用替换的行概率最小。如\n缓存一致性协议 MESI 为什么需要缓存一致 目前主流电脑的 CPU 都是多核心的，多核心的有点就是在不能提升 CPU 主频后，通过增加核心来提升 CPU 吞吐量。每个核心都有自己的 L1 Cache 和 L2 Cache，只是共用 L3 Cache 和主内存。每个核心操作是独立的，每个核心的 Cache 就不是同步更新的，这样就会带来缓存一致性（Cache Coherence）的问题。\n举个例子，如图： 有 2 个 CPU，主内存里有个变量x=0。CPU A 中有个需要将变量x加1。CPU A 就将变量x加载到自己的缓存中，然后将变量x加1。因为此时 CPU A 还未将缓存数据写回主内存，CPU B 再读取变量x时，变量x的值依然是0。\n这里的问题就是所谓的缓存一致性问题，因为 CPU A 的缓存与 CPU B 的缓存是不一致的。\n如何解决缓存一致性问题 通过在总线加 LOCK 锁的方式 在锁住总线上加一个 LOCK 标识，CPU A 进行读写操作时，锁住总线，其他 CPU 此时无法进行内存读写操作，只有等解锁了才能进行操作。\n该方式因为锁住了整个总线，所以效率低。\n缓存一致性协议 MESI 该方式对单个缓存行的数据进行加锁，不会影响到内存其他数据的读写。\n在学习 MESI 协议之前，简单了解一下总线嗅探机制（Bus Snooping）。要对自己的缓存加锁，需要通知其他 CPU，多个 CPU 核心之间的数据传播问题。最常见的一种解决方案就是总线嗅探。\n这个策略，本质上就是把所有的读写请求都通过总线广播给所有的 CPU 核心，然后让各个核心去“嗅探”这些请求，再根据本地的情况进行响应。MESI 就是基于总线嗅探机制的缓存一致性协议。\nMESI 协议的由来是对 Cache Line 的四个不同的标记，分别是：\n状态 状态 描述 监听任务 Modified 已修改 该 Cache Line 有效，数据被修改了，和内存中的数据不一致，数据只存在于本 Cache 中 Cache Line 必须时刻监听所有试图读该 Cache Line 相对于主存的操作，这种操作必须在缓存将该 Cache Line 写回主存并将状态改为 S 状态之前，被延迟执行 Exclusive 独享，互斥 该 Cache Line 有效，数据和内存中的数据一直，数据只存在于本 Cache Cache Line 必须监听其他缓存读主存中该 Cache Line 的操作，一旦有这种操作，该 Cache Line 需要改为 S 状态 Shared 共享的 该 Cache Line 有效，数据和内存中的数据一直，数据存在于很多个 Cache 中 Cache Line 必须监听其他 Cache Line 使该 Cache Line 无效或者独享该 Cache Line 的请求，并将 Cache Line 改为 I 状态 Invalid 无效的 该 Cache Line 无效 无 整个 MESI 的状态，可以用一个有限状态机来表示它的状态流转。需要注意的是，对于不同状态触发的事件操作，可能来自于当前 CPU 核心，也可能来自总线里其他 CPU 核心广播出来的信号。我把各个状态之间的流转用表格总结了一下：\n当前状态 事件 行为 下个状态 M Local Read 从 Cache 中读，状态不变 M M Local Write 修改 cache 数据，状态不变 M M Remote Read 这行数据被写到内存中，使其他核能使用到最新数据，状态变为 S S M Remote Write 这行数据被写入内存中，其他核可以获取到最新数据，由于其他 CPU 修改该条数据，则本地 Cache 变为 I I 当前状态 事件 行为 下个状态 E Local Read 从 Cache 中读，状态不变 E E Local Write 修改数据，状态改为 M M E Remote Read 数据和其他 CPU 共享，变为 S S E Remote Write 数据被修改，本地缓存失效，变为 I I 当前状态 事件 行为 下个状态 S Local Read 从 Cache 中读，状态不变 S S Local Write 修改数据，状态改为 M，其他 CPU 的 Cache Line 状态改为 I M S Remote Read 数据和其他 CPU 共享，状态不变 S S Remote Write 数据被修改，本地缓存失效，变为 I I 当前状态 事件 行为 下个状态 I Local Read 1. 如果其他 CPU 没有这份数据，直接从内存中加载数据，状态变为 E；\n2. 如果其他 CPU 有这个数据，且 Cache Line 状态为 M，则先把 Cache Line 中的内容写回到主存。本地 Cache 再从内存中读取数据，这时两个 Cache Line 的状态都变为 S；\n3. 如果其他 Cache Line 有这份数据，并且状态为 S 或者 E，则本地 Cache Line 从主存读取数据，并将这些 Cache Line 状态改为 S E 或者 S I Local Write 1. 先从内存中读取数据，如果其他 Cache Line 中有这份数据，且状态为 M，则现将数据更新到主存再读取，将 Cache Line 状态改为 M；\n2. 如果其他 Cache Line 有这份数据，且状态为 E 或者 S，则其他 Cache Line 状态改为 I M I Remote Read 数据和其他 CPU 共享，状态不变 S I Remote Write 数据被修改，本地缓存失效，变为 I I 内存 计算机有五大组成部分，分别是：运算器、控制器、存储器、输入设备和输出设备。而内存就是其中的存储器。我们的数据和指令都需要先放到内存中，然后再被 CPU 执行。\n操作系统中程序并不能直接访问物理内存，我们的内存需要被分成固定大小的页（Page），然后再通过虚拟内存地址（Virtual Address）到物理内存地址（Physical Address）的地址转换（Address Translation），才能到达实际存放数据的物理内存位置。而我们的程序看到的内存地址，都是虚拟内存地址。那么如何进行转换的呢？\n简单页表 最简单的方式，就是建立一张虚拟内存到物理内存的映射表，在计算机里叫做页表（Page Table）。页表这个地址转换的办法，会把一个内存地址分成页号（Directory）和偏移量（Offset）两个部分，是不是似曾相识，因为在前面的高速缓存里，缓存的结构也是这样的。\n以一个 32 位地址举例，高 20 位是虚拟页号，可以从虚拟页表中找到物理页号的信息，低 12 位是偏移量，可以准确获得物理地址。 总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n把虚拟内存地址，切分成页号和偏移量的组合； 从页表里面，查询出虚拟页号，对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。 但是这样的页表有个问题，它需要记录$2^{20}$个物理页表，这个存储关系，就好比一个 $2^{20}$大小的数组。一个页号是完整的 32 位的 4 字节（Byte），这样一个页表就需要 4MB 的空间。并且每个进程都会有这样一个页表，现代电脑正常都有成百上千个进程，如果用这样的页表肯定行不通的。\n多级页表 所以，在一个实际的程序进程里面，虚拟内存占用的地址空间，通常是两段连续的空间。而不是完全散落的随机的内存地址。而多级页表，就特别适合这样的内存地址分布。\n谈一谈内存管理，虚拟内存，多级页表 - 知乎\nTLB 内存保护 - 可执行空间保护 内存保护 - 地址空间布局随机化 Address Space Layout Randomization\n总线：计算机内部的高速公路 计算机由控制器、运算器、存储器、输入设备以及输出设备五大部分组成。CPU 所代表的控制器和运算器，要和存储器，也就是我们的主内存，以及输入和输出设备进行通信。那么计算机是用什么样的方式来完成，CPU 和内存、以及外部输入输出设备的通信呢？答案就是通过总线来通信。\n计算机里有不同的硬件设备，如果设备与设备之间都单独连接，那么就需要 N*N 的连线。那么怎么降低复杂度呢？与其让各个设备之间互相单独通信，不如我们去设计一个公用的线路。CPU 想要和什么设备通信，通信的指令是什么，对应的数据是什么，都发送到这个线路上；设备要向 CPU 发送什么信息呢，也发送到这个线路上。这个线路就好像一个高速公路，各个设备和其他设备之间，不需要单独建公路，只建一条小路通向这条高速公路就好了。\n三种线路和多总线架构 首先，CPU 和内存以及高速缓存通信的总线，这里面通常有两种总线。这种方式，我们称之为双独立总线（Dual Independent Bus，缩写为 DIB）。CPU 里，有一个快速的本地总线（Local Bus），以及一个速度相对较慢的前端总线（Front-side Bus）。\n现代的 CPU 里，通常有专门的高速缓存芯片。这里的高速本地总线，就是用来和高速缓存通信的。而前端总线，则是用来和主内存以及输入输出设备通信的。有时候，我们会把本地总线也叫作后端总线（Back-sideBus），和前面的前端总线对应起来。\n除了前端总线呢，我们常常还会听到 PCI 总线、I/O 总线或者系统总线（System Bus）。看到这么多总线的名字，你是不是已经有点晕了。这些名词确实容易混为一谈。其实各种总线的命名一直都很混乱，我们不如直接来看一看 CPU 的硬件架构图。对照图来看，一切问题就都清楚了。\nCPU 里面的北桥芯片，把我们上面说的前端总线，一分为二，变成了三个总线。我们的前端总线，其实就是系统总线。CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器（I/OBridge）。这个 I/O 桥接器，一边接入了我们的内存总线，使得我们的 CPU 和内存通信；另一边呢，又接入了一个 I/O 总线，用来连接 I/O 设备。\n事实上，真实的计算机里，这个总线层面拆分得更细。根据不同的设备，还会分成独立的 PCI 总线、ISA 总线等等。 在物理层面，其实我们完全可以把总线看作一组“电线”。不过呢，这些电线之间也是有分工的，我们通常有三类线路。\n数据线（Data Bus），用来传输实际的数据信息，也就是实际上了公交车的“人”。 地址线（Address Bus），用来确定到底把数据传输到哪里去，是内存的某个位置，还是某一个 I/O 设备。这个其实就相当于拿了个纸条，写下了上面的人要下车的站点。 控制线（ControlBus），用来控制对于总线的访问。虽然我们把总线比喻成了一辆公交车。那么有人想要做公交车的时候，需要告诉公交车司机，这个就是我们的控制信号。 尽管总线减少了设备之间的耦合，也降低了系统设计的复杂度，但同时也带来了一个新问题，那就是总线不能同时给多个设备提供通信功能。\n我们的总线是很多个设备公用的，那多个设备都想要用总线，我们就需要有一个机制，去决定这种情况下，到底把总线给哪一个设备用。这个机制，就叫作总线裁决（Bus Arbitraction）\n硬盘 DMA 过去几年，计算机产业一直在为提升 I/O 设备的速度而努力，从机械硬盘 HDD 到固态硬盘 SSD，从 SATA 协议到 PCIE 协议，虽然速度都几十上百倍的增加，但是仍然不够快。因为相比于 CPU 基本都是 2GHz 的频率（每秒会有 20 亿次的操作），SSD 硬盘的 IOPS 的 2 万次操作就显得微不足道。\n如果我们对于 I/O 的操作，都是由 CPU 发出对应的指令，然后等待 I/O 设备完成操作之后返回，那 CPU 有大量的时间其实都是在等待 I/O 设备完成操作。特别是当传输的数据量比较大的时候，比如进行大文件复制，如果所有数据都要经过 CPU，实在是有点儿太浪费时间了。\n因此，计算机工程师们，就发明了DMA 技术，也就是直接内存访问（Direct Memory Access）技术，来减少 CPU 等待的时间。\n什么是 DMA 本质上，DMA 技术就是我们在主板上放一块独立的芯片。在进行内存和 I/O 设备的数据传输的时候，我们不再通过 CPU 来控制数据传输，而直接通过 DMA 控制器（DMA Controller，简称 DMAC）。这块芯片，我们可以认为它其实就是一个协处理器（Co-Processor）。\nDMAC 最有价值的地方体现在，当我们要传输的数据特别大、速度特别快，或者传输的数据特别小、速度特别慢的时候。\n比如说，我们用千兆网卡或者硬盘传输大量数据的时候，如果都用 CPU 来搬运的话，肯定忙不过来，所以可以选择 DMAC。而当数据传输很慢的时候，DMAC 可以等数据到齐了，再向 CPU 发起中断，让 CPU 去处理，而不是让 CPU 在那里忙等待。\n首先，CPU 还是作为一个主设备，向 DMAC 设备发起请求。这个请求，其实就是在 DMAC 里面修改配置寄存器。 CPU 修改 DMAC 的配置的时候，会告诉 DMAC 这样几个信息： 源地址的初始值：数据要从哪里传输过来。如果我们要从内存里面写入数据到硬盘上，那么就是要读取的数据在内存里面的地址 传输时候的地址增减方式：数据是从大的地址向小的地址传输，还是从小的地址往大的地址传输 传输的数据长度：也就是我们一共要传输多少数据 设置完这些信息之后，DMAC 就会变成一个空闲的状态（Idle）。 如果我们要从硬盘上往内存里面加载数据，这个时候，硬盘就会向 DMAC 发起一个数据传输请求。这个请求并不是通过总线，而是通过一个额外的连线。 然后，我们的 DMAC 需要再通过一个额外的连线响应这个申请。 DMAC 这个芯片，就向硬盘的接口发起要总线读的传输请求。数据就从硬盘里面，读到了 DMAC 的控制器里面。 DMAC 再向我们的内存发起总线写的数据传输请求，把数据写入到内存里面。 DMAC 会反复进行上面第 6、7 步的操作，直到 DMAC 的寄存器里面设置的数据长度传输完成。 数据传输完成之后，DMAC 重新回到第 3 步的空闲状态。 所以，整个数据传输的过程中，我们不是通过 CPU 来搬运数据，而是由 DMAC 这个芯片来搬运数据。但是 CPU 在这个过程中也是必不可少的。因为传输什么数据，从哪里传输到哪里，其实还是由 CPU 来设置的。这也是为什么，DMAC 被叫作 协处理器。\n参考资料 【硬件科普】电脑主板右下角的散热片下面究竟隐藏着什么？详解主板南桥芯片组的功能和作用_哔哩哔哩_bilibili\n","wordCount":"8628","inLanguage":"zh","datePublished":"2022-05-08T10:48:23Z","dateModified":"2022-05-08T10:48:23Z","author":{"@type":"Person","name":"Nic"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%AD%98%E5%82%A8%E4%B8%8Eio%E7%B3%BB%E7%BB%9F/"},"publisher":{"@type":"Organization","name":"夜云泊","logo":{"@type":"ImageObject","url":"https://lifeislife.cn/assets/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><script defer src=/static/fontawesome/fontawesome-all.js></script><header class=header><nav class=nav><div class=logo><a href=https://lifeislife.cn/ accesskey=h title="夜云泊 (Alt + H)">夜云泊</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://lifeislife.cn/archives/ title=归档><span>归档</span></a></li><li><a href=https://lifeislife.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://lifeislife.cn/categories/ title=分类><span>分类</span></a></li><li><a href=https://lifeislife.cn/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://www.travellings.cn/go.html title=开往><span><i class='fa-solid fa-train-subway'></i>开往</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://lifeislife.cn/>主页</a>&nbsp;»&nbsp;<a href=https://lifeislife.cn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">计算机组成原理-存储与 IO 系统</h1><div class=post-meta><span title='2022-05-08 10:48:23 +0000 UTC'>五月 8, 2022</span>&nbsp;·&nbsp;18 分钟&nbsp;·&nbsp;8628 字&nbsp;·&nbsp;Nic</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#存储器>存储器</a><ul><li><a href=#存储器的层次结构>存储器的层次结构</a></li></ul></li><li><a href=#缓存>缓存</a><ul><li><a href=#cpu-cache>CPU cache</a></li><li><a href=#高速缓存>高速缓存</a></li><li><a href=#缓存一致性协议-mesi>缓存一致性协议 MESI</a></li></ul></li><li><a href=#内存>内存</a><ul><li><a href=#简单页表>简单页表</a></li><li><a href=#多级页表>多级页表</a></li><li><a href=#tlb>TLB</a></li><li><a href=#内存保护---可执行空间保护>内存保护 - 可执行空间保护</a></li><li><a href=#内存保护---地址空间布局随机化>内存保护 - 地址空间布局随机化</a></li></ul></li><li><a href=#总线计算机内部的高速公路>总线：计算机内部的高速公路</a><ul><li><a href=#三种线路和多总线架构>三种线路和多总线架构</a></li></ul></li><li><a href=#硬盘>硬盘</a></li><li><a href=#dma>DMA</a><ul><li><a href=#什么是-dma>什么是 DMA</a></li></ul></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></details></div><div class=post-content><h2 id=存储器>存储器<a hidden class=anchor aria-hidden=true href=#存储器>#</a></h2><h3 id=存储器的层次结构>存储器的层次结构<a hidden class=anchor aria-hidden=true href=#存储器的层次结构>#</a></h3><h4 id=sramstatic-random-access-memory静态随机存取存储器>SRAM（Static Random-Access Memory，静态随机存取存储器）<a hidden class=anchor aria-hidden=true href=#sramstatic-random-access-memory静态随机存取存储器>#</a></h4><p>CPU 如果形容成人的大脑的话，那么 CPU Cache (高速缓存) 就好比人的记忆。它用的是 SRAM 芯片。</p><p>SRAM 的“静态”的意思是，只要处于通电状态，里面的数据就保持存在，一旦断电，数据就会丢失。SRAM 里 1bit 数据需要 6-8 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间，能够存的数据有限。因为其电路简单，访问速度非常快。</p><p>在 CPU 里，通常会有 L1、L2、L3 这样三层高速缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，通常分成指令缓存和数据缓存，分开存放 CPU 使用的指令和数据。</p><p>L2 的 Cache 同样是每个 CPU 核心都有的，不过它往往不在 CPU 核心的内部。所以，L2 Cache 的访问速度会比 L1 稍微慢一些。而 L3Cache，则通常是多个 CPU 核心共用的，尺寸会更大一些，访问速度自然也就更慢一些。</p><p>你可以把 CPU 中的 L1Cache 理解为我们的短期记忆，把 L2/L3Cache 理解成长期记忆，把内存当成我们拥有的书架或者书桌。当我们自己记忆中没有资料的时候，可以从书桌或者书架上拿书来翻阅。这个过程中就相当于，数据从内存中加载到 CPU 的寄存器和 Cache 中，然后通过“大脑”，也就是 CPU，进行处理和运算。</p><h4 id=dramdynamic-random-access-memory动态随机存取存储器>DRAM（Dynamic Random Access Memory，动态随机存取存储器）<a hidden class=anchor aria-hidden=true href=#dramdynamic-random-access-memory动态随机存取存储器>#</a></h4><p>内存用的芯片和 Cache 有所不同，它用的是一种叫作 DRAM 的芯片，比起 SRAM 来说，它的密度更高，有更大的容量，而且它也比 SRAM 芯片便宜不少。</p><p>DRAM 被称为“动态”存储器，是因为 DRAM 需要靠不断地“刷新”，才能保持数据被存储起来。DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多，也就是存储的“密度”更大。但是，因为数据是存储在电容里的，电容会不断漏电，所以需要定时刷新充电，才能保持数据不丢失。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081652018.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081652018.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081652018.png alt></a></div></p><p>从 Cache、内存，到 SSD 和 HDD 硬盘，一台现代计算机中，就用上了所有这些存储器设备。其中，容量越小的设备速度越快，而且，CPU 并不是直接和每一种存储器设备打交道，而是每一种存储器设备，只和它相邻的存储设备打交道。比如，CPUCache 是从内存里加载而来的，或者需要写回内存，并不会直接写回数据到硬盘，也不会直接从硬盘加载数据到 CPUCache 中，而是先加载到内存，再从内存加载到 Cache 中。</p><p>这样，各个存储器只和相邻的一层存储器打交道，并且随着一层层向下，存储器的容量逐层增大，访问速度逐层变慢，而单位存储成本也逐层下降，也就构成了我们日常所说的存储器层次结构。</p><h2 id=缓存>缓存<a hidden class=anchor aria-hidden=true href=#缓存>#</a></h2><h3 id=cpu-cache>CPU cache<a hidden class=anchor aria-hidden=true href=#cpu-cache>#</a></h3><h3 id=高速缓存>高速缓存<a hidden class=anchor aria-hidden=true href=#高速缓存>#</a></h3><p>缓存不是 CPU 的专属功能，可以把它当成一种策略，任何时候想要增加数据传输性能，都可以通过加一层缓存试试。</p><p>存储器层次结构的中心思想是，对于每个$k$，位于$k$层的更快更小的存储设备作为位于$k+1$层的更大更慢的存储设备的缓存。<a href=#%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E4%B8%AD%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%BC%93%E5%AD%98%E5%8E%9F%E7%90%86>下图</a>展示了存储器层次结构中缓存的一般性概念。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711145943.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711145943.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711145943.png alt></a></div></p><div id=存储器层次结构中基本的缓存原理></div><p>数据总是以块<code>block</code>为单位，在层与层之间来回复制。</p><p>说回高速缓存，按照摩尔定律，CPU 的访问速度每 18 个月便会翻一翻，相当于每年增长 60%。内存的访问速度虽然不断增长，却远没有那么快，每年只增长 7% 左右。这样就导致 CPU 性能和内存访问的差距不断拉大。为了弥补两者之间差异，现代 CPU 引入了<strong>高速缓存</strong>。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220708092012.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220708092012.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220708092012.png alt></a></div></p><p>CPU 的读（load）实质上就是从缓存中读取数据到寄存器（register）里，在多级缓存的架构中，如果缓存中找不到数据（Cache miss），就会层层读取二级缓存三级缓存，一旦所有的缓存里都找不到对应的数据，就要去内存里寻址了。寻址到的数据首先放到寄存器里，其副本会驻留到 CPU 的缓存中。</p><p>CPU 的写（store）也是针对缓存作写入。并不会直接和内存打交道，而是通过某种机制实现数据从缓存到内存的写回（write back）。</p><p>缓存到底如何与 CPU 和主存数据交换的？CPU 如何从缓存中读写数据的？缓存中没有读的数据，或者缓存写满了怎么办？我们先从 CPU 如何读取数据说起。</p><h4 id=缓存读取>缓存读取<a hidden class=anchor aria-hidden=true href=#缓存读取>#</a></h4><p>CPU 发起一个读取请求后，返回的结果会有如下几种情况：</p><ul><li>缓存命中 (cache hit)
要读取的数据刚好在缓存中，叫做<strong>缓存命中</strong>。</li><li>缓存不命中 (cache miss)
发送缓存不命中，缓存就得执行一直<strong>放置策略</strong>(placement policy)，比如 LRU。来决定从主存中取出的数据放到哪里。<ul><li><strong>强制性不命中</strong>(compulsory miss)/冷不命中(cold miss)：缓存中没有要读取的数据，需要从主存读取数据，并将数据放入缓存。</li><li><strong>冲突不命中</strong>(conflict miss)：缓存中有要读的数据，在采取放置策略时，从主存中取数据放到缓存时发生了冲突，这叫做冲突不命中。</li></ul></li></ul><h4 id=高速缓存存储器组织结构>高速缓存存储器组织结构<a hidden class=anchor aria-hidden=true href=#高速缓存存储器组织结构>#</a></h4><p>整个 Cache 被划分为 1 个或多个<strong>组</strong> (Set)，$S$ 表示组的个数。每个组包含 1 个或多个<strong>缓存行</strong>(Cache line)，$E$ 表示一个组中缓存行的行数。每个缓存行由三部分组成：<strong>有效位</strong>(valid)，<strong>标记位</strong>（tag），<strong>数据块</strong>（cache block）。</p><ul><li>有效位：该位等于 1，表示这个行数据有效。</li><li>标记位：唯一的标识了存储在高速缓存中的块，标识目标数据是否存在当前的缓存行中。</li><li>数据块：一部分内存数据的副本。</li></ul><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711171136.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711171136.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711171136.png alt></a></div></p><p>Cache 的结构可以由元组$(S,E,B,m)$表示。不包括有效位和标记位。Cache 的大小为 $C=S \times E \times B$.</p><p>接下来看看 Cache 是如何工作的，当 CPU 执行数据加载指令，从内存地址 A 读取数据时，根据存储器层次原理，如果 Cache 中保存着目标数据的副本，那么就立即将数据返回给 CPU。那么 Cache 如何知道自己保存了目标数据的副本呢？</p><p>假设目标地址的数据长度为$m$位，这个地址被参数 $S$ 和 $B$ 分成了三个字段：</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711174416.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711174416.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711174416.png alt></a></div></p><p>首先通过长度为$s$的<strong>组索引</strong>，确定目标数据保存在哪一个组 (Set) 中，其次通过长度为$t$的<strong>标记</strong>，确定在哪一行，需要注意的是此时有效位必须等于 1，最后根据长度为$b$的<strong>块偏移</strong>，来确定目标数据在数据块中的确切位置。</p><blockquote><p>Q：既然读取 Cache 第一步是组选择，为什么不用高位作为组索引，而使用中间的为作为组索引？
A：如果使用了高位作索引，那么一些连续的内存块就会映射到相同的高速缓存块。如图前四个块映射到第一个缓存组，第二个四个块映射到第二个组，依次类推。如果一个程序有良好的空间局部性，顺序扫描一个数组的元素，那么在任何时候，缓存中都只保存在一个块大小的数组内容。这样对缓存的使用率很低。相比而言，如果使用中间的位作为组索引，那么相邻的块总是映射到不同的组，图中的情况能够存放整个大小的数组片。
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711185819.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711185819.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711185819.png alt></a></div></p></blockquote><h5 id=直接映射高速缓存-direct-mapped-cache>直接映射高速缓存 Direct Mapped Cache<a hidden class=anchor aria-hidden=true href=#直接映射高速缓存-direct-mapped-cache>#</a></h5><p>根据每个组的缓存行数 $E$ 的不同，Cache 被分为不同的类。每个组只有一行$E=1$的高速缓存被称为<strong>直接映射高速缓存</strong>(direct-mapped cache)。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711190845.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711190845.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711190845.png alt></a></div></p><p>当一条加载指令指示 CPU 从主存地址 A 中读取一个字 w 时，会将该主存地址 A 发送到高速缓存中，则高速缓存会根据<strong>组选择</strong>，<strong>行匹配</strong>和<strong>字抽取</strong>三步来判断地址 A 是否命中。</p><p><strong>组选择</strong>(set selection)：根据组索引值来确定属于哪一个组，如图中索引长度为 5 位，可以检索 32 个组 ($2^5=32$)。当$s=0$时，此时组选择的结果为<code>set 0</code>，当$s=1$时，此时组选择的结果为<code>set 1</code>。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711191708.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711191708.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711191708.png alt></a></div></p><p><strong>行匹配 (line match)</strong>：首先看缓存行的有效位，此时有效位为 1，表示当前数据有效。然后对比缓存行的标记<code>0110</code>与地址中的标记<code>0110</code>是否相等，如果相等，则表示目标数据在当前的缓存行中（缓存命中）。如果不一致或者有效位为 0，则表示目标数据不在当前的缓存行中（缓存不命中）。如果命中，就可以进行下一步字抽取。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192435.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192435.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192435.png alt></a></div></p><p><strong>字抽取 (word extraction)</strong>：根据偏移量$b$确定目标数据的确切位置，通俗来说就是从数据块的什么位置开始抽取位置。如当偏移块等于<code>100</code>时，表示目标数据起始地址位于字节 4 处。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192757.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192757.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711192757.png alt></a></div></p><p>下面通过一个例子来解释清除这个过程。假设我们有一个直接映射高速缓存，描述为$(S,E,B,m) = (4,1,2,4)$。换句话说，高速缓存有 4 个组，每个组 1 行，每个数据块 2 个字节，地址长度为 4 位。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194256.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194256.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194256.png alt></a></div></p><p>从图中可以看出，8 个内存块，但只有 4 个高速缓存组，所以会有多个块映射到同一个高速缓存组中。例如，块 0 和块 4 都会被映射到组 0。</p><p>下面我们来模拟当 CPU 执行一系列读的时候，高速缓存的执行情况，我们假设每次 CPU 读 1 个字节的字。</p><p><strong>读地址 0(0000) 的字：</strong>
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711193901.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711193901.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711193901.gif alt></a></div></p><p><strong>读地址 1(0001) 的字：</strong>
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194838.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194838.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711194838.gif alt></a></div></p><p><strong>读地址 13(1101) 的字：</strong>
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711195108.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711195108.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711195108.gif alt></a></div></p><p><strong>读地址 8(1000) 的字：</strong>
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200054.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200054.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200054.gif alt></a></div></p><p><strong>读地址 0(0000) 的字：</strong>
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200409.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200409.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220711200409.gif alt></a></div></p><h5 id=组相联高速缓存-set-associative-cache>组相联高速缓存 Set Associative Cache<a hidden class=anchor aria-hidden=true href=#组相联高速缓存-set-associative-cache>#</a></h5><p>由于直接映射高速缓存的组中只有一行，所以容易发生冲突不命中。组相联高速缓存 (Set associative cache) 运行有多行缓存行。但是缓存行最大不能超过 $C/B$。</p><p>如图一个组中包含了两行缓存行，这种我们称为 2 路相联高速缓存。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220712160513.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220712160513.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/20220712160513.png alt></a></div></p><p><strong>组选择</strong>：与直接映射高速缓存的组选择过程一样。</p><p><strong>行匹配</strong>：因为一个组有多行，所以需要遍历所有行，找到一个有效位为 1，并且标记为与地址中的标记位相匹配的一行。如果找到了，表示缓存命中。</p><p><strong>字抽取</strong>：根据偏移量$b$确定目标数据的确切位置，通俗来说就是从数据块的什么位置开始抽取位置。如当偏移块等于<code>100</code>时，表示目标数据起始地址位于字节 4 处。</p><p>如果不命中，那么就需要从主存中取出需要的数据块，但是将数据块放在哪一行缓存行呢？如果存在空行 ($valid=0$)，那就放到空行里。如果没有空行，就得选择一个非空行来替换，同时希望 CPU 不会很快引用这个被替换的行。这里介绍几个替换策略。</p><p>最简单的方式就是随机选择一行来替换，其他复杂的方式就是利用局部性原理，使得接下来 CPU 引用替换的行概率最小。如</p><h3 id=缓存一致性协议-mesi>缓存一致性协议 MESI<a hidden class=anchor aria-hidden=true href=#缓存一致性协议-mesi>#</a></h3><h4 id=为什么需要缓存一致>为什么需要缓存一致<a hidden class=anchor aria-hidden=true href=#为什么需要缓存一致>#</a></h4><p>目前主流电脑的 CPU 都是多核心的，多核心的有点就是在不能提升 CPU 主频后，通过增加核心来提升 CPU 吞吐量。每个核心都有自己的 L1 Cache 和 L2 Cache，只是共用 L3 Cache 和主内存。每个核心操作是独立的，每个核心的 Cache 就不是同步更新的，这样就会带来缓存一致性（Cache Coherence）的问题。</p><p>举个例子，如图：
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205291536919.gif alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205291536919.gif><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205291536919.gif alt></a></div></p><p>有 2 个 CPU，主内存里有个变量<code>x=0</code>。CPU A 中有个需要将变量<code>x</code>加<code>1</code>。CPU A 就将变量<code>x</code>加载到自己的缓存中，然后将变量<code>x</code>加<code>1</code>。因为此时 CPU A 还未将缓存数据写回主内存，CPU B 再读取变量<code>x</code>时，变量<code>x</code>的值依然是<code>0</code>。</p><p>这里的问题就是所谓的缓存一致性问题，因为 CPU A 的缓存与 CPU B 的缓存是不一致的。</p><h4 id=如何解决缓存一致性问题>如何解决缓存一致性问题<a hidden class=anchor aria-hidden=true href=#如何解决缓存一致性问题>#</a></h4><h5 id=通过在总线加-lock-锁的方式>通过在总线加 LOCK 锁的方式<a hidden class=anchor aria-hidden=true href=#通过在总线加-lock-锁的方式>#</a></h5><p>在锁住总线上加一个 LOCK 标识，CPU A 进行读写操作时，锁住总线，其他 CPU 此时无法进行内存读写操作，只有等解锁了才能进行操作。</p><p>该方式因为锁住了整个总线，所以效率低。</p><h5 id=缓存一致性协议-mesi-1>缓存一致性协议 MESI<a hidden class=anchor aria-hidden=true href=#缓存一致性协议-mesi-1>#</a></h5><p>该方式对单个缓存行的数据进行加锁，不会影响到内存其他数据的读写。</p><p>在学习 MESI 协议之前，简单了解一下总线嗅探机制（Bus Snooping）。要对自己的缓存加锁，需要通知其他 CPU，多个 CPU 核心之间的数据传播问题。最常见的一种解决方案就是总线嗅探。</p><p>这个策略，本质上就是把所有的读写请求都通过总线广播给所有的 CPU 核心，然后让各个核心去“嗅探”这些请求，再根据本地的情况进行响应。MESI 就是基于总线嗅探机制的缓存一致性协议。</p><p>MESI 协议的由来是对 Cache Line 的四个不同的标记，分别是：</p><table><thead><tr><th style=text-align:center><div style=width:50px>状态</div></th><th style=text-align:center><div style=width:100px>状态</div></th><th><div style=width:200px>描述</div></th><th><div style=width:200px>监听任务</div></th></tr></thead><tbody><tr><td style=text-align:center>Modified</td><td style=text-align:center>已修改</td><td>该 Cache Line 有效，数据被修改了，和内存中的数据不一致，数据只存在于本 Cache 中</td><td>Cache Line 必须时刻监听所有试图读该 Cache Line 相对于主存的操作，这种操作必须在缓存将该 Cache Line 写回主存并将状态改为 S 状态之前，被延迟执行</td></tr><tr><td style=text-align:center>Exclusive</td><td style=text-align:center>独享，互斥</td><td>该 Cache Line 有效，数据和内存中的数据一直，数据只存在于本 Cache</td><td>Cache Line 必须监听其他缓存读主存中该 Cache Line 的操作，一旦有这种操作，该 Cache Line 需要改为 S 状态</td></tr><tr><td style=text-align:center>Shared</td><td style=text-align:center>共享的</td><td>该 Cache Line 有效，数据和内存中的数据一直，数据存在于很多个 Cache 中</td><td>Cache Line 必须监听其他 Cache Line 使该 Cache Line 无效或者独享该 Cache Line 的请求，并将 Cache Line 改为 I 状态</td></tr><tr><td style=text-align:center>Invalid</td><td style=text-align:center>无效的</td><td>该 Cache Line 无效</td><td>无</td></tr></tbody></table><p>整个 MESI 的状态，可以用一个有限状态机来表示它的状态流转。需要注意的是，对于不同状态触发的事件操作，可能来自于当前 CPU 核心，也可能来自总线里其他 CPU 核心广播出来的信号。我把各个状态之间的流转用表格总结了一下：</p><table><thead><tr><th style=text-align:center><div style=width:80px>当前状态</div></th><th style=text-align:center><div style=width:80px>事件</div></th><th><div style=width:300px,center>行为</div></th><th style=text-align:center><div style=width:80px>下个状态</div></th></tr></thead><tbody><tr><td style=text-align:center>M</td><td style=text-align:center>Local Read</td><td>从 Cache 中读，状态不变</td><td style=text-align:center>M</td></tr><tr><td style=text-align:center>M</td><td style=text-align:center>Local Write</td><td>修改 cache 数据，状态不变</td><td style=text-align:center>M</td></tr><tr><td style=text-align:center>M</td><td style=text-align:center>Remote Read</td><td>这行数据被写到内存中，使其他核能使用到最新数据，状态变为 S</td><td style=text-align:center>S</td></tr><tr><td style=text-align:center>M</td><td style=text-align:center>Remote Write</td><td>这行数据被写入内存中，其他核可以获取到最新数据，由于其他 CPU 修改该条数据，则本地 Cache 变为 I</td><td style=text-align:center>I</td></tr></tbody></table><table><thead><tr><th style=text-align:center><div style=width:80px>当前状态</div></th><th style=text-align:center><div style=width:80px>事件</div></th><th><div style=width:200px,center>行为</div></th><th style=text-align:center><div style=width:80px>下个状态</div></th></tr></thead><tbody><tr><td style=text-align:center>E</td><td style=text-align:center>Local Read</td><td>从 Cache 中读，状态不变</td><td style=text-align:center>E</td></tr><tr><td style=text-align:center>E</td><td style=text-align:center>Local Write</td><td>修改数据，状态改为 M</td><td style=text-align:center>M</td></tr><tr><td style=text-align:center>E</td><td style=text-align:center>Remote Read</td><td>数据和其他 CPU 共享，变为 S</td><td style=text-align:center>S</td></tr><tr><td style=text-align:center>E</td><td style=text-align:center>Remote Write</td><td>数据被修改，本地缓存失效，变为 I</td><td style=text-align:center>I</td></tr></tbody></table><table><thead><tr><th style=text-align:center><div style=width:80px>当前状态</div></th><th style=text-align:center><div style=width:80px>事件</div></th><th><div style=width:200px,text-align:center>行为</div></th><th style=text-align:center><div style=width:80px>下个状态</div></th></tr></thead><tbody><tr><td style=text-align:center>S</td><td style=text-align:center>Local Read</td><td>从 Cache 中读，状态不变</td><td style=text-align:center>S</td></tr><tr><td style=text-align:center>S</td><td style=text-align:center>Local Write</td><td>修改数据，状态改为 M，其他 CPU 的 Cache Line 状态改为 I</td><td style=text-align:center>M</td></tr><tr><td style=text-align:center>S</td><td style=text-align:center>Remote Read</td><td>数据和其他 CPU 共享，状态不变</td><td style=text-align:center>S</td></tr><tr><td style=text-align:center>S</td><td style=text-align:center>Remote Write</td><td>数据被修改，本地缓存失效，变为 I</td><td style=text-align:center>I</td></tr></tbody></table><table><thead><tr><th style=text-align:center><div style=width:80px>当前状态</div></th><th style=text-align:center><div style=width:80px>事件</div></th><th><div style=width:200px,center>行为</div></th><th style=text-align:center><div style=width:80px>下个状态</div></th></tr></thead><tbody><tr><td style=text-align:center>I</td><td style=text-align:center>Local Read</td><td>1. 如果其他 CPU 没有这份数据，直接从内存中加载数据，状态变为 E；<br>2. 如果其他 CPU 有这个数据，且 Cache Line 状态为 M，则先把 Cache Line 中的内容写回到主存。本地 Cache 再从内存中读取数据，这时两个 Cache Line 的状态都变为 S；<br>3. 如果其他 Cache Line 有这份数据，并且状态为 S 或者 E，则本地 Cache Line 从主存读取数据，并将这些 Cache Line 状态改为 S</td><td style=text-align:center>E 或者 S</td></tr><tr><td style=text-align:center>I</td><td style=text-align:center>Local Write</td><td>1. 先从内存中读取数据，如果其他 Cache Line 中有这份数据，且状态为 M，则现将数据更新到主存再读取，将 Cache Line 状态改为 M；<br>2. 如果其他 Cache Line 有这份数据，且状态为 E 或者 S，则其他 Cache Line 状态改为 I</td><td style=text-align:center>M</td></tr><tr><td style=text-align:center>I</td><td style=text-align:center>Remote Read</td><td>数据和其他 CPU 共享，状态不变</td><td style=text-align:center>S</td></tr><tr><td style=text-align:center>I</td><td style=text-align:center>Remote Write</td><td>数据被修改，本地缓存失效，变为 I</td><td style=text-align:center>I</td></tr></tbody></table><h2 id=内存>内存<a hidden class=anchor aria-hidden=true href=#内存>#</a></h2><p>计算机有五大组成部分，分别是：运算器、控制器、存储器、输入设备和输出设备。而内存就是其中的存储器。我们的数据和指令都需要先放到内存中，然后再被 CPU 执行。</p><p>操作系统中程序并不能直接访问物理内存，我们的内存需要被分成固定大小的页（Page），然后再通过<strong>虚拟内存地址（Virtual Address）到物理内存地址（Physical Address）的地址转换（Address Translation）</strong>，才能到达实际存放数据的物理内存位置。而我们的程序看到的内存地址，都是虚拟内存地址。那么如何进行转换的呢？</p><h3 id=简单页表>简单页表<a hidden class=anchor aria-hidden=true href=#简单页表>#</a></h3><p>最简单的方式，就是建立一张虚拟内存到物理内存的映射表，在计算机里叫做页表（Page Table）。页表这个地址转换的办法，会把一个内存地址分成页号（Directory）和偏移量（Offset）两个部分，是不是似曾相识，因为在前面的高速缓存里，缓存的结构也是这样的。</p><p>以一个 32 位地址举例，高 20 位是虚拟页号，可以从虚拟页表中找到物理页号的信息，低 12 位是偏移量，可以准确获得物理地址。
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161640968.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161640968.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161640968.png alt></a></div></p><p>总结一下，对于一个内存地址转换，其实就是这样三个步骤：</p><ul><li>把虚拟内存地址，切分成页号和偏移量的组合；</li><li>从页表里面，查询出虚拟页号，对应的物理页号；</li><li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li></ul><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161645714.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161645714.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202207161645714.png alt></a></div></p><p>但是这样的页表有个问题，它需要记录$2^{20}$个物理页表，这个存储关系，就好比一个 $2^{20}$大小的数组。一个页号是完整的 32 位的 4 字节（Byte），这样一个页表就需要 4MB 的空间。并且每个进程都会有这样一个页表，现代电脑正常都有成百上千个进程，如果用这样的页表肯定行不通的。</p><h3 id=多级页表>多级页表<a hidden class=anchor aria-hidden=true href=#多级页表>#</a></h3><p>所以，<strong>在一个实际的程序进程里面，虚拟内存占用的地址空间，通常是两段连续的空间。而不是完全散落的随机的内存地址</strong>。而多级页表，就特别适合这样的内存地址分布。</p><p><a href=https://zhuanlan.zhihu.com/p/357648933>谈一谈内存管理，虚拟内存，多级页表 - 知乎</a></p><h3 id=tlb>TLB<a hidden class=anchor aria-hidden=true href=#tlb>#</a></h3><h3 id=内存保护---可执行空间保护>内存保护 - 可执行空间保护<a hidden class=anchor aria-hidden=true href=#内存保护---可执行空间保护>#</a></h3><h3 id=内存保护---地址空间布局随机化>内存保护 - 地址空间布局随机化<a hidden class=anchor aria-hidden=true href=#内存保护---地址空间布局随机化>#</a></h3><p>Address Space Layout Randomization</p><h2 id=总线计算机内部的高速公路>总线：计算机内部的高速公路<a hidden class=anchor aria-hidden=true href=#总线计算机内部的高速公路>#</a></h2><p>计算机由控制器、运算器、存储器、输入设备以及输出设备五大部分组成。CPU 所代表的控制器和运算器，要和存储器，也就是我们的主内存，以及输入和输出设备进行通信。那么计算机是用什么样的方式来完成，CPU 和内存、以及外部输入输出设备的通信呢？答案就是通过总线来通信。</p><p>计算机里有不同的硬件设备，如果设备与设备之间都单独连接，那么就需要 N*N 的连线。那么怎么降低复杂度呢？与其让各个设备之间互相单独通信，不如我们去设计一个公用的线路。CPU 想要和什么设备通信，通信的指令是什么，对应的数据是什么，都发送到这个线路上；设备要向 CPU 发送什么信息呢，也发送到这个线路上。这个线路就好像一个高速公路，各个设备和其他设备之间，不需要单独建公路，只建一条小路通向这条高速公路就好了。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510203.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510203.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510203.png alt></a></div></p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510711.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510711.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081510711.png alt></a></div></p><h3 id=三种线路和多总线架构>三种线路和多总线架构<a hidden class=anchor aria-hidden=true href=#三种线路和多总线架构>#</a></h3><p>首先，CPU 和内存以及高速缓存通信的总线，这里面通常有两种总线。这种方式，我们称之为双独立总线（Dual Independent Bus，缩写为 DIB）。CPU 里，有一个快速的本地总线（Local Bus），以及一个速度相对较慢的前端总线（Front-side Bus）。</p><p>现代的 CPU 里，通常有专门的高速缓存芯片。这里的高速本地总线，就是用来和高速缓存通信的。而前端总线，则是用来和主内存以及输入输出设备通信的。有时候，我们会把本地总线也叫作后端总线（Back-sideBus），和前面的前端总线对应起来。</p><p>除了前端总线呢，我们常常还会听到 PCI 总线、I/O 总线或者系统总线（System Bus）。看到这么多总线的名字，你是不是已经有点晕了。这些名词确实容易混为一谈。其实各种总线的命名一直都很混乱，我们不如直接来看一看 CPU 的硬件架构图。对照图来看，一切问题就都清楚了。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081513938.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081513938.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081513938.png alt></a></div></p><p>CPU 里面的北桥芯片，把我们上面说的前端总线，一分为二，变成了三个总线。我们的前端总线，其实就是系统总线。CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器（I/OBridge）。这个 I/O 桥接器，一边接入了我们的内存总线，使得我们的 CPU 和内存通信；另一边呢，又接入了一个 I/O 总线，用来连接 I/O 设备。</p><p>事实上，真实的计算机里，这个总线层面拆分得更细。根据不同的设备，还会分成独立的 PCI 总线、ISA 总线等等。
<img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081516341.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081516341.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202205081516341.png alt></a></div></p><p>在物理层面，其实我们完全可以把总线看作一组“电线”。不过呢，这些电线之间也是有分工的，我们通常有三类线路。</p><ol><li>数据线（Data Bus），用来传输实际的数据信息，也就是实际上了公交车的“人”。</li><li>地址线（Address Bus），用来确定到底把数据传输到哪里去，是内存的某个位置，还是某一个 I/O 设备。这个其实就相当于拿了个纸条，写下了上面的人要下车的站点。</li><li>控制线（ControlBus），用来控制对于总线的访问。虽然我们把总线比喻成了一辆公交车。那么有人想要做公交车的时候，需要告诉公交车司机，这个就是我们的控制信号。</li></ol><p>尽管总线减少了设备之间的耦合，也降低了系统设计的复杂度，但同时也带来了一个新问题，那就是<strong>总线不能同时给多个设备提供通信功能</strong>。</p><p>我们的总线是很多个设备公用的，那多个设备都想要用总线，我们就需要有一个机制，去决定这种情况下，到底把总线给哪一个设备用。这个机制，就叫作<strong>总线裁决</strong>（Bus Arbitraction）</p><h2 id=硬盘>硬盘<a hidden class=anchor aria-hidden=true href=#硬盘>#</a></h2><h2 id=dma>DMA<a hidden class=anchor aria-hidden=true href=#dma>#</a></h2><p>过去几年，计算机产业一直在为提升 I/O 设备的速度而努力，从机械硬盘 HDD 到固态硬盘 SSD，从 SATA 协议到 PCIE 协议，虽然速度都几十上百倍的增加，但是仍然不够快。因为相比于 CPU 基本都是 2GHz 的频率（每秒会有 20 亿次的操作），SSD 硬盘的 IOPS 的 2 万次操作就显得微不足道。</p><p>如果我们对于 I/O 的操作，都是由 CPU 发出对应的指令，然后等待 I/O 设备完成操作之后返回，那 CPU 有大量的时间其实都是在等待 I/O 设备完成操作。特别是当传输的数据量比较大的时候，比如进行大文件复制，如果所有数据都要经过 CPU，实在是有点儿太浪费时间了。</p><p>因此，计算机工程师们，就发明了<strong>DMA 技术</strong>，也就是<strong>直接内存访问（Direct Memory Access）技术</strong>，来减少 CPU 等待的时间。</p><h3 id=什么是-dma>什么是 DMA<a hidden class=anchor aria-hidden=true href=#什么是-dma>#</a></h3><p>本质上，DMA 技术就是我们在主板上放一块<strong>独立的芯片</strong>。在进行内存和 I/O 设备的数据传输的时候，我们不再通过 CPU 来控制数据传输，而直接通过 DMA 控制器（DMA Controller，简称 DMAC）。这块芯片，我们可以认为它其实就是一个<strong>协处理器</strong>（Co-Processor）。</p><p>DMAC 最有价值的地方体现在，当我们要传输的数据特别大、速度特别快，或者传输的数据特别小、速度特别慢的时候。</p><p>比如说，我们用千兆网卡或者硬盘传输大量数据的时候，如果都用 CPU 来搬运的话，肯定忙不过来，所以可以选择 DMAC。而当数据传输很慢的时候，DMAC 可以等数据到齐了，再向 CPU 发起中断，让 CPU 去处理，而不是让 CPU 在那里忙等待。</p><p><img loading=lazy src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202208152252016.png alt><div class=post-img-view><a data-fancybox=gallery href=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202208152252016.png><img src=https://picbed-1311007548.cos.ap-shanghai.myqcloud.com/markdown_picbed/img/202208152252016.png alt></a></div></p><ol><li>首先，CPU 还是作为一个主设备，向 DMAC 设备发起请求。这个请求，其实就是在 DMAC 里面修改配置寄存器。</li><li>CPU 修改 DMAC 的配置的时候，会告诉 DMAC 这样几个信息：<ul><li>源地址的初始值：数据要从哪里传输过来。如果我们要从内存里面写入数据到硬盘上，那么就是要读取的数据在内存里面的地址</li><li>传输时候的地址增减方式：数据是从大的地址向小的地址传输，还是从小的地址往大的地址传输</li><li>传输的数据长度：也就是我们一共要传输多少数据</li></ul></li><li>设置完这些信息之后，DMAC 就会变成一个空闲的状态（Idle）。</li><li>如果我们要从硬盘上往内存里面加载数据，这个时候，硬盘就会向 DMAC 发起一个数据传输请求。这个请求并不是通过总线，而是通过一个额外的连线。</li><li>然后，我们的 DMAC 需要再通过一个额外的连线响应这个申请。</li><li>DMAC 这个芯片，就向硬盘的接口发起要总线读的传输请求。数据就从硬盘里面，读到了 DMAC 的控制器里面。</li><li>DMAC 再向我们的内存发起总线写的数据传输请求，把数据写入到内存里面。</li><li>DMAC 会反复进行上面第 6、7 步的操作，直到 DMAC 的寄存器里面设置的数据长度传输完成。</li><li>数据传输完成之后，DMAC 重新回到第 3 步的空闲状态。</li></ol><p>所以，整个数据传输的过程中，我们不是通过 CPU 来搬运数据，而是由 DMAC 这个芯片来搬运数据。但是 CPU 在这个过程中也是必不可少的。因为传输什么数据，从哪里传输到哪里，其实还是由 CPU 来设置的。这也是为什么，DMAC 被叫作 <strong>协处理器</strong>。</p><h2 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h2><p><a href="https://www.bilibili.com/video/BV1cJ411K7HW?spm_id_from=333.999.0.0">【硬件科普】电脑主板右下角的散热片下面究竟隐藏着什么？详解主板南桥芯片组的功能和作用_哔哩哔哩_bilibili</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://lifeislife.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/>计算机组成原理</a></li><li><a href=https://lifeislife.cn/tags/dma/>DMA</a></li><li><a href=https://lifeislife.cn/tags/%E9%A1%B5%E8%A1%A8/>页表</a></li><li><a href=https://lifeislife.cn/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/>虚拟内存</a></li><li><a href=https://lifeislife.cn/tags/%E7%BC%93%E5%AD%98/>缓存</a></li><li><a href=https://lifeislife.cn/tags/cache/>Cache</a></li><li><a href=https://lifeislife.cn/tags/%E6%80%BB%E7%BA%BF/>总线</a></li></ul><nav class=paginav><a class=prev href=https://lifeislife.cn/posts/%E9%93%BE%E6%8E%A5%E8%84%9A%E6%9C%AC%E5%85%A5%E9%97%A8/><span class=title>« 上一页</span><br><span>链接脚本入门</span>
</a><a class=next href=https://lifeislife.cn/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86-%E5%A4%84%E7%90%86%E5%99%A8/><span class=title>下一页 »</span><br><span>计算机组成原理-处理器</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on x" href="https://x.com/intent/tweet/?text=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f&amp;url=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f&amp;hashtags=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86%2cDMA%2c%e9%a1%b5%e8%a1%a8%2c%e8%99%9a%e6%8b%9f%e5%86%85%e5%ad%98%2c%e7%bc%93%e5%ad%98%2cCache%2c%e6%80%bb%e7%ba%bf"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f&amp;title=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f&amp;summary=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f&amp;source=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f&title=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on whatsapp" href="https://api.whatsapp.com/send?text=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f%20-%20https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on telegram" href="https://telegram.me/share/url?text=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f&amp;url=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 计算机组成原理-存储与 IO 系统 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e8%ae%a1%e7%ae%97%e6%9c%ba%e7%bb%84%e6%88%90%e5%8e%9f%e7%90%86-%e5%ad%98%e5%82%a8%e4%b8%8e%20IO%20%e7%b3%bb%e7%bb%9f&u=https%3a%2f%2flifeislife.cn%2fposts%2f%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E7%25BB%2584%25E6%2588%2590%25E5%258E%259F%25E7%2590%2586-%25E5%25AD%2598%25E5%2582%25A8%25E4%25B8%258Eio%25E7%25B3%25BB%25E7%25BB%259F%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://lifeislife-1.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://lifeislife.cn/>夜云泊</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>