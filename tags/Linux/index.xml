<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Linux on PaperMod</title>
    <link>http://localhost:8888/tags/linux/</link>
    <description>Recent content in Linux on PaperMod</description>
    <generator>Hugo -- 0.131.0</generator>
    <language>en</language>
    <lastBuildDate>Sun, 03 Mar 2024 20:45:56 +0000</lastBuildDate>
    <atom:link href="http://localhost:8888/tags/linux/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RemoteX11 远程调试带GUI应用</title>
      <link>http://localhost:8888/posts/remotex11-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B8%A6gui%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sun, 03 Mar 2024 20:45:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/remotex11-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%B8%A6gui%E5%BA%94%E7%94%A8/</guid>
      <description>Windows上通过WSL2进行Linux开发，但是有时候需要开发带GUI的引用，这样就需要将图像转发。
配置Windows 下载安装XMing，启动Xlaunch。
选择MultiWindow 设置Display number为10（可以自行设置，主要是需要和后面在WSL2中设置的变量保持一致） 选择Start no client（Windows的XMing是被动等待接收图像数据，所以选择该项） 一直下一页，其余保持默认，点击完成即可。 配置VSCode 安装RemoteX11插件，直接在插件中心搜索安装即可。
打开设置页面，搜索Remote x11，找到如下配置项，将Display Number配置为10
配置WSL2 安装xclock用于测试
sudo apt-get install xclock 设置环境变量
export DISPLAY=localhost:10.0 # 或者 export DISPLAY=:0 运行xclock查看结果</description>
    </item>
    <item>
      <title>repo源配置解析</title>
      <link>http://localhost:8888/posts/repo%E6%BA%90%E9%85%8D%E7%BD%AE%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Wed, 17 Jan 2024 21:32:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/repo%E6%BA%90%E9%85%8D%E7%BD%AE%E8%A7%A3%E6%9E%90/</guid>
      <description>repo 源配置解析 openEuler 的软件源配置文件位于/etc/yum.repos.d/目录下，以.repo 为后缀名，文件名可以任意取，但是必须以.repo 结尾。
#generic-repos is licensed under the Mulan PSL v2. #You can use this software according to the terms and conditions of the Mulan PSL v2. #You may obtain a copy of Mulan PSL v2 at: # http://license.coscl.org.cn/MulanPSL2 #THIS SOFTWARE IS PROVIDED ON AN &amp;#34;AS IS&amp;#34; BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR #IMPLIED, INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY OR FIT FOR A PARTICULAR #PURPOSE.</description>
    </item>
    <item>
      <title>Linux内核模块校验机制</title>
      <link>http://localhost:8888/posts/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Sat, 13 Jan 2024 22:00:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6/</guid>
      <description>初学 Linux 内核或者第一次编译使用内核模块时经常会遇到类似这样的错误：
insmod: ERROR: could not insert module kvm.ko: Invalid module format 这个报错通常由于当前插入kvm.ko的version magic版本信息与正在运行的 kernel 的version magic版本不一致导致的。
内核校验模块的流程 我们从问题出发，看看内核是如何校验模块的。搜索了内核源码，找到了在函数check_version中抛出了disagrees about version of symbol错误信息，我们根据源码来回溯一下整个过程。
// kernel/module.c static int check_version(const struct load_info *info, const char *symname, struct module *mod, const s32 *crc) { Elf_Shdr *sechdrs = info-&amp;gt;sechdrs; unsigned int versindex = info-&amp;gt;index.vers; unsigned int i, num_versions; struct modversion_info *versions; /* Exporting module didn&amp;#39;t supply crcs? OK, we&amp;#39;re already tainted. */ if (!</description>
    </item>
    <item>
      <title>uCore-实验第 0 章 - 实验环境搭建</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC0%E7%AB%A0-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 08 Sep 2023 10:46:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC0%E7%AB%A0-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>本次实验是清华大学操作系统课程的课程实验，实验内容是基于 RISC-V 架构的 uCore 操作系统。本次实验的目的是搭建实验环境，为后续实验做准备。指导书参考uCore-Tutorial-Guide-2023S 文档。本系列文章内容主要是指导书的补充以及我在实验过程的一些理解。
本章没有什么需要特别说明的，指导手册十分详细，按照指导手册的步骤一步步来就可以了。因为平时也在用 WSL2 开发，所以配置十分顺利，没有遇到什么问题。这篇文章就当占坑了，如果后续有什么需要补充的再来更新。</description>
    </item>
    <item>
      <title>uCore-实验第 1 章 - 应用程序与基本执行环境</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC1%E7%AB%A0-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Fri, 08 Sep 2023 10:45:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC1%E7%AB%A0-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83/</guid>
      <description>了解系统调用 操作系统的系统调用（syscall）是操作系统提供给应用程序使用的一种接口。它允许应用程序通过向操作系统发送请求，来执行一些必须由操作系统来完成的任务，例如读取文件、创建进程、分配内存等。
通俗地说，可以把操作系统看作一个巨大的服务员，而应用程序就像是顾客。应用程序不能直接访问硬件或执行特权操作，因为这样可能会导致系统不稳定或不安全。所以，应用程序需要通过系统调用来与操作系统进行交互，请求操作系统代表它完成某些任务。
当应用程序需要操作系统执行特定的功能时，它会调用适当的系统调用函数，并传递参数给它。然后操作系统会接收到这个请求，并根据请求的类型和参数来执行相应的操作。完成后，操作系统会将执行结果返回给应用程序。
在 RISC-V 架构中，系统调用是通过使用特定的指令来实现的。具体来说，RISC-V 架构提供了一个称为 ecall（environment call）的指令来触发系统调用。
要使用 syscall，在 RISC-V 汇编代码中可以通过以下步骤来完成：
将系统调用编号（syscall number）放入寄存器 a7 中，该编号对应于所需的系统调用功能。 将系统调用所需的参数放入其他相应的寄存器中。例如，参数传递给文件读取系统调用可能需要将文件描述符放入 a0 寄存器，缓冲区地址放入 a1 寄存器，以及读取的字节数放入 a2 寄存器。 执行 ecall 指令。这会触发操作系统处理当前运行的程序的系统调用请求。 操作系统接收到系统调用请求后，根据寄存器 a7 中的系统调用编号和其他寄存器中的参数来执行相应的操作。 当操作系统完成系统调用请求时，它将结果放入适当的寄存器中，通常是 a0 寄存器。 程序继续执行，可以检查结果并进行后续的处理。 需要注意的是，具体的系统调用编号以及参数的传递方式会根据操作系统的实现而有所不同。所以在编写 RISC-V 汇编代码时，需要参考操作系统的相关文档来了解具体的系统调用接口和参数传递方式。
makr run 之后发生了什么？ 当执行make run命令后，以下是运行流程的概述：
内核代码编译：执行make run会触发 Makefile 中的相应规则，从而编译生成内核（kernel）二进制文件。
加载 kernel 并启动 QEMU：根据 QEMUOPTS 变量指定的参数，QEMU 加载生成的 kernel 二进制文件，并启动模拟器。
引导代码执行：在模拟器启动后，CPU 的通用寄存器被清零，程序计数器（PC）指向 0x1000 的位置，这里有硬件固化的一小段引导代码。该引导代码会迅速跳转到 0x80000000 处的 RustSBI（Rust Supervisor Binary Interface）。
RustSBI 完成硬件初始化：RustSBI 是一个用于与操作系统进行交互的接口层。在跳转到 RustSBI 之后，它会完成必要的硬件初始化工作。</description>
    </item>
    <item>
      <title>uCore 实验第 5 章 - 进程及进程管理</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC5%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Fri, 08 Sep 2023 10:01:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC5%E7%AB%A0-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>首先，.section .data 表示定义了一个数据段，在这个段中定义了一系列的全局变量。其中，_app_num 是一个标签，表示一个 64 位的整数，初始值为 23。接下来是一系列的标签，分别代表了应用程序的起始地址，每个标签都是 64 位的整数。
接着，.section .data 后面又出现了一个标签 _app_names，它是一个字符串数组，包含了一组字符串，分别命名为 &amp;ldquo;ch2b_exit&amp;rdquo;、&amp;ldquo;ch2b_hello_world&amp;rdquo;、&amp;ldquo;ch2b_power&amp;rdquo; 等等。这些字符串名字对应了前面定义的应用程序的起始地址。
再往下，出现了一个标签 INIT_PROC，它是一个字符串，表示初始化进程的名称，值为 &amp;ldquo;usershell&amp;rdquo;。
之后，每个应用程序都有自己的标签和段名，比如 app_0_start、app_1_start 等等。每个标签都包含一个指令 .incbin，它用于将一个二进制文件（以字符串形式指定文件路径）插入到当前段中。
进程初始化分析 scheduler() fetch_task() // 获取下一个要执行的进程 swtch(&amp;amp;curenv-&amp;gt;context, nextenv-&amp;gt;context) // 切换到下一个进程上下文 // Per-process state struct proc { enum procstate state; // 进程状态 int pid; // 进程 ID uint64 ustack; // 进程用户栈虚拟地址 (用户页表) uint64 kstack; // 进程内核栈虚拟地址 (内核页表) struct trapframe *trapframe; // 进程中断帧 struct context context; // 用于保存进程内核态的寄存器信息，进程切换时使用 pagetable_t pagetable; // User page table uint64 max_page; uint64 program_brk; uint64 heap_bottom; struct proc * parent; // Parent process uint64 exit_code; struct file * files[FD_BUFFER_SIZE]; uint32 syscall_times[MAX_SYSCALL_NUM]; // 系统调用次数统计 uint64 start_time; // 进程开始运行时间 struct vma vmas[NVMA]; // 虚拟内存区域 }; wait 系统调用的功能 wait 系统调用是用于处理子进程终止状态的系统调用。其主要功能是等待子进程的终止，并获取子进程的退出状态信息。在操作系统中，当一个父进程创建了一个子进程后，通常会使用 wait 来等待子进程的终止，以便进行后续的处理，如回收子进程的资源或获取其运行结果。</description>
    </item>
    <item>
      <title>uCore 实验第 4 章 - 地址空间</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC4%E7%AB%A0-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Mon, 04 Sep 2023 11:11:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC4%E7%AB%A0-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</guid>
      <description>为何指定 TRAMPOLINE 和 TRAPFRAME 在 va 的最高位？ TRAMPOLINE 和 TRAPFRAME 被定义在最高的虚拟内存地址上，是因为它们在操作系统的内存布局中起着重要作用。 TRAMPOLINE 被用作从用户模式切换到内核模式的跳转目标。当发生异常或中断时，处理器将从用户模式切换到内核模式，并将控制权转移到内核中预定义的位置，也就是陷阱处理程序。TRAMPOLINE 页面被映射到最高虚拟地址，以便处理器能够在这个转换过程中方便地引用它。通过将其放置在最高地址，确保了无论系统的具体内存布局如何，它始终是可访问的。 另一方面，TRAPFRAME 用于在发生异常或中断时存储机器状态。它包含寄存器、标志和其他操作系统处理异常所需的信息。TRAPFRAME 也被放置在最高的虚拟地址上，以确保它易于访问，并且陷阱处理程序可以高效地访问它。 通过将 TRAMPOLINE 和 TRAPFRAME 定义在最高的虚拟内存地址上，内核可以方便而可靠地处理异常和中断，而无需关心它们在内存中的特定位置。
如何确定分页方案 - satp 在 MMU 没有使能的情况下，虚拟地址和物理地址是相同的。在 MMU 使能的情况下，虚拟地址会被转换成物理地址。这个转换过程是由操作系统来管理的，操作系统需要维护一个数据结构来记录虚拟地址和物理地址的映射关系。这个数据结构就是页表。
转换的过程需要分页机制，分页机制有多种。RISC-V 的分页方案以 SvX 的模式命名，其中 X 是以位为单位的虚拟地址的长度。在 RV64 架构下，RISC-V 支持多种分页方案，包括 Sv39，Sv48，Sv57 以及 Sv64。Sv39 最大支持 39 位的虚拟地址，这意味着它可以支持 512 GB 的虚拟地址空间。Sv48 最大支持 48 位的虚拟地址，这意味着它可以支持 256 TB 的虚拟地址空间。我们将在本章中实现 Sv39 分页方案。
如何开启分页机制呢？RISC-V 的分页机制是通过 satp（Supervisor address translation and protection）寄存器来开启的。satp 寄存器字段分布如下：
Mode 字段可以决定是否开启分页以及分页级数。Mode=0 时，不开启分页；Mode=8 时，开启 Sv39 分页机制。 ASID（Address Space Identifier，地址空间标识符）域是可选的，它可以用来降低上下文切换的开销。目前我们暂不考虑这个字段的作用。 PPN（Physical Page Number，物理页号），保存了根页表的物理地址。 SV39 多级页表机制 页表项描述 Sv39 页表项（page-table entry，PTE）的布局，从左到右分别包含如下所述的域：</description>
    </item>
    <item>
      <title>uCore 实验第 3 章 - 多道程序与分时多任务</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC3%E7%AB%A0-%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%88%86%E6%97%B6%E5%A4%9A%E4%BB%BB%E5%8A%A1/</link>
      <pubDate>Sat, 02 Sep 2023 16:03:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC3%E7%AB%A0-%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E4%B8%8E%E5%88%86%E6%97%B6%E5%A4%9A%E4%BB%BB%E5%8A%A1/</guid>
      <description>// 启动时初始化进程表 void proc_init(void) { struct proc *p; for (p = pool; p &amp;lt; &amp;amp;pool[NPROC]; p++) { p-&amp;gt;state = UNUSED; // p - pool 是 p 指向的 proc 在 pool 中的下标，因此 p - pool 变化情况是 0, 1, 2, ..., NPROC - 1 p-&amp;gt;kstack = (uint64)kstack[p - pool]; p-&amp;gt;ustack = (uint64)ustack[p - pool]; p-&amp;gt;trapframe = (struct trapframe *)trapframe[p - pool]; /* * LAB1: you may need to initialize your new fields of proc here */ } idle.</description>
    </item>
    <item>
      <title>yq 为 yaml 文件内容排序</title>
      <link>http://localhost:8888/posts/yq%E4%B8%BAyaml%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Fri, 01 Sep 2023 21:37:25 +0000</pubDate>
      <guid>http://localhost:8888/posts/yq%E4%B8%BAyaml%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%8E%92%E5%BA%8F/</guid>
      <description>背景 配置 yaml 文件时会遇到需要将配置的内容按照键值排序的情况，比如下面这样riscv_fork_list.yaml：
packages: - name: accumulo - name: abseil-cpp - name: acpica-tools - name: acpid - name: activemq - name: afflib - name: adcli - name: adwaita-icon-theme - name: aide - name: alsa-lib - name: amtk - name: anaconda - name: apache-sshd - name: annobin - name: antlr3 - name: apache-commons-csv - name: aom - name: apache-commons-beanutils - name: apache-commons-daemon - name: apache-commons-el - name: apache-commons-exec - name: apache-commons-jexl - name: apache-poi - name: apache-rat 我想按照 name 的字母顺序排序，可以使用 yq 工具来实现。</description>
    </item>
    <item>
      <title>uCore 实验第 2 章 - 批处理系统</title>
      <link>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC2%E7%AB%A0-%E6%89%B9%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Thu, 31 Aug 2023 23:16:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/ucore-%E5%AE%9E%E9%AA%8C%E7%AC%AC2%E7%AB%A0-%E6%89%B9%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/</guid>
      <description>flowchart TBsubgraph entry.S_entry[_entry]endsubgraph link_app.S_app_num[_app_num]endsubgraph main.cmain[main]endsubgraph loader.cloader_init[loader_init]run_next_app[run_next_app]load_app[load_app]end_entry --&amp;gt; mainmain --&amp;gt; loader_initmain --&amp;gt; run_next_apprun_next_app --&amp;gt; load_apploader_init --&amp;gt; _app_num </description>
    </item>
    <item>
      <title>SSH 免密登录</title>
      <link>http://localhost:8888/posts/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</link>
      <pubDate>Sat, 12 Aug 2023 09:22:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</guid>
      <description>生成密钥对 宿主机任意下目录执行：
$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/user/.ssh/id_rsa): host2servera_id_rsa Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in host2servera_id_rsa. Your public key has been saved in host2servera_id_rsa.pub. The key fingerprint is: SHA256:OkWcw+R3x6Z2mzeYQuG033H3N9qIeym3TZKzz6YD8tQ user@ubuntu18 The key&amp;#39;s randomart image is: +---[RSA 2048]----+ | . | | = . . | | B .o. + | | .</description>
    </item>
    <item>
      <title>SSH 登录 OpenStack 实例</title>
      <link>http://localhost:8888/posts/ssh-%E7%99%BB%E5%BD%95-openstack-%E5%AE%9E%E4%BE%8B/</link>
      <pubDate>Wed, 28 Jun 2023 22:20:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/ssh-%E7%99%BB%E5%BD%95-openstack-%E5%AE%9E%E4%BE%8B/</guid>
      <description>基础配置 添加安全组规则，允许 Ping 和 SSH 访问虚拟机：
openstack security group rule create --proto icmp default root@allone:~# openstack security group rule create --proto icmp default +-------------------+---------------------------+ | Field | Value | +-------------------+-------------------------+ | created_at | 2023-06-28T06:26:10Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | fe9adfc3-dc42-4680-8ecd-ed5a667e1215 | | location | cloud=&amp;#39;&amp;#39;, project.domain_id=, project.domain_name=&amp;#39;Default&amp;#39;, project.id=&amp;#39;6396365541a74b6b8ea8812d1af05e70&amp;#39;, project.name=&amp;#39;admin&amp;#39;, region_name=&amp;#39;&amp;#39;, zone= | | name | None | | port_range_max | None | | port_range_min | None | | project_id | 6396365541a74b6b8ea8812d1af05e70 | | protocol | icmp | | remote_group_id | None | | remote_ip_prefix | 0.</description>
    </item>
    <item>
      <title>VirtualBox Ubuntu 无法联网</title>
      <link>http://localhost:8888/posts/virtualbox-ubuntu%E6%97%A0%E6%B3%95%E8%81%94%E7%BD%91/</link>
      <pubDate>Mon, 26 Jun 2023 22:38:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/virtualbox-ubuntu%E6%97%A0%E6%B3%95%E8%81%94%E7%BD%91/</guid>
      <description>解决方案 VirtualBox Ubuntu 无法联网，重启后可以联网但是几分钟后断开网络。笔者的情况是因为 NetworkManager 自动修改了网络配置导致无法联网，具体现象是开机后网卡信息如下：
user@allone:~$ ifconfig brq64ff9b38-fa: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 ether ce:29:de:12:35:06 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 enp0s3: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet 10.0.2.15 netmask 255.255.255.0 broadcast 10.0.2.255 inet6 fe80::2e8f:2be6:3752:dec4 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 08:00:27:18:31:21 txqueuelen 1000 (Ethernet) RX packets 947 bytes 584483 (584.</description>
    </item>
    <item>
      <title>Ubuntu 18.04 安装Clang/LLVM 11</title>
      <link>http://localhost:8888/posts/ubuntu-18-04-%E5%AE%89%E8%A3%85clang-llvm-11/</link>
      <pubDate>Sat, 24 Dec 2022 15:53:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/ubuntu-18-04-%E5%AE%89%E8%A3%85clang-llvm-11/</guid>
      <description>从 APT 安装 Install the GPG Key for https://apt.llvm.org/
wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - Add the repo for Clang 11 stable-old for Ubuntu 18.04 Bionic
echo &amp;#34;deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-11 main&amp;#34; | sudo tee -a /etc/apt/sources.list sudo apt-get update Install practically everything (except python-clang-11 which for some reason doesn&amp;rsquo;t work)
sudo apt-get install libllvm-11-ocaml-dev libllvm11 llvm-11 llvm-11-dev llvm-11-doc llvm-11-examples llvm-11-runtime \ clang-11 clang-tools-11 clang-11-doc libclang-common-11-dev libclang-11-dev libclang1-11 clang-format-11 clangd-11 \ libfuzzer-11-dev lldb-11 lld-11 libc++-11-dev libc++abi-11-dev libomp-11-dev -y Make Clang 11 and everything related to it defaults</description>
    </item>
    <item>
      <title>每天学命令-chown 修改文件拥有者</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chown%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E6%8B%A5%E6%9C%89%E8%80%85/</link>
      <pubDate>Sun, 04 Dec 2022 16:32:59 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chown%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E6%8B%A5%E6%9C%89%E8%80%85/</guid>
      <description>chown 命令用来变更文件或目录的拥有者或所属群组，通过 chown 改变文件的拥有者和群组。用户可以是用户名或者用户 ID；组可以是组名或者组 ID；文件是以空格分开的文件列表，文件名也支持通配符。
命令格式 chown [选项] [用户或组] [文件或目录] -c或--changes #效果类似“-v”参数，但仅回报更改的部分； -f或--quite或—-silent #不显示错误信息； -h或--no-dereference #只对符号连接的文件作修改，而不更改其他任何相关文件； -R或--recursive #递归处理，将指定目录下的所有文件及子目录一并处理； -v或--version #显示指令执行过程； --dereference #效果和“-h”参数相同； --help #在线帮助 --reference=&amp;lt;参考文件或目录&amp;gt; #把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同； --version #显示版本信息。 实例 将文件test.md拥有者改为nic
chown nic test.md 将目录/home/nic/develop及其下面的所有文件、子目录的文件拥有者改为nic
chown -R nic /home/nic/develop </description>
    </item>
    <item>
      <title>每天学命令-tree 显示目录结构</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-tree%E6%98%BE%E7%A4%BA%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 04 Dec 2022 16:31:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-tree%E6%98%BE%E7%A4%BA%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</guid>
      <description>-a #显示所有文件 -d #只显示目录（名称） -l #显示链接文件的原始文件 -f #显示所列出的文件或目录的完整目录路径 -i #不以阶梯的形式显示文件或目录名称 -q #将控制字符以?字符代替，显示文件和目录名称 -N #直接显示文件或目录的名称 -p #显示每个文件的权限信息 -u #显示文件所有者或者uid -g #显示文件所属组或者gid -s #显示每个文件的大小信息 -h #以可读的方式显示文件的大小信息 -D #显示最后修改日期 -v #按字母数字正序显示文件 -r #按字母数字倒序显示文件 -t #按最后时间排序显示文件 -C #在文件和目录列表上加上色彩，便于区分文件类型 -P pattern #只显示匹配正则表式的文件或目录名称 -I pattern #与上结果相反 实例 显示当前目录及其子目录下的文件及目录名称
$ tree . ├── CODE_OF_CONDUCT.md ├── CONTRIBUTING.md ├── Fedora-35 │ ├── Dockerfile │ └── Readme.md ├── LICENSE ├── README.md ├── Ubuntu-20 │ ├── Dockerfile │ ├── Readme.md │ ├── init_edkrepo_conf.</description>
    </item>
    <item>
      <title>更换 Debian 软件更新源</title>
      <link>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2debian%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</link>
      <pubDate>Sat, 05 Nov 2022 09:27:52 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2debian%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</guid>
      <description>确认 Debian 版本 $ cat /etc/os-release PRETTY_NAME=&amp;#34;Debian GNU/Linux 10 (buster)&amp;#34; NAME=&amp;#34;Debian GNU/Linux&amp;#34; VERSION_ID=&amp;#34;10&amp;#34; VERSION=&amp;#34;10 (buster)&amp;#34; VERSION_CODENAME=buster ID=debian HOME_URL=&amp;#34;https://www.debian.org/&amp;#34; SUPPORT_URL=&amp;#34;https://www.debian.org/support&amp;#34; BUG_REPORT_URL=&amp;#34;https://bugs.debian.org/&amp;#34; 括号里的buster就是版本信息。
获取镜像地址 打开debian | 清华大学开源软件镜像站，选择buster版本，复制所有镜像地址。
# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free deb https://mirrors.</description>
    </item>
    <item>
      <title>Makefile 基础</title>
      <link>http://localhost:8888/posts/makefile%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Mon, 26 Sep 2022 21:36:18 +0000</pubDate>
      <guid>http://localhost:8888/posts/makefile%E5%9F%BA%E7%A1%80/</guid>
      <description>目标、依赖、命令 目标就是我们要去 make xxx 的那个 xxx，就是我们最终要生成的东西。 依赖是用来生成目录的原材料 命令就是加工方法，所以 make xxx 的过程其实就是使用命令将依赖加工成目标的过程。 通配符 % 和 Makefile 自动推导 % 是 Makefile 中的通配符，代表一个或几个字母。也就是说%.o就代表所有以.o为结尾的文件。 所谓自动推导其实就是 Makefile 的规则。当 Makefile 需要某一个目标时，他会把这个目标去套规则说明，一旦套上了某个规则说明，则 Makefile 会试图寻找这个规则中的依赖，如果能找到则会执行这个规则用依赖生成目标。 Makefile 中定义和使用变量 Makefile 中定义和使用变量，和 shell 脚本中非常相似。相似的是都没有变量类型，直接定义使用，引用变量时用$var。 伪目标（.PHONY） 伪目标意思是这个目标本身不代表一个文件，执行这个目标不是为了得到某个文件或东西，而是单纯为了执行这个目标下面的命令。 伪目标一般都没有依赖，因为执行伪目标就是为了执行目标下面的命令。既然一定要执行命令了那就不必加依赖，因为不加依赖意思就是无条件执行。 伪目标可以直接写，不影响使用；但是有时候为了明确声明这个目标是伪目标会在伪目标的前面用.PHONY来明确声明它是伪目标。 Makfile 中引用其他 Makefile 有时候 Makefile 总体比较复杂，因此分成好几个 Makefile 来写。然后在主 Makefile 中引用其他的，用 include 指令来引用。引用的效果也是原地展开，和 C 语言中的头文件包含非常相似。 赋值 =最简单的赋值 :=一般也是赋值 以上这两个大部分情况下效果是一样的，但是有时候不一样。用=赋值的变量，在被解析时他的值取决于最后一次赋值时的值，所以你看变量引用的值时不能只往前面看，还要往后面看。用:=来赋值的，则是就地直接解析，只用往前看即可。
?=如果变量前面并没有赋值过则执行这条赋值，如果前面已经赋值过了则本行被忽略。（实验可以看出：所谓的没有赋值过其实就是这个变量没有被定义过） +=用来给一个已经赋值的变量接续赋值，意思就是把这次的值加到原来的值的后面，有点类似于 strcat。（注意一个细节，+=续接的内容和原来的内容之间会自动加一个空格隔开） 注意：Makefile 中并不要求赋值运算符两边一定要有空格或者无空格，这一点比 shell 的格式要求要松一些。
Makefile 的环境变量 makefile 中用 export 导出的就是环境变量。一般情况下要求环境变量名用大写，普通变量名用小写。 环境变量和普通变量不同，可以这样理解：环境变量类似于整个工程中所有 Makefile 之间可以共享的全局变量，而普通变量只是当前本 Makefile 中使用的局部变量。所以要注意：定义了一个环境变量会影响到工程中别的 Makefile 文件，因此要小心。 Makefile 中可能有一些环境变量可能是 makefile 本身自己定义的内部的环境变量或者是当前的执行环境提供的环境变量（譬如我们在 make 执行时给 makefile 传参。make CC=arm-linux-gcc，其实就是给当前 Makefile 传了一个环境变量 CC，值是 arm-linux-gcc。我们在 make 时给 makefile 传的环境变量值优先级最高的，可以覆盖 makefile 中的赋值）。这就好像 C 语言中编译器预定义的宏__LINE__ __FUNCTION__等一样。 Makefile 中使用通配符 *：若干个任意字符 ?</description>
    </item>
    <item>
      <title>嵌入式 Shell 基础</title>
      <link>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Fshell%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Sun, 25 Sep 2022 22:35:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E5%B5%8C%E5%85%A5%E5%BC%8Fshell%E5%9F%BA%E7%A1%80/</guid>
      <description>脚本语言 常用的脚本语言有 sh、bash、csh、ksh、perl、python； 在 Linux 下常用的脚本语言其实就是 bash、sh； 脚本语言一般在嵌入式中应用，主要是用来做配置。（一个复杂的嵌入式程序都是可配置的，配置过程就是用脚本语言来实现的）自然不会使用过于复杂的脚本语言特性，因此只需要针对性的学习即可。 shell 脚本的运行机制 C/C++ 语言这种编写过程是：编写出源代码（源代码是不能直接运行的）然后编译链接形成可执行二进制程序，然后才能运行；而脚本程序不同，脚本程序编写好后源代码即可直接运行（没有编译链接过程）； shell 程序是解释运行的，所谓解释运行就是说当我们执行一个 shell 程序时，shell 解析器会逐行的解释 shell 程序代码，然后一行一行的去运行。（顺序结构） CPU 实际只认识二进制代码，根本不认识源代码。脚本程序源代码其实也不是二进制代码，CPU 也不认识，也不能直接执行。只不过脚本程序的编译链接过程不是以脚本程序源代码为单位进行的，而是在脚本运行过程中逐行的解释执行时才去完成脚本程序源代码转成二进制的过程（不一定是编译链接，因为这行脚本程序可能早就编译连接好了，这里我们只是调用它）。 动手写第一个 shell 编辑器与编译器 shell 程序是文本格式的，只要是文本编辑器都可以。但是因为我们的 shell 是要在 Linux 系统下运行的，所以换行符必须是\n，而 Windows 下的换行符是\r\n，因此 Windows 中的编辑器写的 shell 不能在 Linux 下运行。 编译器不涉及，因为 shell 是解释性语言，直接编辑完就可以运行。 shell 程序运行的运行的三种方法 ./xx.sh，和运行二进制可执行程序方法一样。这样运行 shell 要求 shell 程序必须具有可执行权限。chmod a+x xx.sh 来添加可执行权限。 source xx.sh，source 是 Linux 的一个命令，这个命令就是用来执行脚本程序的。这样运行不需要脚本具有可执行权限。 bash xx.sh，bash 是一个脚本程序解释器，本质上是一个可执行程序。这样执行相当于我们执行了 bash 程序，然后把 xx.sh 作为 argv[1] 传给他运行。 hello world 程序和解释 shell 程序的第一行一般都是以#!</description>
    </item>
    <item>
      <title>每天学命令-chattr 修改文件与目录属性防止误删除</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chattr%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E5%B1%9E%E6%80%A7%E9%98%B2%E6%AD%A2%E8%AF%AF%E5%88%A0%E9%99%A4/</link>
      <pubDate>Sun, 25 Sep 2022 11:20:35 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-chattr%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E5%B1%9E%E6%80%A7%E9%98%B2%E6%AD%A2%E8%AF%AF%E5%88%A0%E9%99%A4/</guid>
      <description>使用背景 chattr命令可以修改 Linux 的文件属性，在类 Unix 等发行版中，该命令能够有效防止文件和目录被意外的删除或修改。文件在 Linux 中被描述为一个数据结构，chattr 命令在大多数现代 Linux 操作系统中是可用的，可以修改文件属性，一旦定义文件的隐藏属性，那么该文件的拥有者和 root 用户也无权操作该文件，只能解除文件的隐藏属性。这就可以有效的避免被误删除。
命令格式 一个完整的命令一般由命令 (chattr)，可选项 (option)，操作符 (operator) 与属性 (attribute) 组成：
chattr [option] [operator] [attribute] file [option] 可选项：
-R， 递归更改目录及其内容的属性。 -V， 详细说明chattr的输出并打印程序版本。 -f， 隐藏大多数错误消息。 [operator] 操作符：
+，追加指定属性到文件已存在属性中 -， 删除指定属性 =，直接设置文件属性为指定属性 [attribute] 属性如下：
a， 只能向文件中添加数据 A，不更新文件或目录的最后访问时间 i， 文件或目录不可改变 使用实例 lsattr 命令检查文件已有属性 -d：如果目标是目录，只会列出目录本身的隐藏属性，而不会列出所含文件或子目录的隐藏属性信息 -R：作用于目录时，会显示所有的子目录和文件的隐藏信息 $ lsattr clash --------------e------- clash/glados.yaml --------------e------- clash/clash-linux-386-v1.10.0 --------------e------- clash/Country.mmdb --------------e------- clash/cache.db --------------e------- clash/clash-linux-amd64-v1.10.0 --------------e------- clash/dashboard $ lsattr -d clash --------------e------- clash $ lsattr -R clash --------------e------- clash/glados.</description>
    </item>
    <item>
      <title>解决 Linux 终端回车键变成字符 M</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E9%94%AE%E5%8F%98%E6%88%90%E5%AD%97%E7%AC%A6m/</link>
      <pubDate>Mon, 12 Sep 2022 14:52:12 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E9%94%AE%E5%8F%98%E6%88%90%E5%AD%97%E7%AC%A6m/</guid>
      <description>保留现场 解决方法 命令行执行
stty sane </description>
    </item>
    <item>
      <title>Linux 下切换 Python 版本</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E4%B8%8B%E5%88%87%E6%8D%A2python%E7%89%88%E6%9C%AC/</link>
      <pubDate>Mon, 12 Sep 2022 14:05:17 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E4%B8%8B%E5%88%87%E6%8D%A2python%E7%89%88%E6%9C%AC/</guid>
      <description>需求背景 用过 Python 的都知道，Python 是不向后兼容的，也就是 Python3.X 开发的程序，使用 Python2.X 环境就无法正常运行。因为很多语法都改变了。现在接触到的大部分 Python 程序都是 Python3.X 开发的，但是偶尔也会遇到使用 Python2.X 的时候。这就需要灵活切换版本。
一般 Linux 的各个发行版都预装了 Python2.X。我使用的 Debian 就预装了 Python2.7。
$ python -V Python 2.7.16 但是我同时也安装了 Python3.7
$ ls /usr/bin | grep &amp;#34;python*&amp;#34; dh_python2 python python2 python2.7 python3 python3.7 python3.7m python3m alias 修改别名 $ alias python=/usr/bin/python3 $ python -V Python 3.7.3 上面的别名修改只对当前终端有效。如果要使每个窗口都使用这个别名，将别名加入~/.bashrc，如 zsh 是则是~/.zshrc。
软链接 和修改别名类似
ln -s python /usr/bin/python3 update-alternatives update-alternatives是 Debian 系统提供的一个工具，Ubuntu 是基于 Debian 的，所以 Ubuntu 也可以使用，其他发行版没有该工具。它可以用来方便快捷地切换应用版本，不仅仅用来切换 Python，其他应用程序有多个版本的也可以使用该工具。</description>
    </item>
    <item>
      <title>每天学命令-nohup 后台运行</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-nohup%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/</link>
      <pubDate>Sat, 10 Sep 2022 17:14:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-nohup%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/</guid>
      <description>使用 MobaXertm 连接服务器后，想要在运行一个下载任务，使用&amp;amp;挂在后台后，退出 MobaXterm，后台的任务也随之中断，于是搜到这个nohup命令，可以完成我的需求。
nohup意思是 No Hang Up，不要挂起的意思，即使退出终端也不会中断任务。
为了方便以后查阅，这里总结一下关于后台运行相关的命令。首先是最常用的&amp;amp;符号。
&amp;amp; 后台运行 比如执行编译任务时通常会占用终端前台，这时候无法再执行其他命令，除非再开一个终端，对于有 GUI 界面时，再开一个终端很方便，但是如果是服务器就只能再想办法了。 &amp;amp;可以将命令执行过程放在后台运行，如：
$ make &amp;gt; make.log 2&amp;gt;&amp;amp;1 &amp;amp; [1] 16586 2&amp;gt;&amp;amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了make.log文件，即将标准出错也输出到make.log文件中。最后一个&amp;amp;，是让该命令在后台执行。 试想2&amp;gt;1代表什么，2与&amp;gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&amp;gt;&amp;amp;1，&amp;amp;与1结合就代表标准输出了，就变成错误重定向到标准输出。
在后台运行make进行编译，并将输出结果（错误和正常输出）都保存到make.log文件中，提交任务成功后，会显示进程 ID，编译的进程 ID 为 16586。
有了进程 ID 我们可以监控，也可以中断进程：
# 查看进程状态 ps -ef | grep 16586 # 中断进程 kill -9 16586 但是使用 &amp;amp;时关闭终端后，进程也会随之关闭。如果想要在后台持续运行程序，就需要nohup命令。
nohup 使用 $ nohup make &amp;gt; make.log 2&amp;gt;&amp;amp;1 &amp;amp; [1] 112233 命令功能同上，但是终端关闭，后台程序也会继续执行。
NOTE：终端关闭，是指带 GUI 的界面里终端，如果使用 SSH 等登陆，比如使用 MobaXterm，一个 session 相当于一个登陆账户，如果异常退出了这个账户，那么后台执行的程序也会中断。如果需要继续执行，需要正常退出账户，执行exit命令。
汇总 fg # 将后台中的命令调至前台继续运行 bg # 将一个在后台暂停的命令，变成继续执行 (在后台执行) jobs # 查看当前有多少在后台运行的命令 kill %num # 终止进程num &amp;amp; # 加在命令后可以将其置于后台运行 ctrl + z # 置于后台，并且暂停不可执行 ctrl + c # 终止前台进程 ctrl + \ # 退出 ctrl + d # 结束当前输入(即用户不再给当前程序发出指令)，那么Linux通常将结束当前程序 </description>
    </item>
    <item>
      <title>从零开始搭建一台 NAS 存储服务器</title>
      <link>http://localhost:8888/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0nas%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Sat, 10 Sep 2022 11:37:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0nas%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>技术没学多少，教程下满了硬盘，一直想专门部署 NAS 来存文件，但是一来要花钱，二来搭建 NAS 没有经验怕部署不好，没有现在硬盘直连舒适，所以将就用吧。
自从有天忘了忘了休眠电脑，一个自动备份任务开启，在 40 度的高温天，满速跑了一天，下班回来硬盘直接报废。这就加速我折腾部署 NAS 的进程。
准备阶段 威联通的几款中意的 NAS 放购物车很久了，如果硬盘没有这么早坏掉，可能在双十一就买整机了，现在离双十一还早，硬件价格都不便宜，想来想去还是买二手硬件攒一台更划算。如果买整机，硬盘加 NAS 主机就得五千大洋，只是用来存文件，部署个 Jellyfin 看电影用，属实奢侈了。
￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥
买二手就得从零开始学。生命不休，折腾不止。经过一次完整的 NAS 攒机过程发现，其实 NAS 就是安装了专用系统的一台电脑而已。这个专用系统就是面向网络存储开发的，如群晖，威联通，开源的 OMV，FreeNAS 等等。
既然是一台电脑，其实攒 NAS 就和攒电脑一样，选配好以下几大件即可。
CPU 主板 散热器 机箱 内存 电源 机箱风扇 下面分别介绍在攒机过程中遇到的一些概念，参数到底是什么意思。
CPU CPU 型号字母数字都是什么意思 Intel 是英特尔的英文名称，也是目前热门的 CPU 品牌； “酷睿”代表英特尔品牌下面向普通消费者的一个 CPU 系列，一般划分为 Core（酷睿）、Pentium（奔腾）、Celeron（赛扬）、Xeon（至强）、Atom（凌动）等； i5 代表这款 CPU 定位中端，在其下面还有 i3，在其上面还有 i7 和 i9，同一代中，数字越大，性能越强；但是不同代 - 数之间，性能不能直接相比，比如 12 代的 i5 在理论性能上是强于 10 代 i7 的。 12 代表这款 CPU 的代数，说明其已经发展到第十二代了，数字越大越新； 600 这三位数字代表 Intel SKU 型号划分，一般来说 Core i7 有固定几个 SKU，比方说 700；Core i5有600/500/400；Core i3有300/100等等，一般来说数字越大说明隶属的Core系列越高级，同级别下比较，数字越大频率越高，换句话说性能就越强，比方说Core i5-8600 默认 3.</description>
    </item>
    <item>
      <title>Linux 终端回车变成^M</title>
      <link>http://localhost:8888/posts/linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E5%8F%98%E6%88%90-m/</link>
      <pubDate>Mon, 05 Sep 2022 15:37:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E7%BB%88%E7%AB%AF%E5%9B%9E%E8%BD%A6%E5%8F%98%E6%88%90-m/</guid>
      <description>解决方法 终端执行：
stty sane 参考 command line - Pressing enter produces ^M instead of a newline - Ask Ubuntu</description>
    </item>
    <item>
      <title>Linux 切换不同 Python 版本</title>
      <link>http://localhost:8888/posts/linux%E5%88%87%E6%8D%A2%E4%B8%8D%E5%90%8Cpython%E7%89%88%E6%9C%AC/</link>
      <pubDate>Mon, 05 Sep 2022 15:31:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%88%87%E6%8D%A2%E4%B8%8D%E5%90%8Cpython%E7%89%88%E6%9C%AC/</guid>
      <description></description>
    </item>
    <item>
      <title>每天学命令-生成指定大小文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 23 Jul 2022 16:14:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-%E7%94%9F%E6%88%90%E6%8C%87%E5%AE%9A%E5%A4%A7%E5%B0%8F%E6%96%87%E4%BB%B6/</guid>
      <description>使用背景 在测试下载速度，或者测试加解密文件，亦或者制作文件系统时都需要一些指定大小的文件。Linux 有一些命令可以快速完成这样的任务。接下来介绍几个好用的命令。
空洞文件 在 Unix 文件操作中，操作文件的位移量可以大于文件的当前长度，在下一次写操作时，就会把文件撑大（Extend），在文件里创建空洞（Hole），没有被实际写入的部分都是 0。空洞文件是否占用实际磁盘空间由文件系统觉得，Linux 中空洞文件不占用实际磁盘空间。
fallocate fallocate用于将块预分配给文件。对于支持fallocate系统调用的文件系统，这可以通过分配块并将其标记为未初始化来快速完成，因此不需要对数据块进行 I/O 操作。这是创建文件而不是用零填充的更快的方法。大文件几乎可以立即创建，而不必等待任何 I/O 操作完成。
语法：
fallocate [-n] [-o offset] -l length filename d: 检测零并替换为空洞。 -n：指定文件的大小，单位为字节。 -o：指定文件的偏移量，可以跟二进制$2^{N}$后缀KiB，MiB，GiB，TiB，PiB和EiB（iB为可选，例如，K的含义与KiB的含义相同或后缀KB，MB，GB，PB和EB的十进制（$10^{N}$）。 -l：指定文件的大小，单位同上。 -p, --punch-hole: 将某个范围替换为空洞 (连带打开 -n)。 filename：指定文件名。 示例： 分配一个大小为512MB的文件，文件名为efi.img：
fallocate -l 512M efi.img 将efi.img文件中的0替换为空洞：
fallocate -d efi.img 从偏移 128M 的位置挖一个 10M 大小的洞
fallocate -p -o 128M -l 10M efi.img dd Linux dd 命令用于读取、转换并输出数据。dd 可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出
dd 的原意为 data duplicator，但由于 dd 属于较低阶的资料处理工具，通常都会以管理者（root）权限来执行，如果稍有不慎，也很容易造成严重的后果（例如整颗硬碟的资料不见等等），所以有些人也把 dd 取名为 data destroyer。dd 指令教学与实用范例，备份与回复资料的小工具 - GT Wang</description>
    </item>
    <item>
      <title>理解虚拟内存</title>
      <link>http://localhost:8888/posts/%E7%90%86%E8%A7%A3%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</link>
      <pubDate>Sun, 17 Jul 2022 21:45:20 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E7%90%86%E8%A7%A3%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</guid>
      <description>为什么需要虚拟内存？ CPU 访问内存的最自然的方式就是使用物理地址，这种方式称为物理寻址。1，计算机中并不是只有一个程序在运行，如果它们都是用物理寻址的方式，那么所有程序必须在链接之前确定好自己所用到的内存范围，否则两个程序就可能会发生冲突。2，程序大于内存的问题早在上世纪六十年代就出现，后来出现了覆盖技术（Overlay），把程序分割成许多片段。程序开始执行时，将覆盖管理模块装入内存，该管理模块立即装入并运行覆盖 0。执行完成后，覆盖 0 通知管理模块装入覆盖 1，或者占用覆盖 0 的上方位置（如果有空间），或者占用覆盖 0（如果没有空间）。把一个大程序分割成小的、模块化的片段是非常费时和枯燥的，并且易于出错。很少程序员擅长使用覆盖技术。
为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存(VM)。主要有三个功能：
它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 它为每个进程提供了一致的地址空间，从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 什么是虚拟寻址？ 如果主存被分为长度为$M$的单字节大小的数组，每个字节都对应一个物理地址，CPU 通过这个唯一的地址访问主存，这样的方式就是物理寻址。 现代处理器使用虚拟寻址的方式。CPU 通过生成的虚拟地址来访问内存，这个地址在送到内存之前会被转换成物理地址。这个过程称为地址翻译。CPU 芯片上叫做内存管理单元（Memory Management Unit, MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。 虚拟内存作为缓存的工具 概念上而言，虚拟内存被组织成为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组，也就是字节数组。每个字节都有一个唯一的虚拟地址作为数组的索引。磁盘上活动的数组内容被缓存在主存中。在存储器结构中，较低层次上的磁盘的数据被分割成块，这些块作为和较高层次的主存之间的传输单元。主存作为虚拟内存的缓存。
虚拟内存被分割为大小固定的块，这些块叫虚拟页（Virtual Page，VP），类似的物理内存也有物理页(Physical Page, PP)。虚拟页有三种不同的状态：
未分配：VM 系统还未分配 (或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。 已缓存：当前已缓存在物理内存中的已分配页。 未缓存：未缓存在物理内存中的已分配页。 为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语SRAM缓存来表示位于 CPU 和主存之间的 Ll、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页。
在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。回想一下，DRAM 比 SRAM 要慢大约 10 倍，而磁盘要比 DRAM 慢大约 100000 多倍。因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多。因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。（这些替换算法超出了我们的讨论范围）。最后，因为对磁盘的访问时间很长，DRAM 缓存总是使用写回，而不是直写。
页表 虚拟内存系统可以完成以下这些功能，
判定一个虚拟页是否缓存在 DRAM 中的某个地方； 可以确定这个虚拟页存放在哪个物理页中； 如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。 这些功能是由软硬件联合提供的，包括操作系统软件、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表（page table）的数据结构。页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页。</description>
    </item>
    <item>
      <title>C 语言 getopt() 函数的用法</title>
      <link>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80getopt-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/</link>
      <pubDate>Sat, 16 Jul 2022 22:42:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/c%E8%AF%AD%E8%A8%80getopt-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/</guid>
      <description>在做CSAPP_LAB-Cache Lab时，实验要求对输入参数进行处理，如程序csim执行需要 4 个参数：
./csim -s 4 -E 6 -b 4 -t &amp;lt;tracefile&amp;gt; 原先想通过字符串解析，一个个处理，但是看到了其他参考代码后发现了一个更简单的方法，可以通过getopt()函数来解析参数。
函数的功能：解析命令行参数。 头文件 #include &amp;lt;unistd.h&amp;gt;
在学习函数前需要了解与该函数相关的四个变量：
int opterr：控制是否输出错误； 如果此变量的值非零，则 getopt 在遇到未知选项字符或缺少必需参数的选项时将错误消息打印到标准错误流 (终端)。该值默认为非零。如果将此变量设置为零，getopt 不会打印任何消息，但仍会返回问号?提示错误。
int optopt：保存未知的选项； 当 getopt 遇到未知选项字符或缺少必需参数的选项时，它将该选项字符存储在此变量中。
int optind：指向下一个要处理的参数； 此变量由 getopt 设置为要处理的 argv 数组的下一个元素的索引。一旦 getopt 找到所有选项参数，就可以使用此变量来确定其余非选项参数的开始位置。该变量的初始值为 1。
char * optarg：保存选项参数； 对于那些接受参数的选项，此变量由 getopt 设置为指向选项参数的值。
函数原型：
int getopt(int argc, char * const argv[], const char * options); 参数解析：
参数argc 和argv 是由main()传递的参数个数和内容。 options 参数是一个字符串，它指定对该程序有效的选项字符。此字符串中的选项字符后面可以跟一个冒号（:），表示它需要一个必需的参数，这个参数可以与选项连写也可以空格分开，如-a13 or -a 13。如果选项字符后跟两个冒号（::），则其参数是可选的，如果有参数，那么参数不能与选项分割，如只能写成-a13而不能写成-a 13；这是一个 GNU 扩展。 实例：</description>
    </item>
    <item>
      <title>构建和测试 RISC-V 架构下启用 ACPI 的内核</title>
      <link>http://localhost:8888/posts/%E6%9E%84%E5%BB%BA%E5%92%8C%E6%B5%8B%E8%AF%95risc-v%E6%9E%B6%E6%9E%84%E4%B8%8B%E5%90%AF%E7%94%A8acpi%E7%9A%84%E5%86%85%E6%A0%B8/</link>
      <pubDate>Tue, 12 Jul 2022 15:06:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%9E%84%E5%BB%BA%E5%92%8C%E6%B5%8B%E8%AF%95risc-v%E6%9E%B6%E6%9E%84%E4%B8%8B%E5%90%AF%E7%94%A8acpi%E7%9A%84%E5%86%85%E6%A0%B8/</guid>
      <description>参考自PoC : How to build and test ACPI enabled kernel · riscv-non-isa/riscv-acpi Wiki
准备环境及工具链 安装 RISC-V 工具链，需下载原发行版。好在 apt 可以安装。
如果报错：riscv64-linux-gnu-gcc: error: unrecognized command line option ‘-mno-relax’; did you mean ‘-Wno-vla’?，多半是工具链原因，请按照以下方法安装！！！
sudo apt remove gcc-riscv64-linux-gnu sudo apt install gcc-8-riscv64-linux-gnu 安装必要的三方库，以下为Ubuntu下的命令，其他平台可以参考这个文档。
sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \ gawk build-essential bison flex texinfo gperf libtool patchutils bc \ zlib1g-dev libexpat-dev git 下载源码 可能无法一次搭建成功，一些环境变量会经常用到，所以干脆把所有环境变量放到.bashrc。
vim ~/.bashrc # 添加以下内容 export WORK_DIR=~/riscv64-acpi export GCC5_RISCV64_PREFIX=riscv64-unknown-elf- export MAINSPACE=~/riscv64-acpi/tianocore export PACKAGES_PATH=$MAINSPACE/edk2:$MAINSPACE/edk2-platforms export EDK_TOOLS_PATH=$MAINSPACE/edk2/BaseTools 首先，创建一个工作目录，我们将在其中下载并构建所有源代码。</description>
    </item>
    <item>
      <title>CSAPP-LAB-Cache Lab</title>
      <link>http://localhost:8888/posts/csapp-lab-cache-lab/</link>
      <pubDate>Mon, 11 Jul 2022 09:55:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/csapp-lab-cache-lab/</guid>
      <description>预备知识 开始这个实验前，需要学习《CSAPP 第六章-存储器层次结构》的相关内容，与缓存相关的内容，我也做了相关的CPU Cache 高速缓存学习记录可以参考。
实验相关的文件可以从CS:APP3e, Bryant and O&amp;rsquo;Hallaron下载。
其中，
README：介绍实验目的和实验要求，以及实验的相关文件。需要注意的是，必须在 64-bit x86-64 system 上运行实验。需要安装 Valgrind 工具。 Writeup：实验指导。 Release Notes：版本发布信息。 Self-Study Handout：需要下载的压缩包，里面包含了待修改的源码文件等。 下载 Self-Study Handout 并解压，得到如下文件：
├── cachelab.c # 一些辅助函数，如打印输出等，不需要修改 ├── cachelab.h # 同上 ├── csim.c # 需要完善的主文件，需要在这里模拟Cache ├── csim-ref # 已经编译好的程序，我们模拟的Cache需要与这个程序运行的结果保持一致 ├── driver.py # 驱动程序，运行 test-csim 和 test-trans ├── Makefile # 用来编译csim程序 ├── README # ├── test-csim # 测试缓存模拟器 ├── test-trans.c # 测试转置功能 ├── tracegen.c # test-trans 辅助程序 ├── traces # test-csim.</description>
    </item>
    <item>
      <title>每天学命令-watch 周期执行命令</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-watch%E5%91%A8%E6%9C%9F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Thu, 09 Jun 2022 22:50:54 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-watch%E5%91%A8%E6%9C%9F%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/</guid>
      <description>功能 watch 命令的功能如其名，可以监视命令的执行结果。它实现的原理就是每隔一段时间执行一次命令，然后显示结果。他的用途很广，具体怎么用就靠想象力了。
命令参数 -n # 或--interval watch默认每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。-d # 或--differences 用-d或--differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。-t # 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。-h # 或--help # 查看帮助文档 实例 watch -d &amp;#39;ls -l | grep tmp&amp;#39; # 监测当前目录中 scf&amp;#39; 的文件的变化 </description>
    </item>
    <item>
      <title>CPU 亲和性与中断亲和性</title>
      <link>http://localhost:8888/posts/cpu%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E4%B8%AD%E6%96%AD%E4%BA%B2%E5%92%8C%E6%80%A7/</link>
      <pubDate>Mon, 23 May 2022 22:38:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/cpu%E4%BA%B2%E5%92%8C%E6%80%A7%E4%B8%8E%E4%B8%AD%E6%96%AD%E4%BA%B2%E5%92%8C%E6%80%A7/</guid>
      <description>预备知识 超线程技术 (Hyper-Threading)：就是利用特殊的硬件指令，把两个逻辑内核 (CPU core) 模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了 CPU 的闲置时间，提高的 CPU 的运行效率。
我们常听到的双核四线程/四核八线程指的就是支持超线程技术的CPU.
物理 CPU：机器上安装的实际 CPU, 比如说你的主板上安装了一个 8 核 CPU，那么物理 CPU 个数就是 1 个，所以物理 CPU 个数就是主板上安装的 CPU 个数。
逻辑 CPU：一般情况，我们认为一颗 CPU 可以有多核，加上 Intel 的超线程技术 (HT), 可以在逻辑上再分一倍数量的 CPU core 出来；
逻辑CPU数量 = 物理CPU数量 x CPU cores x 2(如果支持并开启HT) //前提是CPU的型号一致，如果不一致只能一个一个的加起来，不用直接乘以物理CPU数量//比如你的电脑安装了一块4核CPU，并且支持且开启了超线程（HT）技术，那么逻辑CPU数量 = 1 × 4 × 2 = 8 Linux 下查看 CPU 相关信息, CPU 的信息主要都在/proc/cupinfo中。
# 查看物理CPU个数➜ ~ cat /proc/cpuinfo|grep &amp;#34;physical id&amp;#34;|sort -u|wc -l32# 查看每个物理CPU中core的个数(即核数)➜ ~ cat /proc/cpuinfo|grep &amp;#34;cpu cores&amp;#34;|uniq1# 或者➜ cat /proc/cpuinfo | grep &amp;#39;process&amp;#39; | sort | uniq | wc -l1# 查看逻辑CPU的个数➜ ~ cat /proc/cpuinfo|grep &amp;#34;processor&amp;#34;|wc -l32# 查看CPU的名称型号➜ ~ cat /proc/cpuinfo|grep &amp;#34;name&amp;#34;|cut -f2 -d:|uniqIntel Xeon Processor (Skylake, IBRS) Linux 查看某个进程运行在哪个逻辑 CPU 上</description>
    </item>
    <item>
      <title>QEMU 源码分析-QOM</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-qom/</link>
      <pubDate>Wed, 09 Mar 2022 16:02:19 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-qom/</guid>
      <description>QOM 简介 QOM(QEMU Object Model) 是 QEMU 的一个模块，用于描述虚拟机的结构，包括虚拟机的 CPU、内存、硬盘、网络、输入输出设备等。QEMU 为了方便整个系统的构建，实现了自己的一套的面向对象机制，也就是 QOM(QEMU Object Model)。它能够方便的表示各个设备（Device）与总线（Bus）之间的关系。
这个模型主要包含四个结构体：
Object: 是所有对象的 基类 Base Object ObjectClass: 是所有类对象的基类 TypeInfo：是用户用来定义一个 Type 的工具型的数据结构 TypeImpl：TypeInfo 抽象数据结构，TypeInfo 的属性与 TypeImpl 的属性对应 在 QEMU 里要初始化一个对象需要完成四步：
将 TypeInfo 注册 TypeImpl 实例化 Class（ObjectClass） 实例化 Object 添加 Property QOM 中的面向对象 继承 在 QEMU 中通过 TypeInfo 来定义一个类。
例如 x86_base_cpu_type_info 就是一个 class，
static const TypeInfo x86_base_cpu_type_info = { .name = X86_CPU_TYPE_NAME(&amp;#34;base&amp;#34;), .parent = TYPE_X86_CPU, .class_init = x86_cpu_base_class_init, }; 利用结构体包含来实现继承。这应该是所有的语言实现继承的方法，在 C++ 中，结构体包含的操作被语言内部实现了，而 C 语言需要自己实现。</description>
    </item>
    <item>
      <title>QEMU 源码分析-内存虚拟化</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</link>
      <pubDate>Tue, 25 Jan 2022 13:42:11 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96/</guid>
      <description>1.大部分转载自QEMU 内存虚拟化源码分析 | Keep Coding | 苏易北 2.原文源码为 QEMU1.2.0，版本较旧，部分源码内容根据 QEMU6.2 版本修改 3.部分内容根据自己理解补充添加
概述 我们知道操作系统给每个进程分配虚拟内存，通过页表映射，变成物理内存进行访问。当有了虚拟机之后，情况会变得更加复杂。因为虚拟机对于物理机来讲是一个进程，但是虚拟机里面也有内核，也有虚拟机里面跑的进程。所以有了虚拟机，内存就变成了四类：
虚拟机里面的虚拟内存（Guest OS Virtual Memory，GVA），这是虚拟机里面的进程看到的内存空间； 虚拟机里面的物理内存（Guest OS Physical Memory，GPA），这是虚拟机里面的操作系统看到的内存，它认为这是物理内存； 物理机的虚拟内存（Host Virtual Memory，HVA），这是物理机上的 qemu 进程看到的内存空间； 物理机的物理内存（Host Physical Memory，HPA），这是物理机上的操作系统看到的内存。 内存虚拟化的关键在于维护 GPA 到 HVA 的映射关系。
页面分配和映射的两种方式 要搞清楚 QEMU system emulation 的仿真架构，首先对于 Host OS，将 QEMU 作为进程启动，然后对于 QEMU 进程，会仿真各种硬件和运行 Guest OS，在这层 OS 上运行要全系统模拟的应用程序，因此对于 Guest OS 管理的内存要实现到 QEMU 进程的虚拟空间的转换需要 softMMU（即需要对 GPA 到 HVA 进行转换）。从 GVA 到 GPA 到 HVA 到 HPA，性能很差，为了解决这个问题，有两种主要的思路。
影子页表 Shadow Page Table，SPT 第一种方式就是软件的方式，影子页表（Shadow Page Table）。</description>
    </item>
    <item>
      <title>Linux 帧缓冲</title>
      <link>http://localhost:8888/posts/linux%E5%B8%A7%E7%BC%93%E5%86%B2/</link>
      <pubDate>Mon, 17 Jan 2022 17:38:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%B8%A7%E7%BC%93%E5%86%B2/</guid>
      <description>简介 FrameBuffer 是内核当中的一种驱动程序接口。Linux 是工作在保护模式下，所以用户态进程是无法象 DOS 那样使用显卡 BIOS 里提供的中断调用来实现直接写屏，Linux 抽象出 FrameBuffer 这个设备来供用户态进程实现直接写屏。
帧缓冲主要结构 fb_info 该结构体记录当前帧缓冲设备的状态信息，如果系统中有多个帧缓冲设备，就需要两个fb_info结构，这个结构只在内核中可以看到，对用户空间不可见。
fb_var_screeninfo 该结构体记录指定的帧缓冲设备和显示模式中可以被修改的信息，其中包括显示器分辨率等信息。
fb_fix_screeninfo 该结构体表示帧缓冲设备中一些不能修改的参数，包括特定的显示模式，屏幕缓冲区的物理地址，显示缓冲区的长度信息。
fb_ops LCD底层硬件操作接口集。比如fb_open、fb_release、fb_read、fb_write、fb_ioctl、fb_mmap等：
fb_cmap fb_cmap指定颜色映射，用于以内核可以理解的方式存储用户的颜色定义。
帧缓冲显示原理 帧缓冲设备是一种显示抽象的设备，也可以被理解为它是一个内存区域，上面的应用程序可以直接对显示缓冲区进行读和写操作，就像访问文件的通用接口一样，用户可以认为帧缓冲是一块内存，能读取数据的内存块也可以向这个内存写入数据，因此显示器显示图形界面实际上根据根据的是指定的内存数据块内的数据。
帧缓冲的显示缓冲区位于 Linux 内核地址空间，应用程序不能直接访问内核地址空间，在 Linux 中，只有一个内存的内核地址空间映射到用户地址空间才可以由用户访问，内存的映射是通过MMAP函数实现的在 Linux 中。对于帧缓冲，虚拟地址是通过内存映射的方法将显示缓冲区内核地址映射到用户空间的，然后用户可以通过读和写这部分的虚拟地址来访问显示缓冲区，在屏幕上绘图。
使用流程 使用帧缓冲之前应该首先确定 Linux 系统上已安装了帧缓冲驱动，可以在目录/dev/下查找fb*如，/dev/fb0, /dev/fb1等设备来确定是否安装。如果没有需要安装一个帧缓冲驱动的模块到内核，或者重新编译内核生成一个带帧缓冲模块的镜像。
使用帧缓冲需要进入控制台模式，即纯命令行的模式进行编程。一般可以通过快捷键CTRL+ALT+F1进入控制台模式，CTRL+ALT+F7切回图形窗口。如果控制台模式没有登录，可以CTRL+ALT+F6尝试登录。
因硬件显示设备的物理显示区是通过帧缓存区操作，而帧缓存区是处于内核空间，应用程序不能随意操作，此时可以通过系统调用mmap把帧缓存映射到用户空间，在用户空间中创建出帧缓存映射区（用户图像数据缓存区），以后只需把用户图像数据写入到帧缓存映射区就可在硬件设备上显示图像。
具体实现流程如下：
打开帧缓冲设备/dev/f0 在Linux的/dev目录的寻找b*设备文件然后使用读写模式打开它，Linux 系统将使用通用的open系统调用来完成功能， open的功能原型如下：
int open(const char *path, int oflags); Path是准备打开的文件或设备的路径参数； oflags指定打开文件时使用的参数； flags参数的指定，是通过组合文件访问模式和其他的可选模式一起的，可以支持多个模式或，参数必须是指定下列文件的访问模式。 只读：O_RDONLLY 只写：O_WRONLY 读写：O_RDWR 简而言之， open函数建立设备文件的访问路径。如果操作成功，它返回一个文件描述符，只是一个文件描述符，它将不使用其他任何正在运行的进程共享。如果两个程序同时打开相同的文件，将得到两个不同的文件描述符。如果他们执行文件写入操作，他们将操作每个文件描述符，不会发生冲突，写完之后退出。他们的数据不会互相交织在一起的，但会互相的彼此覆盖 (后写完的内容覆盖前面写的内容)，两个程序来读取和写入的文件位置看似一样但是有各自不同拷贝所以不会发生交织。如果open调用未能返回1，则将全局变量errno设置为指示失败的原因。
通过系统调用ioctl函数获得帧设备相关信息 通过顿缓冲文件描述符，屏幕的分辨率、颜色深度等信息可以被获得，帧缓冲驱动中存放了这些对应的信息，必须使用 Linux 系统调用ioctl首先将帧缓冲的文件描述符和fb_var_screeninfo 结构体对应起来。
结构体fb_var_screeninfo包含以下三个重要数据结构：
屏幕的 x 方向分辨率，像素作为单位。 屏幕的 Y 方向分辨率，像素作为单位。 屏幕的像素颜色深度，每个像素用多少比特数表示。 ioctl函数原型如下：</description>
    </item>
    <item>
      <title>Linux 安装 Node.js 以及 hexo</title>
      <link>http://localhost:8888/posts/linux%E5%AE%89%E8%A3%85nodejs/</link>
      <pubDate>Mon, 10 Jan 2022 11:51:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E5%AE%89%E8%A3%85nodejs/</guid>
      <description>安装 Node.js 过程 进入该网站下载 | Node.js 也可以进入该网站下载历史版本，Previous Releases | Node.js
进入 download 目录，
cd downloadwget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz -O nodejs.tar.xz 解压
tar -xvf node-v10.16.3-linux-x64.tar.xz 改名 Node.js
mv node-v10.16.3-linux-x64 nodejs 将 npm，node 两个程序建立软连接，能够全局可用
ln -s /download/nodejs/bin/npm /usr/local/bin/ ln -s /download/nodejs/bin/node /usr/local/bin/ 检查是否安装
node -vnpm -v 安装 hexo 过程 npm i hexo-cli -ghexo -v 如果出现命令未找到到错误，说明 hexo 还未加入全局变量。 将下面命令加入
vim ~/.bashrcexport PATH=/usr/local/nodejs/lib/node_modules/hexo-cli/bin/:$PATH Reference Previous Releases | Node.js Linux 安装 Node.js | F2E 前端技术论坛 Linux 下安装 node 及 npm - SegmentFault 思否 超详细 Hexo+Github 博客搭建小白教程 - 知乎</description>
    </item>
    <item>
      <title>解决 unable to install libpng12.so.0</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-install-libpng12-so-0/</link>
      <pubDate>Wed, 05 Jan 2022 13:01:47 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3unable-to-install-libpng12-so-0/</guid>
      <description>保留现场 apt工具损坏了，在修复时使用了sudo apt-get install -f命令，中途会提示需要安装libpng12-0，但是始终无法安装，会提示如下错误。
Unpacking libpng12-0:amd64 (1.2.50-2+deb8u3) ... dpkg: error processing archive libpng12-0_1.2.50-2+deb8u3_amd64.deb (--install): unable to install new version of &amp;#39;/usr/lib/ x86_64-linux-gnu/libpng12.so.0&amp;#39;: No such file or directory Errors were encountered while processing: libpng12-0_1.2.50-2 +deb8u3_amd64.deb 探究原因 具体原因未知，网上答案众说纷纭。
解决方法 这个问题遇到的人还挺多的，解决方法也各不相同，我先说我自己最终解决的方法。
方法一 将软件源更换成中科院的源，使用 Linux 自带的软件和更新工具，具体方法参考这篇文章。更换完之后可以重新尝试安装，有人换源后即可成功安装。
如果未能安装成功，可能曾经手动添加过软件源，将其删除。
# 将所有内容注释vim /etc/apt/sources.list 方法二 下载已安装的库文件libpng12.so.0，可以从该链接下载。
将该文件复制到它本该安装的位置。
sudo cp libpng12.so.0 /usr/lib/x86_64-linux-gnu/ 方法三 sudo add-apt-repository ppa:linuxuprising/libpng12sudo apt updatesudo apt install libpng12-0 </description>
    </item>
    <item>
      <title>VSCode 使用 sftp 插件上传本地文件至局域网服务器</title>
      <link>http://localhost:8888/posts/vscode%E4%BD%BF%E7%94%A8sftp%E6%8F%92%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%87%B3%E5%B1%80%E5%9F%9F%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Fri, 24 Dec 2021 11:39:03 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E4%BD%BF%E7%94%A8sftp%E6%8F%92%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%87%B3%E5%B1%80%E5%9F%9F%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>测试代码时经常需要上传文件至服务器端运行，每次上传都需要通过第三方传输工具如 FileZilla，有了SFTP插件，可以直接在 VSCode 上编译成功后，一键上传本地文件。
安装插件 打开插件中心，搜索sftp，安装量最高的就是我们需要的插件，点击安装。
配置插件 插件安装完成后，输入快捷键Control + Shift + P 弹出命令面板，然后输入sftp:config，回车，当前工程的.vscode文件夹下就会自动生成一个sftp.json文件，我们需要在这个文件里配置的内容可以是：
{ &amp;#34;host&amp;#34;: &amp;#34;192.168.xxx.xxx&amp;#34;, //服务器 ip &amp;#34;port&amp;#34;: 22, //端口，sftp 模式是 22 &amp;#34;username&amp;#34;: &amp;#34;&amp;#34;, //用户名 &amp;#34;password&amp;#34;: &amp;#34;&amp;#34;, //密码 &amp;#34;protocol&amp;#34;: &amp;#34;ftp&amp;#34;, //模式，sfpt 或者 ftp &amp;#34;agent&amp;#34;: null, &amp;#34;privateKeyPath&amp;#34;: null, //存放在本地的已配置好的用于登录工作站的密钥文件（也可以是 ppk 文件） &amp;#34;passphrase&amp;#34;: null, &amp;#34;passive&amp;#34;: false, &amp;#34;interactiveAuth&amp;#34;: false, &amp;#34;remotePath&amp;#34;: &amp;#34;/root/node/build/&amp;#34;, //服务器上的文件地址 &amp;#34;context&amp;#34;: &amp;#34;./server/build&amp;#34;, //本地的文件地址 &amp;#34;uploadOnSave&amp;#34;: true, //监听保存并上传 &amp;#34;syncMode&amp;#34;: &amp;#34;update&amp;#34;, &amp;#34;watcher&amp;#34;: { //监听外部文件 &amp;#34;files&amp;#34;: false, //外部文件的绝对路径 &amp;#34;autoUpload&amp;#34;: false, &amp;#34;autoDelete&amp;#34;: false }, &amp;#34;ignore&amp;#34;: [ //指定在使用 sftp: sync to remote 的时候忽略的文件及文件夹 //注意每一行后面有逗号，最后一行没有逗号 //忽略项 &amp;#34;**/.</description>
    </item>
    <item>
      <title>解决 Linux 启动出现 fsck exited with status code 4</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E5%90%AF%E5%8A%A8%E5%87%BA%E7%8E%B0fsck-exited-with-status-code-4/</link>
      <pubDate>Sat, 04 Dec 2021 10:18:09 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3linux%E5%90%AF%E5%8A%A8%E5%87%BA%E7%8E%B0fsck-exited-with-status-code-4/</guid>
      <description>保留现场 探究原因 磁盘检测不能通过，可能是因为系统突然断电或其它未正常关闭系统导致。
解决方法 根据提示可以看到是dev/sda5这个扇区出现了异常，所以通过fsck命令修复文件系统。详细命令解释。
将sda5改为自己损坏的扇区即可，等待一段时间修复完成后，输入exit即可重启。
fsck -y /dev/sda5 </description>
    </item>
    <item>
      <title>Clang-Format 格式化代码</title>
      <link>http://localhost:8888/posts/clang-format%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Wed, 01 Dec 2021 17:42:45 +0000</pubDate>
      <guid>http://localhost:8888/posts/clang-format%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/</guid>
      <description>安装 Linux sudo apt-get install clang-format windows 每每到这时候就越能感受到用 Linux 作为开发环境的优势，Windows 安装就稍显复杂了。
你可以选择安装完整的 LLVM，在bin目录可以看到clang-format.exe。安装完后，将 bin 目录添加到环境变量中。
你也可以只下载clang-format.exe，从LLVM Snapshot Builds下载安装包。在下载页面的底部。同样你需要将单独下载的文件加入到环境变量中。
使用 入门使用 Linux 可以直接命令行，使用以 LLVM 代码风格格式化main.cpp, 结果直接写到main.cpp
clang g-format -i main.cpp -style=LLVM 进阶配置 如果每次编码都命令行执行一遍那也太麻烦了，而且每次修改也不止一个文件。最好的方式就是每次保存文件时自动格式化。比如 VSCode 已经内置了Clang-Format稍作配置即可实现，接下来介绍几种常见 IDE 如何配置Clang-Format。
VSCode VSCode 最常用，因为内置了Clang-Format也最容易配置。
安装C/C++插件，Ctrl+Shift+X打开应用商店，搜索C/C++找到下图插件，安装后会自动安装Clang-Format程序，无需单独下载。默认安装路径为： C:\Users\(你的用户名)\.vscode\extensions\ms-vscode.cpptools-1.7.1\LLVM\bin\clang-format.exe。 打开设置页面（左下角齿轮 - 设置），搜索format，勾选Format On Save，每次保存文件时自动格式化文档。下方的设置是决定每次格式化是整个文档，还是做过修改的内容。默认是file，对整个文档进行格式化。 仍在设置页面搜索Clang，配置如下。.clang-format文件最后详解。 效果图 QtCreator 安装Beautifier插件：帮助（Help）-关于插件（About Plugins）- Beautifier勾选，重启 QtCreator。 工具（Tool）- Beautifier，配置如图。该配置，保存文档时自动格式化，并选择Clang-Format作为格式化工具。 配置Clang-Format程序路径，如果开头已经apt install安装过，这里会自动补全。 Use predefined style可以选择内置的一些代码风格，如LLVM，Google等。 Use customized style使用自定义的一些代码风格。点击添加（Add）将配置文件粘贴进去即可，具体配置文件见最后。 别忘了点击OK保存。 Eclipse 安装cppstyle插件：Help - Eclipse Marketplace - 搜索cppstyle。</description>
    </item>
    <item>
      <title>Linux 文件删除仍然在 Trash 目录下占用空间，该如何删除 Trash 下的文件</title>
      <link>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E5%88%A0%E9%99%A4%E4%BB%8D%E7%84%B6%E5%9C%A8trash%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E8%AF%A5%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4trash%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 25 Nov 2021 10:31:27 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E5%88%A0%E9%99%A4%E4%BB%8D%E7%84%B6%E5%9C%A8trash%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E8%AF%A5%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4trash%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</guid>
      <description>保留现场 探究原因 查阅了一个网上的答案，大意就是，你删除了属于你的文件夹，但其中包含属于另一个用户的文件时，文件可能会卡住，就会在 Trash 目录里不会被彻底删除。
解决方法 sudo rm -rv /home/&amp;lt;your_username&amp;gt;/.local/share/Trash/expunged/* PS：发现一个好用的磁盘分析工具，Linux 内置应用Disk Usage Analyzer。按Win键后搜索框搜索即可打开。
图形化的方式快速找到占用空间较大的目录，文件。可以右击直接删除。</description>
    </item>
    <item>
      <title>Linux 下将编译结果输出到文件</title>
      <link>http://localhost:8888/posts/linux%E4%B8%8B%E5%B0%86%E7%BC%96%E8%AF%91%E7%BB%93%E6%9E%9C%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 30 Sep 2021 15:18:32 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E4%B8%8B%E5%B0%86%E7%BC%96%E8%AF%91%E7%BB%93%E6%9E%9C%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/</guid>
      <description>在命令行编译项目时，经常遇到编译结果太长，覆盖了最先输出的结果，此时就需要将结果输出到文件再查看。命令如下：
make &amp;gt; make.log 2&amp;gt;&amp;amp;1 # make 编译命令 # make.log 输出文件名 # 2 文件描述符，标准错误 # &amp;gt; 重定向符，输出 # &amp;amp;1 文件描述符&amp;amp;，文件描述符1 标准输入 该命令功能即将make编译时输出，标准错误重定向为标准输入，写入到make.log文件中。符号的含义可以参考Linux 文件描述符</description>
    </item>
    <item>
      <title>Linux 文件描述符</title>
      <link>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</link>
      <pubDate>Thu, 30 Sep 2021 11:13:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</guid>
      <description>前言 Linux 中一切皆文件，比如 C++ 源文件、视频文件、Shell 脚本、可执行文件等，就连键盘、显示器、鼠标等硬件设备也都是文件。
一个 Linux 进程可以打开成百上千个文件，为了表示和区分已经打开的文件，Linux 会给每个文件分配一个编号（一个 ID），这个编号就是一个整数，被称为文件描述符（File Descriptor）。
文件描述符是什么？ 一个 Linux 进程启动后，会在内核空间中创建一个 PCB 控制块，PCB 内部有一个文件描述符表（File descriptor table），记录着当前进程所有可用的文件描述符，也即当前进程所有打开的文件。
除了文件描述符表，系统还需要维护另外两张表：
打开文件表（Open file table） i-node 表（i-node table） 文件描述符表每个进程都有一个，打开文件表和 i-node 表整个系统只有一个，它们三者之间的关系如下图所示。
对上图的说明：
在进程A 中，文件描述符 1 和20 都指向了同一个打开文件表项，标号为 23（指向了打开文件表中下标为 23 的数组元素），这可能是通过调用 dup()、dup2()、fcntl() 或者对同一个文件多次调用了 open() 函数形成的。 进程 A 的文件描述符 2和进程B 的文件描述符2 都指向了同一个文件，这可能是在调用 fork() 后出现的（即进程 A、B是父子进程关系），或者是不同的进程独自去调用open() 函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。 进程 A 的描述符0和进程B的描述符3分别指向不同的打开文件表项，但这些表项均指向 i-node 表的同一个条目（标号为 1976）；换言之，它们指向了同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了 open() 调用。同一个进程两次打开同一个文件，也会发生类似情况。 通过文件描述符，可以找到文件指针，从而进入打开文件表。该表存储了以下信息：
文件偏移量，也就是文件内部指针偏移量。调用read()或者write() 函数时，文件偏移量会自动更新，当然也可以使用 lseek() 直接修改。 状态标志，比如只读模式、读写模式、追加模式、覆盖模式等。 i-node 表指针。 然而，要想真正读写文件，还得通过打开文件表的 i-node 指针进入</description>
    </item>
    <item>
      <title>VSCode 中调试带 Makefile 文件的项目</title>
      <link>http://localhost:8888/posts/vscode%E4%B8%AD%E8%B0%83%E8%AF%95%E5%B8%A6makefile%E6%96%87%E4%BB%B6%E7%9A%84%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Mon, 06 Sep 2021 15:41:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E4%B8%AD%E8%B0%83%E8%AF%95%E5%B8%A6makefile%E6%96%87%E4%BB%B6%E7%9A%84%E9%A1%B9%E7%9B%AE/</guid>
      <description>在调试 QEMU 时，自己需要修改源文件，但是每次修改都需要在命令行重新make编译一遍，比较麻烦，想到之前刚刚配置过tasks.json文件，可以把命令行任务配置到文件里，make命令不也一样可以加入吗？修改tasks.json文件如下：
{ &amp;#34;version&amp;#34;: &amp;#34;2.0.0&amp;#34;, &amp;#34;tasks&amp;#34;: [ { //任务的名字方便执行 &amp;#34;label&amp;#34;: &amp;#34;make qemu&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;command&amp;#34;: &amp;#34;make&amp;#34;, &amp;#34;args&amp;#34;:[ //8 线程编译 &amp;#34;-j8&amp;#34;, ], &amp;#34;options&amp;#34;: { //切换到 build 文件夹下 &amp;#34;cwd&amp;#34;: &amp;#34;${workspaceFolder}/build&amp;#34; }, }, { // 启动 qemu 供调试器连接 &amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, &amp;#34;label&amp;#34;: &amp;#34;Run Qemu Server(RISCV)&amp;#34;, //在执行这个任务前，先执行 make qemu 任务、 //这样就可以在执行调试时，自动先编译一遍 &amp;#34;dependsOn&amp;#34;: &amp;#34;make qemu&amp;#34;, &amp;#34;command&amp;#34;: &amp;#34;qemu-system-riscv64&amp;#34;, &amp;#34;args&amp;#34;: [ &amp;#34;-g&amp;#34;, &amp;#34;${workspaceFolder}/debug/${fileBasenameNoExtension}&amp;#34; ], }, ] } </description>
    </item>
    <item>
      <title>解决 gcc-multilib : 依赖：gcc-4.8-multilib (&gt;= 4.8.2-5~) 但是它将不会被安装</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc-multilib-%E4%BE%9D%E8%B5%96-gcc-4-8-multilib-4-8-2-5-%E4%BD%86%E6%98%AF%E5%AE%83%E5%B0%86%E4%B8%8D%E4%BC%9A%E8%A2%AB%E5%AE%89%E8%A3%85/</link>
      <pubDate>Fri, 03 Sep 2021 10:44:44 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3gcc-multilib-%E4%BE%9D%E8%B5%96-gcc-4-8-multilib-4-8-2-5-%E4%BD%86%E6%98%AF%E5%AE%83%E5%B0%86%E4%B8%8D%E4%BC%9A%E8%A2%AB%E5%AE%89%E8%A3%85/</guid>
      <description>问题 这是一类问题，不仅限于安装 gcc，这类问题的根本原因在于，Ubuntu 已安装的软件包版本高，而所安装软件的依赖包版本低，这样在安装高版软件时，已有的软件包依赖你要安装的软件包，你把软件包升级了，可能就会破坏这个依赖关系，所以apt-get不让你安装。
这时就要请到大杀器-aptitude，它与 apt-get一样，是 Debian 及其衍生系统中功能极其强大的包管理工具。与 apt-get 不同的是，aptitude在处理依赖问题上更佳一些。举例来说，aptitude在删除一个包时，会同时删除本身所依赖的包。这样，系统中不会残留无用的包，整个系统更为干净。
方法 $sudo apt-get install aptitude //安装aptitude包管理器$sudo aptitude install gcc-multilib //用新的包管理器安装你要安装的软件 安装gcc-multilib时会把所有依赖包一并安装，此时会让你同意，选择n就行。
接下来就会解决已经安装的包之间的依赖关系，他会降级或升级一些软件包来匹配当前安装的软件版本，此时选择y。
完成以上操作，再次正常安装需要的软件包即可成功安装。
如果无法正常安装，重复以上操作，每次都选择n。</description>
    </item>
    <item>
      <title>解决 fatal error: bits/libc-header-start.h：no such file</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3fatal-error-bits-libc-header-start-hno-such-file/</link>
      <pubDate>Fri, 03 Sep 2021 09:26:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3fatal-error-bits-libc-header-start-hno-such-file/</guid>
      <description>保留现场 想要分别编译 32 位和 64 位的程序时，gcc 出现了错误，
In file included from func_call.c:1:/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: 没有那个文件或目录27 | #include &amp;lt;bits/libc-header-start.h&amp;gt;| ^~~~~~~~~~~~~~~~~~~~~~~~~~compilation terminated. 问题解决 问题原因猜测是默认 gcc 只提供当前机器的版本，解决如下
apt install gcc-multilib </description>
    </item>
    <item>
      <title>QEMU 源码分析-虚拟 CPU 创建</title>
      <link>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9Fcpu%E5%88%9B%E5%BB%BA/</link>
      <pubDate>Wed, 01 Sep 2021 18:22:14 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E8%99%9A%E6%8B%9Fcpu%E5%88%9B%E5%BB%BA/</guid>
      <description>流程图 先开个头吧，把创建流程稍微捋一下，找到创建虚拟 CPU 的模块。至于中间的流程还没有详细分析，万事开头难，先上手再说吧。
qemu_add_opts解析 qemu 的命令行 qemu_init函数中下面这一长串内容，就是在解析命令行的参数。
qemu add opts (&amp;amp;qemu drive opts); qemu add drive opts(&amp;amp;qemu Legacy drive opts); qemu add drive opts (&amp;amp;qemu common drive opts); qemu add drive opts (&amp;amp;qemu drive opts); qemu add drive opts (sbdry runtime opts); qemu add opts (qemu chardev opts); qemu add opts (&amp;amp;qemu device opts); qemu add opts (&amp;amp;qemu netdev opts); qemu add opts (&amp;amp;qemu nic opts); qemu add opts (sqemu net opts qemu add opts (&amp;amp;qemu rtc opts) qemu add opts (&amp;amp;qemu global_opts); qemu add opts (&amp;amp;qemu mon opts); qemu add opts (sqemu trace opts); .</description>
    </item>
    <item>
      <title>Linux 操作系统-进程管理</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 30 Aug 2021 09:41:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</guid>
      <description>进程 源码 //process.c #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; extern int create_process (char* program, char** arg_list); int create_process (char* program, char** arg_list) { pid_t child_pid; child_pid = fork (); if (child_pid != 0) { return child_pid; } else { execvp (program, arg_list); abort (); } } 在这里，我们创建的子程序运行了一个最最简单的命令 ls。
//createprocess.c #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; extern int create_process (char* program, char** arg_list); int main () { char* arg_list[] = { &amp;#34;ls&amp;#34;, &amp;#34;-l&amp;#34;, &amp;#34;/etc/yum.</description>
    </item>
    <item>
      <title>CSAPPLAB-Bomb Lab</title>
      <link>http://localhost:8888/posts/csapp-lab-bomb-lab/</link>
      <pubDate>Sun, 29 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/csapp-lab-bomb-lab/</guid>
      <description>Tips 缩写注释 CSAPP：Computer Systems A Programmer’s Perspective（深入理解计算机操作系统）。CSAPP（C：P166，O：P278）表示书本的中文版第 166 页，英文原版第 278 页。
寄存器信息 了解寄存器的基本用途，看到一个汇编代码，可以大概了解这个寄存器是在栈中使用的，还是保存参数的，是调用者保存，还是被调用者保存。 GDB 调试过程用到的 GDB 命令可以先参考GDB 调试入门这篇文章。文中所用例子也是摘自与 BombLab 的源码，更容易理解如何使用。还有一定比较重要的是，如何使用 gdb 带参数调试。为了不用每次运行bomb程序都需要重新输入答案，bomb程序可以读取文本信息，在文本文件中写入答案即可免去手动输入。
phase_1 拆弹专家已上线，开干！！！！！！！！！！！！！
(gdb) b phase_1(gdb) b explode_bomb(gdb) disas phase_1Dump of assembler code for function phase_1:&amp;#39;0x0000000000400ee0 &amp;lt;+0&amp;gt;: sub $0x8,%rsp0x0000000000400ee4 &amp;lt;+4&amp;gt;: mov $0x402400,%esi0x0000000000400ee9 &amp;lt;+9&amp;gt;: callq 0x401338 &amp;lt;strings_not_equal&amp;gt;0x0000000000400eee &amp;lt;+14&amp;gt;: test %eax,%eax0x0000000000400ef0 &amp;lt;+16&amp;gt;: je 0x400ef7 &amp;lt;phase_1+23&amp;gt;0x0000000000400ef2 &amp;lt;+18&amp;gt;: callq 0x40143a &amp;lt;explode_bomb&amp;gt;0x0000000000400ef7 &amp;lt;+23&amp;gt;: add $0x8,%rsp0x0000000000400efb &amp;lt;+27&amp;gt;: retq End of assembler dump.</description>
    </item>
    <item>
      <title>GDB 调试入门</title>
      <link>http://localhost:8888/posts/gdb%E8%B0%83%E8%AF%95%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sun, 29 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/gdb%E8%B0%83%E8%AF%95%E5%85%A5%E9%97%A8/</guid>
      <description>file 加载程序 (gdb) file bomb Reading symbols from bomb... set args 带参数调试 有时候程序不是直接可以运行的，需要加上一些必要的参数。带上参数运行很容易，只要在程序名后加上相应参数即可，但是如何带上参数进行调试呢？这就需要set args命令。
比如在BombLab实验中，我们不可能一次解决所有phase，但是每次重新调试，已经解决的phase还要重新输入一次答案，这就很麻烦，好在这个实验的作者也考虑到了，他支持读取文本。我们可以把答案预先写入一个文本文件中，程序读取已经保存的答案即可跳过相应的phase。
假设我们把答案写入了solutions.txt文件中，首先，我们加载程序，然后通过set args solutions.txt设置运行参数。
(gdb) file bomb Reading symbols from bomb... (gdb) set args solutions.txt (gdb) r Starting program: /home/dominic/learning-linux/bomb/bomb solutions.txt Welcome to my fiendish little bomb. You have 6 phases with which to blow yourself up. Have a nice day! Phase 1 defused. How about the next one? That&amp;#39;s number 2. Keep going! list 查看源码 查看 10 行源码 每条命令显示 10 行代码</description>
    </item>
    <item>
      <title>oh-my-zsh 让你的终端更加顺手（眼）</title>
      <link>http://localhost:8888/posts/oh-my-zsh%E8%AE%A9%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E6%9B%B4%E5%8A%A0%E9%A1%BA%E6%89%8B%E7%9C%BC/</link>
      <pubDate>Sun, 29 Aug 2021 09:56:21 +0000</pubDate>
      <guid>http://localhost:8888/posts/oh-my-zsh%E8%AE%A9%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E6%9B%B4%E5%8A%A0%E9%A1%BA%E6%89%8B%E7%9C%BC/</guid>
      <description>效果 主题：evan
主题：dallas
主题：robbyrussell
如果原先其他电脑安装过 把.oh-my-zsh整个文件夹，.zshrc，.zsh_history复制到/home/user/目录；
安装zsh
sudo apt install zsh 切换shell
chsh -s /bin/zsh source ~/.zshrc 即可使用。所有配置都会和原先一样。
如果是新安装 官方方法，curl和wget二选一即可
curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh 应该也有人和我一样，可能会遇到连接 GitHub 失败的问题，要不就是 SSL 验证失败，要不就是连接无响应。可以更换下面的方法。
# 先下载 git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh ## 再替换 cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc 重启终端即可成功。
如果无法访问 GitHub，其实oh-my-zsh并不需要安装，完整的工程就是oh-my-zsh本体，只要想办法把整个工程下载下来，并重命名为oh-my-zsh即可。所以找找 gitee 有没有相关工程。这也是为什么从旧电脑里直接复制.oh-my-zsh就能用的原因。
问题 oh-my-zsh.sh parse error near `&amp;laquo;&amp;lt;&#39; 一般是在更新oh-my-zsh时出现，因为更新相当于就是从远程拉取了内容，可能本地的oh-my-zsh.sh脚本自己做了修改与远程冲突了。只要退回上个版本，重新拉取就可以了。
cd $ZSH git reset --hard HEAD^ git pull --rebase 如果本地修改了一些内容需要保留，可以打开oh-my-zsh.sh看看冲突在哪，自己做个备份，保存一下。</description>
    </item>
    <item>
      <title>VSCode 单步调试 QEMU</title>
      <link>http://localhost:8888/posts/vscode%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95qemu/</link>
      <pubDate>Tue, 24 Aug 2021 19:24:08 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95qemu/</guid>
      <description>了解了如何在VSCode 中调试程序，接下来我们在 VSCode 中搭建调试 QEMU 的环境。
配置 首先我们需要下载和编译 QEMU 源码
./configure --enable-debug --target-list=riscv32-softmmu,riscv32-linux-user --enable-kvm 一定要加上--enable-debug，编译出的程序才带有调试信息，不用设置安装路径，编译时会自动在 qemu 文件夹下自动创建一个build文件夹，编译后的程序也在build文件夹下。
用 VSCode 打开qemu-6.X.X文件夹，Ctrl+Shift+D打开调试配置。如果参考过VSCode 中调试程序这篇文章，接下来就很容易。我们只需要将launch.jason文件中的program属性改为${workspaceFolder}/build/qemu-system-riscv32即可。
调试 打开qemu-6.X.X/softmmu/main.c文件，在main函数入口处打上断点，即可开始调试。
现在只需要点击屏幕上的图标，就可以快速的进行单步调试。
如果需要进行命令行操作，在屏幕下方打开DEBUG CONSOLE，输入-exec+正常命令行下的命令即可在命令行中进行更多的调试。如查看断点信息-exec info breakpoints</description>
    </item>
    <item>
      <title>Qt 模仿登录界面-页面反转效果</title>
      <link>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E9%A1%B5%E9%9D%A2%E5%8F%8D%E8%BD%AC%E6%95%88%E6%9E%9C/</link>
      <pubDate>Tue, 24 Aug 2021 13:55:37 +0000</pubDate>
      <guid>http://localhost:8888/posts/qt%E6%A8%A1%E4%BB%BF%E7%99%BB%E5%BD%95%E7%95%8C%E9%9D%A2-%E9%A1%B5%E9%9D%A2%E5%8F%8D%E8%BD%AC%E6%95%88%E6%9E%9C/</guid>
      <description>设置一个旋转效果，将登录界面旋转翻个面，设置一些网络参数。
效果 网络参数设置界面布局 网络参数设置界面 //loginnetsetwindow.cpp //初始化标题 void LoginNetSetWindow::initMyTitle() { m_titleBar-&amp;gt;move(0, 0); m_titleBar-&amp;gt;raise(); m_titleBar-&amp;gt;setBackgroundColor(0, 0, 0, true); m_titleBar-&amp;gt;setButtonType(MIN_BUTTON); m_titleBar-&amp;gt;setTitleWidth(this-&amp;gt;width()); m_titleBar-&amp;gt;setMoveParentWindowFlag(false); } void LoginNetSetWindow::initWindow() { QLabel* pBack = new QLabel(this); QMovie *movie = new QMovie(); movie-&amp;gt;setFileName(&amp;#34;:/Resources/NetSetWindow/headBack.gif&amp;#34;); pBack-&amp;gt;setMovie(movie); movie-&amp;gt;start(); pBack-&amp;gt;move(0, 0); connect(ui.pButtonOk, SIGNAL(clicked()), this, SIGNAL(rotateWindow())); connect(ui.pButtonCancel, SIGNAL(clicked()), this, SIGNAL(rotateWindow())); ui.comboBoxNetType-&amp;gt;addItem(QStringLiteral(&amp;#34;不使用代理&amp;#34;)); ui.comboBoxServerType-&amp;gt;addItem(QStringLiteral(&amp;#34;不使用高级选项&amp;#34;)); } void LoginNetSetWindow::paintEvent(QPaintEvent *event) { // 绘制背景图; QPainter painter(this); QPainterPath pathBack; pathBack.setFillRule(Qt::WindingFill); pathBack.addRoundedRect(QRect(0, 0, this-&amp;gt;width(), this-&amp;gt;height()), 3, 3); painter.setRenderHint(QPainter::Antialiasing, true); painter.fillPath(pathBack, QBrush(QColor(235, 242, 249))); QPainterPath pathBottom; pathBottom.</description>
    </item>
    <item>
      <title>Linux 操作系统-系统初始化</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/</link>
      <pubDate>Tue, 24 Aug 2021 09:45:57 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/</guid>
      <description>系统初始化 x86 架构概述 CPU（Central Processing Unit）：中央处理器，计算机所有设备都围绕它展开工作。
运算单元：只管算，例如做加法、做位移等等。但是，它不知道应该算哪些数据，运算结果应该放在哪里。 数据单元：运算单元计算的数据如果每次都要经过总线，到内存里面现拿，这样就太慢了，所以就有了数据单元。数据单元包括 CPU 内部的缓存和寄存器组，空间很小，但是速度飞快，可以暂时存放数据和运算结果。 控制单元：有了放数据的地方，也有了算的地方，还需要有个指挥到底做什么运算的地方，这就是控制单元。控制单元是一个统一的指挥中心，它可以获得下一条指令，然后执行这条指令。这个指令会指导运算单元取出数据单元中的某几个数据，计算出个结果，然后放在数据单元的某个地方。 内存（Memory）：CPU 本身不能保存大量数据，许多复杂的计算需要将中间结果保存下来就必须用到内存。
总线（Bus）：CPU 和其他设备连接，就靠总线，其实就是主板上密密麻麻的集成电路，这些东西组成了 CPU 和其他设备的高速通道。
地址总线：传输地址数据（我想拿内存中哪个位置的数据） 数据总线：传输真正的数据 总线就像 CPU 和内存之间的高速公路，总线多少位就类似高速公路多少个车道，但两种总线的位数意义不同。
地址总线的位数决定了访问地址范围有多广，数据总线位数决定了一次能拿多少数据进来。那么 CPU 中总线的位数有没有标准呢？如果没有标准，那操作系统作为软件就很难办了，因为软件层没办法实现通用的运算逻辑。早期每家公司的 CPU 架构都不同，后来历史将 x86 平台推到了开放，统一，兼容的位置。
8086 架构图 数据单元： 8086 处理器内部共有 8 个 16 位的通用寄存器，分别是 数据寄存器（AX、BX、CX、DX）、指针寄存器（SP、BP）、变址寄存器（SI、DI）。其中 AX、BX、CX、DX 可以分成两个 8 位的寄存器来使用，分别是 AH、AL、BH、BL、CH、CL、DH、DL，其中 H 就是 High（高位），L 就是 Low（低位）的意思。
控制单元： IP 寄存器（Instruction Pointer Register）就是指令指针寄存器，它指向代码段中下一条指令的位置。CPU 会根据它来不断地将指令从内存的代码段中，加载到 CPU 的指令队列中，然后交给运算单元去执行。
如果需要切换进程呢？每个进程都分代码段和数据段，为了指向不同进程的地址空间，有四个 16 位的段寄存器，分别是 CS、DS、SS、ES。
其中，CS 就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置；DS 是数据段的寄存器（Data Segment Register），通过它可以找到数据在内存中的位置。SS 是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取只能从一端进行，秉承后进先出的原则。ES是扩展段寄存器（Extra Segment Register）顾名思义。</description>
    </item>
    <item>
      <title>VSCode 调试 RISC-V 程序</title>
      <link>http://localhost:8888/posts/vscode%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Mon, 23 Aug 2021 15:51:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/vscode%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F/</guid>
      <description>前提 本文主要涉及 VSCode 的相关配置，编译及调试工具需要提前安装好。
已经安装好riscv-toolchain，包括riscv64-unknown-elf-gcc，riscv64-unknown-elf-gdb 已经安装好qemu，包括riscv32-softmmu,riscv32-linux-user,riscv64-softmmu,riscv64-linux-user 已经安装好g++,gdb 调试流程简介 对于我这样的新手，要调试一个项目源码最怕的就是开始，也就是怎么能把项目跑起来。
我们以一个简单的test项目，看看在 VSCode 里怎么跑起来。
拿到源码后，将其以文件夹形式，加入到 VSCode 中，文件 - 打开文件夹 - 选择 test 项目文件夹。项目就会在 VSCode 中打开，但是此时我们还无法编译运行，我们需要在 VSCode 上 构建出一个 C 语言的编译与调试环境。
首先得安装一个插件C/C++，打开插件中心Ctrl+Shit+X，搜索，安装。
然后输入F5，会弹出对话框，选择C++(GDB)，继续选择g++。VSCode 会自动创建.vscode文件夹，已经两个文件launch.json和tasks.json。 launch.json用来配置调试环境，tasks.json主要用来配置编译环境，当然也可以配置其他任务。task.json里配置的每个任务其实就相当于多开一个控制台。
配置tasks.json 因为我们先要编译源码，生成.out或者.exe文件，才能调试，所以先进行编译任务配置。
自动生成的文件是个配置模板，我们可以根据自己的实际情况进行配置，也有一部分可以保持默认。
// tasks.json{// https://code.visualstudio.com/docs/editor/tasks&amp;#34;version&amp;#34;: &amp;#34;2.0.0&amp;#34;,&amp;#34;tasks&amp;#34;: [{// 任务的名字，注意是大小写区分的//会在launch中调用这个名字&amp;#34;label&amp;#34;: &amp;#34;C/C++: g++ build active file&amp;#34;, // 任务执行的是shell&amp;#34;type&amp;#34;: &amp;#34;shell&amp;#34;, // 命令是g++&amp;#34;command&amp;#34;: &amp;#34;g++&amp;#34;, //g++ 后面带的参数&amp;#34;args&amp;#34;: [&amp;#34;&amp;#39;-Wall&amp;#39;&amp;#34;,&amp;#34;-g&amp;#34;, // 生成调试信息，否则无法进入断点&amp;#34;&amp;#39;-std=c++17&amp;#39;&amp;#34;, //使用c++17标准编译&amp;#34;&amp;#39;${file}&amp;#39;&amp;#34;, //当前文件名&amp;#34;-o&amp;#34;, //对象名，不进行编译优化&amp;#34;&amp;#39;${fileBasenameNoExtension}.</description>
    </item>
    <item>
      <title>进程间通信（IPC）之信号量（Semaphore）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8Fsemaphore/</link>
      <pubDate>Thu, 19 Aug 2021 15:36:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8Fsemaphore/</guid>
      <description>简介 为了防止出现因多个程序同时访问一个共享资源而引发的一系列问题，我们需要一种方法，它可以通过生成并使用令牌来授权，在任一时刻只能有一个执行线程访问代码的临界区域。临界区域是指执行数据更新的代码需要独占式地执行。而信号量就可以提供这样的一种访问机制，让一个临界区同一时间只有一个线程在访问它，也就是说信号量是用来调协进程对共享资源的访问的。
信号量是一个特殊的变量，程序对其访问都是原子操作，且只允许对它进行等待（即P) 和发送（即V) 信息操作。最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二进制信号量。而可以取多个正整数的信号量被称为通用信号量。这里主要讨论二进制信号量。
由于信号量只能进行两种操作等待和发送信号，即 P(sv) 和 V(sv),他们的行为是这样的：
P(sv)：如果sv的值大于零，就给它减 1；如果它的值为零，就挂起该进程的执行
V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加 1.
举个例子，就是两个进程共享信号量sv，一旦其中一个进程执行了P(sv)操作，它将得到信号量，并可以进入临界区，使sv减 1。而第二个进程将被阻止进入临界区，因为当它试图执行P(sv)时，sv为 0，它会被挂起以等待第一个进程离开临界区域并执行V(sv)释放信号量，这时第二个进程就可以恢复执行。
本文代码同步在这里。
相关函数 Linux 提供了一组精心设计的信号量接口来对信号进行操作，它们不只是针对二进制信号量，下面将会对这些函数进行介绍，但请注意，这些函数都是用来对成组的信号量值进行操作的。它们声明在头文件 sys/sem.h 中。
semget() 它的作用是创建一个新信号量或取得一个已有信号量，原型为：
int semget(key_t key, int num_sems, int sem_flags); key是整数值（唯一非零），不相关的进程可以通过它访问一个信号量，它代表程序可能要使用的某个资源，程序对所有信号量的访问都是间接的，程序先通过调用semget()函数并提供一个键，再由系统生成一个相应的信号标识符（semget()函数的返回值），只有semget()函数才直接使用信号量键，所有其他的信号量函数使用由semget()函数返回的信号量标识符。如果多个程序使用相同的key值，key将负责协调工作。
num_sems指定需要的信号量数目，它的值几乎总是 1。
sem_flags是一组标志，当想要当信号量不存在时创建一个新的信号量，可以和值IPC_CREAT做按位或操作。设置了IPC_CREAT标志后，即使给出的键是一个已有信号量的键，也不会产生错误。而IPC_CREAT | IPC_EXCL则可以创建一个新的，唯一的信号量，如果信号量已存在，返回一个错误。
semget()函数成功返回一个相应信号标识符（非零），失败返回-1.
semop() 它的作用是改变信号量的值，原型为：
int semop(int sem_id, struct sembuf *sem_opa, size_t num_sem_ops); sem_id是由semget()返回的信号量标识符，sembuf结构的定义如下：
struct sembuf{ short sem_num; // 除非使用一组信号量，否则它为0 short sem_op; // 信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即 P（等待）操作， // 一个是+1，即V（发送信号）操作。 short sem_flg; // 通常为 SEM_UNDO，使操作系统跟踪信号， // 并在进程没有释放该信号量而终止时，操作系统释放信号量 }; num_sem_ops：操作sops中的操作个数，通常取值为 1</description>
    </item>
    <item>
      <title>进程间通信（IPC）之消息队列（MessageQueue）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97messagequeue/</link>
      <pubDate>Thu, 19 Aug 2021 10:53:09 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97messagequeue/</guid>
      <description>简介 消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。
每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。我们可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。
本文代码同步在这里。
相关函数 msgget() 该函数用来创建和访问一个消息队列。它的原型为：
int msgget(key_t, key, int msgflg); key：与其他的 IPC 机制一样，程序必须提供一个键来命名某个特定的消息队列。 msgflg是一个权限标志，表示消息队列的访问权限，它与文件的访问权限一样。msgflg可以与IPC_CREAT做或操作，表示当 key 所命名的消息队列不存在时创建一个消息队列，如果 key 所命名的消息队列存在时，IPC_CREAT标志会被忽略，而只返回一个标识符。 它返回一个以key命名的消息队列的标识符（非零整数），失败时返回-1.
msgsnd() 该函数用来把消息添加到消息队列中。它的原型为：
int msgsend(int msgid, const void *msg_ptr, size_t msg_sz, int msgflg); msgid是由msgget函数返回的消息队列标识符。
msg_ptr是一个指向准备发送消息的指针，但是消息的数据结构却有一定的要求，指针msg_ptr所指向的消息结构一定要是以一个长整型成员变量开始的结构体，接收函数将用这个成员来确定消息的类型。所以消息结构要定义成这样：
struct my_message { long int message_type; /* The data you wish to transfer */ }; msg_sz 是msg_ptr指向的消息的长度
msgflg 用于控制当前消息队列满或队列消息到达系统范围的限制时将要发生的事情
如果调用成功，消息数据的副本将被放到消息队列中，并返回0，失败时返回-1.
msgrcv() 该函数用来从一个消息队列获取消息，它的原型为
int msgrcv(int msgid, void *msg_ptr, size_t msg_st, long int msgtype, int msgflg); 前三个参数参照前面的解释 msgtype 可以实现一种简单的接收优先级。如果msgtype为0，就获取队列中的第一个消息。如果它的值大于零，将获取具有相同消息类型的第一个信息。如果它小于零，就获取类型等于或小于msgtype的绝对值的第一个消息。 msgflg 用于控制当队列中没有相应类型的消息可以接收时将发生的事情。 调用成功时，该函数返回放到接收缓存区中的字节数，消息被复制到由msg_ptr指向的用户分配的缓存区中，然后删除消息队列中的对应消息。失败时返回-1。 msgctl() 该函数用来控制消息队列，它与共享内存的shmctl函数相似，它的原型为：</description>
    </item>
    <item>
      <title>Linux(Ubuntu) 环境下安装 VSCode</title>
      <link>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85vscode/</link>
      <pubDate>Thu, 19 Aug 2021 09:38:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85vscode/</guid>
      <description>本来不想写这一篇的，安装 VSCode 时随便搜一下就 OK 了，但是因为 APT 源中没有 VSCode，所以需要找下载网址，几次的安装经历下来，找下载网址也经历了一番折腾。今天又要安装一遍，就顺手记录一下吧。以后翻自己记录总比翻全网记录方便。
官方文档 其实最完备安装教程在官方文档里。本文也算是对官方文档的一个翻译版吧。
基于 Debian 和 Ubuntu 的发行版 如果下载了.deb 安装包，那么只需要一个命令就可以完成安装了。
sudo apt install ./&amp;lt;file&amp;gt;.deb 无奈的是，我需要在开发机安装，无法下载安装包，但是我又不想用ftp传来传去，要是apt能完成，绝不单独下载安装包。
可以使用以下脚本手动安装存储库和密钥
wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &amp;gt; packages.microsoft.gpg sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/ sudo sh -c &amp;#39;echo &amp;#34;deb [arch=amd64,arm64,armhf signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] https://packages.microsoft.com/repos/code stable main&amp;#34; &amp;gt; /etc/apt/sources.list.d/vscode.list&amp;#39; rm -f packages.microsoft.gpg 更新与安装
sudo apt install apt-transport-httpssudo apt updatesudo apt install code # or code-insiders </description>
    </item>
    <item>
      <title>Linux 操作系统-内存管理</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Thu, 19 Aug 2021 09:37:04 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>内存管理概述 计算机所谓的“计算”指的是：
进程和线程对于 CPU 的使用 对内存的管理 独享内存空间的原理 每个进程都独享一段内存空间，并且真实物理内存地址对进程不可见，操作系统会给进程分配一个虚拟地址，每个进程看到的内存地址都是从 0 开始。操作系统会将不同进程的虚拟地址和不同内存的物理地址做映射。当程序访问虚拟地址时，由内核的数据结构进行转换，转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址。
规划虚拟地址空间 通过以上的原理，我们可以看出，操作系统的内存管理，主要分为三个方面。
物理内存的管理； 虚拟地址的管理； 虚拟地址和物理地址如何映射； 进程获取了一段独立的虚拟内存空间后，可以不用管其他进程，“任意”使用这片内存，但是也有一点规则。这篇内存需要存放内核态和用户态的内容。高地址存放内核态的内容，低地址存放用户态的内容。具体分界线 64 位与 32 位不同，暂不深究。
我们从最低位开始排起，先是Text Segment、Data Segment 和 BSS Segment。Text Segment 是存放二进制可执行代码的位置，Data Segment 存放静态常量，BSS Segment 存放未初始化的静态变量。是不是觉得这几个名字很熟悉？没错，咱们前面讲 ELF 格式的时候提到过，在二进制执行文件里面，就有这三个部分。这里就是把二进制执行文件的三个部分加载到内存里面。
接下来是堆（Heap）段。堆是往高地址增长的，是用来动态分配内存的区域，malloc 就是在这里面分配的。 接下来的区域是Memory Mapping Segment。这块地址可以用来把文件映射进内存用的，如果二进制的执行文件依赖于某个动态链接库，就是在这个区域里面将 so 文件映射到了内存中。 再下面就是栈（Stack）地址段。主线程的函数调用的函数栈就是用这里的。
普通进程不能访问内核空间，如果需要进行更高权限的工作，就需要系统调用进入内核。每一段进程的内存空间存放的内容各不相同，但是进入内核后看到的都是同一个内核空间，同一个进程列表。
内核的代码访问内核的数据结构，大部分的情况下都是使用虚拟地址的，虽然内核代码权限很大，但是能够使用的虚拟地址范围也只能在内核空间，也即内核代码访问内核数据结构。
接下来，我们需要知道，如何将其映射成为物理地址呢？
咱们前面讲 x86 CPU 的时候，讲过分段机制，咱们规划虚拟空间的时候，也是将空间分成多个段进行保存。我们来看看分段机制的原理。
分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。段选择子就保存在咱们前面讲过的段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。虚拟地址中的段内偏移量应该位于 0 和段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。
例如，我们将上面的虚拟空间分成以下 4 个段，用 0～3 来编号。每个段在段表中有一个项，在物理空间中，段的排列如下图的右边所示。如果要访问段 2 中偏移量 600 的虚拟地址，我们可以计算出物理地址为，段 2 基地址 2000 + 偏移量 600 = 2600。
在 Linux 里面，段表全称段描述符表（segment descriptors），放在全局描述符表 GDT（Global Descriptor Table）里面，会有下面的宏来初始化段描述符表里面的表项。</description>
    </item>
    <item>
      <title>Linux 操作系统-进程间通信</title>
      <link>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</link>
      <pubDate>Sat, 14 Aug 2021 09:46:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</guid>
      <description>Linux 环境下，进程地址空间相互独立，每个进程各自有不同的用户地址空间。任何一个进程的全局变量在另一个进程中都看不到，所以进程和进程之间不能相互访问，要交换数据必须通过内核，在内核中开辟一块缓冲区，进程 1 把数据从用户空间拷到内核缓冲区，进程 2 再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）。
进程间通信概述 管道 在学 Linux 命令时就有管道在这个概念，比如下面这个命令
ps -ef | -grep root | xargs kill -9 将上一个命令的输出作为下一个命令的输入，数据只能向一个方向流动；双方需要互相通信时，需要建立起两个管道。
管道有两种类型：匿名管道和命名管道。上面提到的命令中|表示的管道即匿名管道 pipe。用完即销毁，自动创建，自动销毁。
使用mkfifo显示创建的是命名管道 fifo，
mkfifo hello hello即是管道名称，类型为p，就是pipe，接下来就可以在管道里写入东西，
# echo &amp;#34;hello world&amp;#34; &amp;gt; hello 光写入还不行，只有有另一个进程读取了内容才完成一次信息交换，才完成一次通信，
# cat &amp;lt; hello hello world 这种方式通信效率低，无法频繁通信。
消息队列 类似于日常沟通使用的邮件，有一定格式，有个收件列表，列表上的用户都可以反复在原邮件基础上回复，达到频繁交流的目的。这种模型就是消息队列模型。
共享内存 共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。
每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存空间映射到不同的物理内存中去。这个进程访问 A 地址和另一个进程访问 A 地址，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。
但是，咱们是不是可以变通一下，拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去。
使用shmget函数创建一个共享内存，
//key_t key: 唯一定位一个共享内存对象 //size_t size: 共享内存大小 //int flag: 如果是 IPC_CREAT 表示创建新的共享内存空间 int shmget(key_t key, size_t size, int flag); 创建完毕之后，我们可以通过 ipcs 命令查看这个共享内存。</description>
    </item>
    <item>
      <title>每天学命令-rename 批量重命名</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-rename%E6%89%B9%E9%87%8F%E9%87%8D%E5%91%BD%E5%90%8D/</link>
      <pubDate>Fri, 13 Aug 2021 18:40:16 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-rename%E6%89%B9%E9%87%8F%E9%87%8D%E5%91%BD%E5%90%8D/</guid>
      <description>Commands rename [options] &amp;#34;s/oldname/newname/&amp;#34; file 格式就很容易看出来怎么用的，就是/不能丢。
-v 将重命名的内容都打印到标准输出，v 可以看成 verbose-n 测试会重命名的内容，将结果都打印，但是并不真正执行重命名的过程-f force 会覆盖本地已经存在的文件-h -m -V 分别为帮助，帮助，版本-e 比较复杂，可以通过该选项，写一些脚本来做一些复杂的事情 Examples 替换文件名中的特定字段 rename &amp;#34;s/AA/aa/&amp;#34; * # 把文件名中的AA替换成aa 修改文件后缀 rename &amp;#34;s/.html/.php/&amp;#34; * # 把.html 后缀的改成 .php后缀rename &amp;#34;s/.png/.jpg/&amp;#34; * # 将 png 改为 jpg 添加后缀 rename &amp;#34;s/$/.txt/&amp;#34; * # 把所有的文件名都以txt结尾 $正则表达式中表示结尾。
保留部分文件名 假如需要在批量修改的时候保留部分文件名，可以使用引用\1 ，比如有下面格式的文件，只想保留日期部分。
Screenshot from 2019-01-02 15-56-49.jpgrename -n &amp;#34;s/Screenshot from ([0-9\\- ]+).jpg/\1.jpg/&amp;#34; * 将() 匹配的内容取出来放到替换部分。</description>
    </item>
    <item>
      <title>每天学命令-apt 安装卸载软件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-apt%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E8%BD%AF%E4%BB%B6/</link>
      <pubDate>Thu, 12 Aug 2021 18:42:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-apt%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E8%BD%AF%E4%BB%B6/</guid>
      <description>这个命令应该是我们平时用的最多的命令之一了，应该早就拿出来讲一下的。但是平时用的太多，总感觉自己都会用了，但是仔细看了所有命令，还是有一些比较实用但是没记住的命令。
apt的全称是Advanced Packaging Tool是 Linux 系统下的一款安装包管理工具。APT 可以自动下载、配置和安装二进制或源代码格式软件包，简化了 Unix 系统上管理软件的过程。
APT 主要由以下几个命令组成：
apt-getapt-cacheapt-file Commands 搜索软件包 apt search python3 安装软件包 apt install python3 更新源 sudo apt install update 更新软件 执行完 update 命令后，就可以使用 apt upgrade 来升级软件包了。执行命令后系统会提示有几个软件需要升级。在得到你的同意后，系统即开始自动下载安装软件包。
sudo apt install upgrade 卸载软件 apt remove python3 # 移除软件包，但是保留配置文件apt purge python3 #移除软件包并移除配置apt autoremove # 移除孤立的并不被依赖的软件包 列出软件清单 apt list </description>
    </item>
    <item>
      <title>每天学命令-kill 这个进程</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-kill%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/</link>
      <pubDate>Wed, 11 Aug 2021 15:22:40 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-kill%E8%BF%99%E4%B8%AA%E8%BF%9B%E7%A8%8B/</guid>
      <description>对于在前台运行的程序，我们可以用Ctrl+C来终止运行，但是在后台的程序就必须用kill命令来终止了。
Command -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称-a 当处理当前进程时，不限制命令名和进程号的对应关系-p 指定 kill 命令只打印相关进程的进程号，而不发送任何信号-s 指定发送信号-u 指定用户 Examples 查看所有信号 ➜ kill -lHUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS 常用信号
HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \）TERM 15 终止KILL 9 强制终止CONT 18 继续（与 STOP 相反， fg/bg 命令）STOP 19 暂停（同 Ctrl + Z） 用 ps 查找进程，然后用 kill 杀掉 ps -ef | grep &amp;#39;program&amp;#39;kill PID 无条件彻底杀死进程 kill –9 PID 杀死指定用户所有进程 kill -9 $(ps -ef | grep username)kill -u username </description>
    </item>
    <item>
      <title>进程间通信（IPC）之信号（Signal）</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7signal/</link>
      <pubDate>Wed, 11 Aug 2021 10:59:22 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E4%BF%A1%E5%8F%B7signal/</guid>
      <description>关于进程间通信的概述可以查看Linux 操作系统 - 进程间通信，代码同步在这里。
本文通过实例介绍通过共享内存实现进程间通信。
简介 信号就像实际生产过程中的应急预案，发生了某个异常就会启动特定的应急预案，为了响应各类异常情况，所以就定义了很多个信号，信号的名称是在头文件signal.h中定义的，信号都以SIG开头，常用的信号并不多，常用的信号如下：
SIGALRM #时钟定时信号, 计算的是实际的时间或时钟时间SIGHUP #终端的挂断或进程死亡SIGINT #来自键盘的中断信号SIGKILL #用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。SIGPIPE #管道破裂SIGTERM #程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理SIGUSR1,SIGUSR2 #留给用户使用 实例 #include &amp;lt;signal.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; void signalHandler(int sig) { printf(&amp;#34;\nOps! - I got signal %d\n&amp;#34;, sig); // 恢复终端中断信号 SIGINT 的默认行为 (void)signal(SIGINT, SIG_DFL); } int main() { // 改变终端中断信号 SIGINT 的默认行为，使之执行 ouch 函数 // 而不是终止程序的执行 (void)signal(SIGINT, signalHandler); while (1) { printf(&amp;#34;Hello World!\n&amp;#34;); sleep(1); } return 0; } 我们可以用signal()函数处理指定的信号，主要通过忽略和恢复其默认行为来工作。signal() 函数的原型如下：</description>
    </item>
    <item>
      <title>进程间通信（IPC）之共享内存 (SharedMemory)</title>
      <link>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98sharedmemory/</link>
      <pubDate>Tue, 10 Aug 2021 17:41:26 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1ipc%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98sharedmemory/</guid>
      <description>关于进程间通信的概述可以查看Linux 操作系统 - 进程间通信，代码同步在这里。
本文通过实例介绍通过共享内存实现进程间通信。
shmget(得到一个共享内存标识符或创建一个共享内存对象) 我们可以通过shmget函数创建或打开共享内存，通过函数签名
//key_t key: 唯一定位一个共享内存对象 //size_t size: 共享内存大小 //int flag: 如果是 IPC_CREAT 表示创建新的共享内存空间 int shmget(key_t key, size_t size, int flag); 第一个参数是共享内存的唯一标识，是需要我们指定的。那么如何指定key呢？如何保证唯一性呢？我们可以指定一个文件，ftok会根据这个文件的 inode，生成一个近乎唯一的 key。只要在这个消息队列的生命周期内，这个文件不要被删除就可以了。只要不删除，无论什么时刻，再调用 ftok，也会得到同样的key。 第二个参数是申请的空间大小，我们就申请 1024B。 第三个参数是权限标识，IPC_CREAT表示创建共享内存，0644表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。 shmat(把共享内存区对象映射到调用进程的地址空间) 第一次创建完共享内存时，它还不能被任何进程访问，shmat()函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。它的签名如下：
void *shmat(int shm_id, const void *shm_addr, int shmflg); 第一个参数就是上文产生的唯一标识。 第二个参数，shm_addr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址。 第三个参数，shm_flg是一组标志位，通常为 0。 调用成功时返回一个指向共享内存第一个字节的指针，如果调用失败返回-1. (void *) - 1把-1转换为指针0xFFFFFFFF，有时也会用到(void*)0，表示一个空指针。
shmdt(断开共享内存连接) 与 shmat 函数相反，是用来断开与共享内存附加点的地址，禁止本进程访问此片共享内存
函数签名如下：
int shmdt(const void *shmaddr) 参数一shmaddr为连接共享内存的起始地址。 需要注意的是，本函数调用并不删除所指定的共享内存区，而只是将先前用 shmat 函数连接（attach）好的共享内存脱离（detach）目前的进程。删除共享内存就需要下面的这个函数。
shmctl(共享内存管理) 完成对共享内存的控制，包括改变状态，删除共享内存等。
函数签名如下：
int shmctl(int shmid, int cmd, struct shmid_ds *buf) shmid共享内存唯一标识符 cmd执行的操作，包括如下 IPC_STAT：得到共享内存的状态，把共享内存的shmid_ds结构复制到buf中 IPC_SET：改变共享内存的状态，把buf所指的shmid_ds结构中的uid、gid、mode复制到共享内存的shmid_ds结构内 IPC_RMID：删除这片共享内存 buf共享内存管理结构体。具体说明参见共享内存内核结构定义部分 //server.</description>
    </item>
    <item>
      <title>每天学命令-ar 多文件归档为一个文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ar%E5%A4%9A%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/</link>
      <pubDate>Tue, 10 Aug 2021 11:33:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ar%E5%A4%9A%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/</guid>
      <description>现在我们有solution.c,solution.h两个文件，他们实现了某一个功能，自成一个模块。在其他项目中也可复用。我们就可以把它做成库文件。ar命令就可以将锁哥文件整合成一个库文件，也可以从一个库中单独提取出某一个文件。
Commands -d 删除备存文件中的成员文件。-m 变更成员文件在备存文件中的次序。-p 显示备存文件中的成员文件内容。-q 将文件附加在备存文件末端。-r 将文件插入备存文件中。-t 显示备存文件中所包含的文件。-x 自备存文件中取出成员文件。 Examples 打包文件 将solution.c solution.h两个文件打包成solution.bak，并显示详细信息
➜ ar rv solution.bak solution.c solution.har: 正在创建 solution.baka - solution.ca - solution.h 显示打包文件内容 ➜ ar t solution.bak solution.csolution.h </description>
    </item>
    <item>
      <title>每日学命令-ps 显示进程状态</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E5%91%BD%E4%BB%A4-ps%E6%98%BE%E7%A4%BA%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81/</link>
      <pubDate>Mon, 09 Aug 2021 19:37:38 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E5%91%BD%E4%BB%A4-ps%E6%98%BE%E7%A4%BA%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81/</guid>
      <description>ps命令显示的信息类似于 Windows 的任务管理器。也是参数超级多的一个命令，所以就不列参数了，需要查看时直接搜索，这里列举一下实例。
使用实例 显示当前执行的所有程序
➜ ~ ps -a PID TTY TIME CMD 879 tty2 00:03:43 Xorg 990 tty2 00:00:00 gnome-session-b 2653 pts/0 00:00:00 zsh 12365 pts/0 00:00:00 ps 显示所有程序
➜ ~ ps -A PID TTY TIME CMD 1 ? 00:00:01 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:00 rcu_gp 4 ? 00:00:00 rcu_par_gp 6 ? 00:00:00 kworker/0:0H-kblockd 9 ? 00:00:00 mm_percpu_wq 10 ? 00:00:00 ksoftirqd/0 11 ? 00:00:02 rcu_sched 12 ?</description>
    </item>
    <item>
      <title>每天学命令-scp 远程拷贝文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-scp%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D%E6%96%87%E4%BB%B6/</link>
      <pubDate>Fri, 06 Aug 2021 20:05:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-scp%E8%BF%9C%E7%A8%8B%E6%8B%B7%E8%B4%9D%E6%96%87%E4%BB%B6/</guid>
      <description>看到同事要安装自己编译一天的库，本想传授一下“踩坑经验”，结果他用scp命令直接从已经安装好的电脑里复制了一份。心里一万只 XXX 在奔腾。
早知道先学学这个命令了。
可选参数 参数 功能 -1 强制 scp 命令使用协议 ssh1 -2 强制 scp 命令使用协议 ssh2 -4 强制 scp 命令使用协议 ssh2 -6 强制 scp 命令只使用 IPv6 寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩 -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条 -r 递归复制整个目录 -v 详细方式显示输出 -P 注意是大写的 P, port 是指定数据传输用到的端口号 使用实例 复制文件
scp local_file rmot_usr@rmot_ip:rmot_folderscp /opt/soft/ root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz </description>
    </item>
    <item>
      <title>每天学命令-grep 文本搜索</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-grep%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2/</link>
      <pubDate>Thu, 05 Aug 2021 19:27:48 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-grep%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2/</guid>
      <description>grep全称global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来。这名字就怪吓人，如果熟练掌握正则表达式，配上这命令 Linux 里可以横着走了。
这个命令参数实在太多，加上正则表达式估计一张纸不够。那就直接上实例吧。
使用实例 在当前目录中，查找后缀带有cpp字样的文中包含test字符串的文件，并打印所在行
grep test *cppgrep --colorauto test *cpp # 用颜色标记 通过&amp;quot;-v&amp;quot;参数可以打印出不符合条件行的内容。
grep -v test *cpp 系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行)。-n 或 --line-number 可以显示符合样式的那一行之前，标示出该行的列数编号。
grep -n &amp;#39;2019-10-24 00:01:11&amp;#39; *.log grep 静默输出，不会输出任何信息，如果命令运行成功返回 0，失败则返回非 0 值。一般用于条件测试。
grep -q &amp;#34;test&amp;#34; filename 在多级目录中对文本进行递归搜索
grep &amp;#34;text&amp;#34; . -r -n 配合管道，查找指定的进程信息
ps -ef | grep svn 查找指定的进程个数，-c计数
ps -ef | grep svn -c 常用正则表达式通配符
通配符 功能 c* 将匹配 0 个（即空白）或多个字符 c（c 为任一字符） .</description>
    </item>
    <item>
      <title>每天学命令-cat 可以查看文件的小猫咪</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-cat%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%B0%8F%E7%8C%AB%E5%92%AA/</link>
      <pubDate>Wed, 04 Aug 2021 09:57:51 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-cat%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%B0%8F%E7%8C%AB%E5%92%AA/</guid>
      <description>cat 可以将文件的内容方便地输出到屏幕上。但是它的全称concatenate意为“连接”，连接文件也是它的重要功能之一，很多人可能都不常用。只记得输出文件内容了。
可选参数 -n 或 --number #由 1 开始对所有输出的行数编号。-b 或 --number-nonblank #和 -n 相似，只不过对于空白行不编号。-s 或 --squeeze-blank #当遇到有连续两行以上的空白行，就代换为一行的空白行。-v 或 --show-nonprinting #使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。-E 或 --show-ends # 在每行结束处显示 $。-T 或 --show-tabs: #将 TAB 字符显示为 ^I。-A, --show-all #等价于 -vET。-e #等价于&amp;#34;-vE&amp;#34;选项；-t #等价于&amp;#34;-vT&amp;#34;选项； 使用实例 将文件内容输出到屏幕
➜ ~ cat test.txt This is firt line!This is second line!This is third line!This is fourth line!</description>
    </item>
    <item>
      <title>解决/usr/bin/env:python:No such file or directory</title>
      <link>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3-usr-bin-env-python-no-such-file-or-directory/</link>
      <pubDate>Tue, 03 Aug 2021 15:58:44 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E8%A7%A3%E5%86%B3-usr-bin-env-python-no-such-file-or-directory/</guid>
      <description>在执行的程序源码开头有这么一句!#/usr/bin/env python，!#这玩意叫shebang也叫hashbang。他用来指定脚本的解释器，也就是说这个程序指定python解释器。
再看这个错误提示，罪魁祸首就是这句命令，就是说在环境变量找不到python，通俗点说，假如我要能直接用python来跑这个程序，我在命令行直接输入python应该是可以进入python环境的，但是此时肯定不能。我们可以试试
dominic@hanhan:~$ pythonCommond not found xxxxxxxxxxx 解决方案一 系统里没有python还跑个锤子，先装上再说
apt-get install python3 这时候可能就解决问题了
解决方案二 有的人可能python早就装了，但是仍然有这个问题，但是我们在命令输入python仍然没法用，但是输入python3就可以
那python3可以，我直接将python改成python3不就完了。没错！
打开文件将!#/usr/bin/env python改成!#/usr/bin/env python3
解决方案三 如果了解软链接，那我们就可以不用去改源码了，源码最好还是保持原样。
既然找不到python这玩意，那我们给他建一个不就完了。
他要python就是用来解释程序的，我们本地装的python3就是他需要的东西
先找找我们的python3在哪
dominic@hanhan:~$ whereis python3python3: /usr/bin/python3.8 /usr/bin/python3.8-config /usr/bin/python3 一般在/usr/bin目录下，然后我们在这个目录下给他创建一个软链接“快捷方式”，具体咋用的啥意思，可以参考这篇文章。
sudo ln -s /usr/bin/python3 /usr/bin/python 这样程序再找python时就会链接到python3，然后用python3去当解释器。
解决方案四 可能在root目录下使用过repo，将其删除</description>
    </item>
    <item>
      <title>每天学命令-ln 软硬链接</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ln%E8%BD%AF%E7%A1%AC%E9%93%BE%E6%8E%A5/</link>
      <pubDate>Tue, 03 Aug 2021 11:57:02 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ln%E8%BD%AF%E7%A1%AC%E9%93%BE%E6%8E%A5/</guid>
      <description>Linux ln（英文全拼：link files）命令是一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。这有点像 Windows 环境下的快捷方式。介绍命令前了解一下软链接，硬链接具体是什么。
硬链接 Hard Link 在 Linux 系统中，每个文件对应一个 inode，文件的内容在存储在 inode 指向的 data block 中。要读取该文件的内容，需要通过文件所在的目录中记录的文件名找到文件的 inode 号，然后通过 inode 找到存储文件内容的 data block。当然多个文件名可以指向同一个inode。
使用ll命令显示文件的详细信息，-i参数显示其结点信息，其中最前面的一串数字就是inode信息。我们以/opt/test.txt文件为例，查看其结点信息。
dominic@hanhan:/opt$ ll -i test.txt 2498138 -rw-r--r-- 1 root root 4 8月 3 12:16 test.txt 使用 ln 命令在/opt/temp目录下创建一个 test.txt 文件的硬链接，然后观察其文件属性：
dominic@hanhan:/opt/temp$ sudo ln ../test.txt .dominic@hanhan:/opt/temp$ ll -i ../test.txt test.txt 2498138 -rw-r--r-- 2 root root 4 8月 3 12:16 ../test.txt2498138 -rw-r--r-- 2 root root 4 8月 3 12:16 test.</description>
    </item>
    <item>
      <title>每天学命令-ed 行编辑器</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ed%E8%A1%8C%E7%BC%96%E8%BE%91%E5%99%A8/</link>
      <pubDate>Mon, 02 Aug 2021 09:57:10 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-ed%E8%A1%8C%E7%BC%96%E8%BE%91%E5%99%A8/</guid>
      <description>ed命令是文本编辑器，用于文本编辑。
ed是 Linux 中功能最简单的文本编辑程序，一次仅能编辑一行而非全屏幕方式的操作。很多命令和vim相似，平时开发中并不常用，但是在编辑大文本时还是会用到。
学学无妨毕竟这是 Unix 系统三大要件（编辑器，汇编器和 shell）之一。
ed编辑器有两种模式：命令模式和输入模式。命令模式下输入a,i,c,d可以进入对应的编辑模式，接下来可以输入任何想要输入的内容，输入完毕或者要切换命令时，可以输入.退出输入模式。
Commands a #添加到行i #添加到行首c #改变行d #删除行 Line Address . #buffer 中 当前行$ #最后一行n #第 n 行，行的范围是 [0,$]- or ^ #前一行-n or ^n #前 n 行+ or +n #后一行及后n行, or % #全部行，等同于 1,$; #当前行到最后一行 .,$/re/ #下一个包含正则 re 的行?re? #上一个包含正则 re 的行 使用实例 dominic@hanhan:~$ ed # 进入编辑模式This is a test text!</description>
    </item>
    <item>
      <title>每天学命令-wc 统计文件有多少字多少行</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-wc%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E6%9C%89%E5%A4%9A%E5%B0%91%E5%AD%97%E5%A4%9A%E5%B0%91%E8%A1%8C/</link>
      <pubDate>Fri, 30 Jul 2021 17:26:39 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-wc%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E6%9C%89%E5%A4%9A%E5%B0%91%E5%AD%97%E5%A4%9A%E5%B0%91%E8%A1%8C/</guid>
      <description>想知道自己代码写了多少行，可以一个wc命令搞定。
可选参数 -l：仅列出行； -w：仅列出多少字 (英文单字)； -m：多少字符 使用实例 统计hello.c文件夹下文件总共多少行
$ wc -l hello.c 14 hello.c 统计文件夹下文件的个数
ls -l | grep &amp;#34;^-&amp;#34; | wc -l 统计当前目录下文件的个数（包括子目录）
ls -lR| grep &amp;#34;^-&amp;#34; | wc -l 查看目录下文件夹 (目录) 的个数（包括子目录）
ls -lR | grep &amp;#34;^d&amp;#34; | wc -l 过滤ls的输出信息，只保留一般文件，只保留目录是grep &amp;quot;^d&amp;quot;。 </description>
    </item>
    <item>
      <title>更换 Ubuntu 软件更新源</title>
      <link>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2ubuntu%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</link>
      <pubDate>Fri, 30 Jul 2021 11:14:41 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux%E6%9B%B4%E6%8D%A2ubuntu%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%BA%90/</guid>
      <description>Ubuntu 默认是国外的源，软件下载和更新都比较慢。两种方法将下载源换成国内的源。
用&amp;quot;软件和更新&amp;quot;工具 从 Ubuntu 菜单中找到软件和更新这个应用并打开。
找到下载自，选择其他 - 国内-aliyun，然后勾选前四个选项。关闭时会弹出对话框，点击更新。然后就能愉快的下载软件了。
修改sourcelist 备份原文件 这也算是系统文件的一部分，还是保险一点，出错了再改回来。
sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup 打开并修改 sudo vi /etc/apt/sources.list vim用的不习惯的估计会和我一样找全选内容怎么操作。教给你了 在命令模式下，就是按一下esc键，然后输入ggvG。具体什么含义看VIM 笔记吧，选择后直接delete删除，再把阿里云源粘贴进去。保存退出。
#阿里云 deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.</description>
    </item>
    <item>
      <title>每天学命令-find 查找文件</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-find%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 29 Jul 2021 11:05:43 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-find%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6/</guid>
      <description>命令格式 find [path] [expression] 在path下查找expression表示的文件
常用命令 一般常见就是自己不知道写的某个文件或者文件夹放哪里了，又或者只记住部分文件名。以下几个命令就能帮到你。
按文件名查找 find -name filename(查找结果显示路径)或者 find filename(查找结果不显示路径)find hello.cpp #当前目录下精确查找hello.cpp文件find hello #当前目录下精确查找hello文件find hello* #当前目录下模糊查找以hello为前缀的文件 按类型查找 这就是为查找文件夹用的。
find -type [fdlcb] name [fdlcb]都是类型，d就是目录，文件夹类型。
find / -type d -name &amp;#34;helloworld&amp;#34; #查找名为helloworld的文件夹 按文件名查找 以下就详细介绍一些参数
find -name &amp;#34;hello.cpp&amp;#34; # 搜索文件名，大小写敏感find -iname &amp;#34;hello.cpp&amp;#34; #大小写不敏感 按文件大小查找 find [path] -size 50Mfind / -size 10M # 查找系统中大小等于10M的文件find / -size +50M # 查找系统中大小大于50M的文件find / -size -30M # 查找系统中大小小于30M的文件 按时间来查找文件 Linux 会存储下面的时间：</description>
    </item>
    <item>
      <title>在 QEMU 上运行 64 位和 32 位 RISC-V-Linux</title>
      <link>http://localhost:8888/posts/qemu%E4%B8%8A%E8%BF%90%E8%A1%8C64%E4%BD%8D%E5%92%8C32%E4%BD%8Drisc-v-linux/</link>
      <pubDate>Wed, 28 Jul 2021 13:47:56 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E4%B8%8A%E8%BF%90%E8%A1%8C64%E4%BD%8D%E5%92%8C32%E4%BD%8Drisc-v-linux/</guid>
      <description>制作交叉工具链 riscv-gnu-toolchain 下载源码 这个仓库是我遇到的最难下载的一个仓库了，公司网慢和虚拟机性能差都脱不了干系。估计下载了五小时都不止，刚开始还指望一个命令所有子模块都下载完的，结果愣是等了半天中断了。试了两次后放弃了。如果各位看官能一次完成，那您是福大。
国内的码云平台有个Gitee 极速下载项目，上面有 GitHub 的一些常用开源项目的镜像，可供加速下载。
# riscv-gnu-toolchainhttps://gitee.com/mirrors/riscv-gnu-toolchain.git 下载时问题出现了，如果下载子模块仍然会卡住，如果不加--recursive就只能下载主体内容，子模块都没有。（以下内容为第一安装时的方法，后续又找到了git clone 快速下载子模块的方法）
开始下载时不加--recursive参数，只下载riscv-gnu-toolchain的主体内容，然后进入到riscv-gnu-toolchain文件夹下，手动下载子模块的内容。
当下完riscv-binutils继续下载riscv-gdb时发现这两个项目是同一个项目，只是不同的分支。但是码云上并没有区分，但是我也没找到在码云上的对应分支。只能用油猴脚本了。
如果你有油猴插件可以去greasyfork搜索安装GitHub 镜像访问，加速下载这个脚本，刷新 GitHub 仓库界面就会多出几个镜像地址，一般下载都会快好几倍。如果不用油猴插件的可以用我复制好的链接。
# riscv-binutilsgit clone https://gitee.com/mirrors/riscv-binutils-gdb.git# riscv-gccgit clone https://gitee.com/mirrors/riscv-gcc.git# riscv-dejagnugit clone https://gitee.com/mirrors/riscv-dejagnu.git# riscv-glibcgit clone https://gitee.com/mirrors/riscv-glibc.git# riscv-newlibgit clone https://gitee.com/mirrors/riscv-newlib.git# riscv-gdbgit clone --depth=1 https://hub.fastgit.org/riscv/riscv-binutils-gdb.git 编译 riscv-gnu-toolchain 提前安装如下软件：
sudo apt-get install autoconf automake autotools-dev curl python3 libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev 不听老人言，吃亏在眼前呀，本以为这是可选项，很多库都安装了，就没有操作这一步，结果就是编译半天结果还错了。如果报make 错误 127，那就老老实实把前置的这些库都装上。</description>
    </item>
    <item>
      <title>每天学命令-df/du查看磁盘剩余空间</title>
      <link>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-df-du%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Wed, 28 Jul 2021 10:13:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E6%AF%8F%E5%A4%A9%E5%AD%A6%E5%91%BD%E4%BB%A4-df-du%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4/</guid>
      <description>df全称disk filesystem ，以磁盘分区为单位查看文件系统，可以查看磁盘文件占用空间，磁盘剩余空间等信息。
命令格式 df [] [] 可选参数 -a 全部文件系统列表-h 方便阅读方式显示-H 等于“-h”，但是计算式，1K=1000，而不是 1K=1024-i 显示 inode 信息-k 区块为 1024 字节-l 只显示本地文件系统-m 区块为 1048576 字节--no-sync 忽略 sync 命令-P 输出格式为 POSIX--sync 在取得磁盘信息前，先执行 sync 命令-T 文件系统类型 使用实例 df -T显示包含文件系统，类型，可用大小，已用大小，挂载点等信息。
dominic@hanhan:~$ df -T文件系统 类型 1K-块 已用 可用 已用% 挂载点udev devtmpfs 1985056 0 1985056 0% /devtmpfs tmpfs 403036 1304 401732 1% /run/dev/sda5 ext4 50824704 20826256 27386992 44% /tmpfs tmpfs 2015172 0 2015172 0% /dev/shmtmpfs tmpfs 5120 4 5116 1% /run/locktmpfs tmpfs 2015172 0 2015172 0% /sys/fs/cgroup/dev/loop0 squashfs 56832 56832 0 100% /snap/core18/1988/dev/loop1 squashfs 56832 56832 0 100% /snap/core18/2074 du全称disk usage可以查看文件，文件夹占用情况。</description>
    </item>
    <item>
      <title>Linux(Ubuntu) 环境下安装 Qt</title>
      <link>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85qt/</link>
      <pubDate>Tue, 27 Jul 2021 16:34:50 +0000</pubDate>
      <guid>http://localhost:8888/posts/linux-ubuntu-%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85qt/</guid>
      <description>真蠢，之前费那么大劲，只要一句命令就完事了
下载安装 sudo apt install qtcreator 但是在用命令行构建 project 时可能会报错
qmake -projectcould not find a Qt installation of &amp;#39;&amp;#39; 这时候需要
sudo apt-get install qt5-default 好了可以愉快玩耍了。
瞎折腾
下载 Qt 从 Qt5.15.0 起，对于开源用户，Qt 官方不再提供独立安装文件，且不再有 bug 修复版本（比如 Qt5.15.1），如果从官网下载，需要自己编译。虽然想试试编译，但是虚拟机刚开始开的空间太小了，还是另寻他法吧。以后有机会再来编译试试新功能。若读者有兴趣可以从官网下载源码并编译。或者参考官方的编译教程，从 GitHub 上下载。
国内有一些镜像站，提供 qt 镜像下载： 清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/archive/qt/ 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/ 北京理工大学：https://mirrors.cnnic.cn/qt/
以清华大学的镜像为例，找到archive/qt/5.14/5.14.0/qt-opensource-linux-x64-5.14.0.run，点击即可开始下载。
qt 5.15 已经不提供安装包，想要最新版本，只能下 5.14，但是 5.14.2 下载没资源，下不动，如果遇到下不动的情况换一个版本吧
安装 Qt 下载的.run文件双击是无法安装的，因为它还没有可执行的权限，需要我们赋给它执行权限，打开终端进入安装包的目录。
chmod +x filename.run chmod命令是控制用户对文件的权限修改的命令，x是可执行权限的参数。 执行以上命令后就可以直接双击安装了。
网上一些教程可以跳过登录，我没找到跳过按钮，需要注册一个账号才能继续安装。 安装目录一般选择在/opt目录下 安装的附加组件最好都选择，以免后期使用再安装麻烦。Qt Creator 肯定要装的。 安装依赖库 apt-get install g++apt-get install libgl1-mesa-devapt-get install libqt4-devapt-get install build-essential # Build Essential，它是一个元软件包，可让您在Ubuntu中安装和使用c ++工具。sudo apt install qt5-default # 如果要将Qt 5用作默认的Qt Creator版本需要安装，否则会报 qmake: could not find a Qt installation of &amp;#39;&amp;#39;的错误 使用 Qt Creator 创建第一个程序 使用 Qt Creator 创建 首先我们先创建一个不带窗口的 HelloWorld 程序，测试安装是否成功，打开 Qt Creator-文件 - 新建文件或项目，选择 Non-Qt Project-Plain C++ Application。 接下来就设置项目名等，一直下一步。完成后就可以在编辑器看到如下 点击左下角运行按钮就可以得到如下： 再创建一个带窗口的 HelloWorld，在选择模板时选择 Application-Qt Widgets Application。一路点下一步就可以完成创建，运行后就可得到一个灰白的 HelloWorld 窗口。</description>
    </item>
    <item>
      <title>QEMU 文档</title>
      <link>http://localhost:8888/posts/qemu%E6%96%87%E6%A1%A3/</link>
      <pubDate>Tue, 27 Jul 2021 11:12:01 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E6%96%87%E6%A1%A3/</guid>
      <description>调用文档 qemu-system-x86_64 [options] [disk_image]disk_image是 IDE 硬盘 0 的原始硬盘映像。某些目标不需要磁盘映像。
标准参数 Standard options -h 功能 显示帮助信息并退出
子参数
调用实例
qemu-system-riscv32 -h -version 功能 显示 qemu 版本信息并退出
子参数
调用实例
qemu-system-riscv32 -version -machine [type=]name[,prop=value[,...]] 功能 通过名称选择模拟器。使用 -machine help 可以查看可用的模拟器。 对于支持跨版本实时迁移兼容性的架构，每个版本都会引入一个新的版本化模拟器类型。例如，2.8.0 版本为 x86_64/i686 架构引入了“pc-i440fx-2.8”和“pc-q35-2.8”。
子参数 为了允许用户从 QEMU 2.8.0 版实时迁移到 QEMU 2.9.0 版，2.9.0 版也必须支持“pc-i440fx-2.8”和“pc-q35-2.8”机器。为了允许用户在升级时实时迁移 VMs 跳过多个中间版本，QEMU 的新版本将支持多个以前版本的机器类型。 支持的机器属性有：
accel=accels1[:accels2[:...]] This is used to enable an accelerator. Depending on the target architecture, kvm, xen, hax, hvf, nvmm, whpx or tcg can be available.</description>
    </item>
    <item>
      <title>QEMU 初识</title>
      <link>http://localhost:8888/posts/qemu%E5%88%9D%E8%AF%86/</link>
      <pubDate>Fri, 23 Jul 2021 11:54:49 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%88%9D%E8%AF%86/</guid>
      <description>简介 QEMU 是一款开源的模拟器及虚拟机监管器 (Virtual Machine Monitor, VMM)。QEMU 主要提供两种功能给用户使用。一是作为用户态模拟器，利用动态代码翻译机制来执行不同于主机架构的代码。二是作为虚拟机监管器，模拟全系统，利用其他 VMM(Xen, KVM, etc) 来使用硬件提供的虚拟化支持，创建接近于主机性能的虚拟机。
安装 使用包管理安装 sudo apt-get install qemu 使用源码安装 wget wget https://download.qemu.org/qemu-6.1.0-rc3.tar.xztar xvJf qemu-6.1.0-rc3.tar.xzcd qemu-6.1.0-rc3 安装相关库 apt-get install libglib2.0-devapt-get install ninja-buildapt install g++apt install libpixman-1-devapt install libsdl2-dev -y 配置 通过./configure --help 的查看编译时的选项，--target-list选项为可选的模拟器，默认全选。 --target-list 中的 xxx-soft 和 xxx-linux-user 分别指系统模拟器和应用程序模拟器，生成的二进制文件名字为qemu-system-xxx和 qemu-xxx 本文使用如下配置：
./configure --prefix=XXX --enable-debug --target-list=riscv32-softmmu,riscv32-linux-user,riscv64-linux-user,riscv64-softmmu --enable-kvm# --prefix 选项设置qemu的安装位置绝对路径，之后若要卸载删除qemu只要删除该文件夹即可，--enable-kvm开启kvm# config完，可以在指定的qemu安装文件夹下面找到config-host.mak文件，# 该文件记录着qemu配置的选项，可以和自己设置的进行对比，确保配置和自己已知 接着进行编译
make -j8 直接make会很慢，第一次编译时默认安装说有模拟器，编译了三四个小时。加上-j8可以进行多线程编译</description>
    </item>
    <item>
      <title>什么是驱动，驱动的作用又是什么？</title>
      <link>http://localhost:8888/posts/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A9%B1%E5%8A%A8%E9%A9%B1%E5%8A%A8%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88/</link>
      <pubDate>Wed, 21 Jul 2021 15:02:58 +0000</pubDate>
      <guid>http://localhost:8888/posts/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A9%B1%E5%8A%A8%E9%A9%B1%E5%8A%A8%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88/</guid>
      <description>任何一个计算机系统的运行都是系统中软硬件协作的结果，没有硬件的软件是空中楼阁，而没有软件的硬件则只是一堆废铁。&amp;ndash;天朗 - 星空
硬件是底层基础，所有软件代码的运行平台，相对固定不易改变，而软件是具体的应用，它灵活多变，可以应对用户的不同需求。
为尽可能快速地完成设计，应用软件工程师不想也不必关心硬件，而硬件工程师也难有足够的闲暇和能力来顾忌软件。譬如，应用软件工程师在调用套接字发送和接收数据包的时候，不必关心网卡上的寄存器、存储空间、I/O 端口、片选以及其他任何硬件层面的操作调度；在使用printf()函数输出信息的时候，他不用知道底层究竟是怎样把相应的信息输出到屏幕或者串口的具体硬件过程，需要的只是出现相应的显示效果。
也就是说，应用软件工程师需要看到一个没有硬件的纯粹的软件世界，硬件必须被透明地呈现给他们。谁来实现硬件对应用软件工程师的隐形？这个艰巨的任务就落在了驱动工程师的头上。
对设备驱动最通俗的解释就是“驱使硬件设备行动” 。设备驱动与底层硬件直接打交道，按照硬件设备的具体工作方式读写设备寄存器，完成设备的轮询、中断处理、DMA 通信，进行物理内存向虚拟内存的映射，最终使通信设备能够收发数据，使显示设备能够显示文字和画面，使存储设备能够记录文件和数据。</description>
    </item>
    <item>
      <title>QEMU 学习记录</title>
      <link>http://localhost:8888/posts/qemu%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 20 Jul 2021 16:51:34 +0000</pubDate>
      <guid>http://localhost:8888/posts/qemu%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
      <description>QEMU 学习记录 什么是 KVM？ 基于内核的虚拟机 Kernel-based Virtual Machine（KVM）是一种内建于 Linux 中的开源虚拟化技术。具体而言，KVM 可帮助用户将 Linux 转变为虚拟机监控程序，使主机计算机能够运行多个隔离的虚拟环境，即虚拟客户机或虚拟机（VM）。
什么是 QEMU？ Qemu 是一个完整的可以单独运行的软件，它可以用来模拟不同架构的机器，非常灵活和可移植。它主要通过一个特殊的&amp;rsquo;重编译器&amp;rsquo;将为特定处理器编写二进制代码转换为另一种。
KVM 与 QEMU 的关系 KVM 是 Linux 的一个模块。可以用modprobe去加载 KVM 模块。加载了模块后，才能进一步通过其他工具创建虚拟机。但仅有 KVM 模块是 远远不够的，因为用户无法直接控制内核模块去作事情：还必须有一个用户空间的工具才行。这个用户空间的工具，开发者选择了已经成型的开源虚拟化软件 QEMU。KVM 使用了 QEMU 的一部分，并稍加改造，就成了可控制 KVM 的用户空间工具了。所以你会看到，官方提供的 KVM 下载有两 大部分三个文件，分别是 KVM 模块、QEMU 工具以及二者的合集。也就是说，你可以只升级 KVM 模块，也可以只升级 QEMU 工具。
QEMU 用户模式与系统模式 QEMU 属于应用层的仿真程序，它支持两种操作模式：用户模式模拟和系统模式模拟。
用户模式仿真 利用动态代码翻译机制，可以在当前 CPU 上执行被编译为支持其他 CPU 的程序，如可以在 x86 机器上执行一个 ARM 二进制可执行程序。（执行主机 CPU 指令的动态翻译并相应地转换 Linux 系统调用）。 系统模式仿真 利用其它 VMM(Xen, KVM) 来使用硬件提供的虚拟化支持，创建接近于主机性能的全功能虚拟机，包括处理器和配套的外围设备（磁盘，以太网等）。 用户模式 支持的 CPU：x86 (32 and 64 bit), PowerPC (32 and 64 bit), ARM, MIPS (32 bit only), Sparc (32 and 64 bit), Alpha, ColdFire(m68k), CRISv32 和 MicroBlaze 下列操作系统支持 QEMU 的用户模式模拟：</description>
    </item>
    <item>
      <title>ZH-Unix 是什么，为什么重要？</title>
      <link>http://localhost:8888/posts/zh-unix%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</link>
      <pubDate>Tue, 20 Jul 2021 15:44:05 +0000</pubDate>
      <guid>http://localhost:8888/posts/zh-unix%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E8%A6%81/</guid>
      <description>Unix 是什么，为什么重要？ Author：CHRIS HOFFMAN 译：What Is Unix, and Why Does It Matter?
大多数操作系统都可以分为两大类。除了微软基于 Windows NT 的操作系统之外，几乎所有其他系统的祖宗都是 Unix。
Linux、Mac OS X、Android、iOS、Chrome OS、PlayStation 4 上使用的 Orbis 操作系统，无论路由器上运行的是什么固件——所有这些操作系统通常都被称为“类 Unix”操作系统。
Unix 的设计延续至今 19 世纪中后期 Unix 在贝尔实验室中被开发出来。最初版的 Unix 有许多重要的设计特性至今仍然在使用。
“Unix 哲学”之一就是，创建小型、模块化的程序，一个程序只做一件事并把它做好。如果你经常使用 Linux 终端，那么你应该对此很熟悉——系统提供了许多实用程序，这些程序可以通过管道和其他功能以不同方式组合以执行更复杂的任务。甚至图形程序也可能在后台调用更简单的实用程序来完成复杂的工作。这也使得创建 shell 脚本变得容易，将简单的工具串在一起来完成复杂的事情。
Unix 有一个程序之间通信用的单一文件系统。这就是为什么在 Linux 上“一切都是文件” ——包括硬件设备和提供系统信息或其他数据的特殊文件。这也是为什么只有 Windows 有驱动器号（C、D、E 盘）的原因，它是从 DOS 继承的——在其他操作系统上，系统上的每个文件都是单个目录层次结构的一部分。
追寻 Unix 的后代 Unix 及其后代的历史错综复杂，简化起见，我们大致将 Unix 的后代分为两类。
一类 Unix 后代是在学术界发展起来的。第一个是 BSD（BerkeleySoftwareDistribution），一个开源、类 Unix 操作系统。BSD 通过 FreeBSD、NetBSD 和 OpenBSD 延续至今。NeXTStep 也是基于最初的 BSD 开发的，Apple 的 Mac OS X 是基于 NeXTStep 开发出来的，而 iOS 则基于 Mac OS X。还有一些操作系统，包括 PlayStation 4 上使用的 Orbis OS，都是从 BSD 操作系统衍生而来的。</description>
    </item>
  </channel>
</rss>
